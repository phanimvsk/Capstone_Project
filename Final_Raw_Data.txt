After some deliberation we have chosen Python as our programming language. It is freely available and has been adopted as the programming language of choice for many practitioners in data science and machine learning. It has many useful
packages for data manipulation (often ported from R) and has been designed to be easy to program.Python is a high-level, general-purpose programming language.Python is dynamically-typed and garbage-collected. It supports multiple programming paradigms
It is objected oriented Language. Data Science is an interdisciplinary field that mines raw data, analyses it, and comes up with patterns that are used to extract valuable insights.Data Science combines statistics, maths, specialised programs, artificial intelligence, machine learning etc.To be able to truly understand data science and machine learning it is important to appreciate the underlying mathematics and statistics, as well as the resulting
algorithms.The purpose of this book is to provide an accessible, yet comprehensive, account of data science and machine learning. It is intended for anyone interested in gaining a better understanding of the mathematics and statistics that underpin the rich variety of ideas and machine learning algorithms in data science.An example of supervised learning is email spam detection. The goal is to train the learner gT to accurately predict whether any future email, as represented by the feature vector x, is spam or not. The training data consists of the feature vectors of a number of different email examples as well as the corresponding labels (spam or not spam). For instance, a feature vector could consist of the number of times sales-pitch words like “free”,“sale”, or “miss out” occur within a given email.As seen from the above discussion, most questions of interest in supervised learning can be answered if we know the conditional pdf f(y | x), because we can then in principle work out the function value g.(x).In Supervised Learning labeled data is used as an input.It has a feedback mechanism.The most commonly used algorithms in this section are decision trees, logistic regression, and support vector machine.In contrast, unsupervised learning makes no distinction between response and explanatory variables, and the objective is simply to learn the structure of the unknown distribution of the data. In other words, we need to learn f(x). In this case the guess g(x) is an approximation of f(x) and the risk is of the form (g) = E Loss(f(X), g(X)).
An example of unsupervised learning is when we wish to analyze the purchasing behaviors of the customers of a grocery shop that has a total of, say, a hundred items on sale.A feature vector here could be a binary vector x ∈ {0, 1} 100 representing the items bought by a customer on a visit to the shop (a 1 in the k-th position if a customer bought item k ∈ {1, . . . , 100} and a 0 otherwise). Based on a training set τ = {x1, . . . , xn}, we wish to find any interesting or unusual purchasing patterns. In general, it is difficult to know if an unsupervised learner is doing a good job, because there is no teacher to provide examples of accurate predictions.In Unsupervised Learning unlabeled data is used as input. It has no feedback mechanism.The most commonly used unsupervised learning algorithms are k-means clustering, hierarchical clustering, and apriori algorithm.The main reason why the multivariate normal distribution plays an important role in data science and machine learning is that it satisfies the following properties, the details
and proofs of which can be found in :
1. Affine combinations are normal.
2. Marginal distributions are normal.
3. Conditional distributions are normal.The following are the steps involved in Lifecycle of Data Science:-
a) Business Understanding (b) Data Mining (c) Data Cleaning (d) Data Exploration(e) Feature Engineering (f) Predictive Modeling (g) Data Vizualization.
Many algorithms in machine learning and data science make use of Monte Carlo techniques.When we taught these courses, we noticed that students were eager to learn not only how to apply algorithms but also to understand how these algorithms actually work. However,many existing textbooks assumed either too much background knowledge (e.g., measure theory and functional analysis) or too little (everything is a black box), and the information overload from often disjointed and contradictory internet sources made it more difficult for students to gradually build up their knowledge and understanding. We therefore wanted to write a book about data science and machine learning that can be read as a linear story,with a substantial “backstory” in the appendices. When we taught these courses, we noticed that students were eager to learn not only how to apply algorithms but also to understand how these algorithms actually work. However,many existing textbooks assumed either too much background knowledge (e.g., measure theory and functional analysis) or too little (everything is a black box), and the information overload from often disjointed and contradictory internet sources made it more difficult for students to gradually build up their knowledge and understanding. We therefore wanted to write a book about data science and machine learning that can be read as a linear story,with a substantial “backstory” in the appendices.Having business knowledge of the problem you are solving is very important. Why because one needs to have proper knowledge, ask relevant questions & ask appropriate questions.Supervised learning, as the name indicates, has the presence of a supervisor as a teacher.Basically supervised learning is when we teach or train the machine using data that is well labelled. Which means some data is already tagged with the correct answer. After that, the machine is provided with a new set of examples(data) so that the supervised learning algorithm analyses the training data(set of training examples) and produces a correct outcome from labelled data.Both Supervised and unsupervised learning systems differ in the nature of the training data.Supervised learning requires labeled training data, whereas,unsupervised learning system, is provided with unlabeled data and discovers the trends that are present.Unsupervised learning is the training of a machine using information that is neither classified nor labeled and allowing the algorithm to act on that information without guidance. Here the task of the machine is to group unsorted information according to similarities, patterns, and differences without any prior training of data. 
Unlike supervised learning, no teacher is provided that means no training will be given to the machine.Therefore the machine is restricted to find the hidden structure in unlabeled data by itself.For instance, suppose it is given an image having both dogs and cats which it has never seen. (Logistic Regression) In a logistic regression regression or logit model, we assume that the response variables Y1, . . . , Yn are independent and distributed according to logistic β)), where h here is defined as the cdf of the logistic distribution.Logistic regression is a form of predictive analysis.Logistic regression measures the relationship between the dependent variable (our label of what we want to predict) and one or more independent variables (our features) by estimating probability using its underlying logistic function (sigmoid).The data mining tutorial provides basic and advanced concepts of data mining. Our data mining tutorial is designed for learners and experts.Data mining is one of the most useful techniques that help entrepreneurs, researchers, and individuals to extract valuable information from huge sets of data. Data mining is also called Knowledge Discovery in Database (KDD).The knowledge discovery process includes Data cleaning, Data integration, Data selection, Data transformation, Data mining, Pattern evaluation, and Knowledge presentation.Data is new oil in the present day.Gather data and fix the inconsistencies within the data & handle the missing values.Data exploration is the first step of data analysis used to explore and visualize data to uncover insights from the start or identify areas or patterns to dig into more.
Using interactive dashboards and point-and-click data exploration, users can better understand the bigger picture and get to insights faster.In general, Data Exploration means "Define Data,understand the problem statement and Data".This step will really help in fetching great insights.We can even visualize, to get more insights easily.Feature engineering is a machine learning technique that leverages data to create new variables that aren’t in the training set. It can produce new features for both supervised and unsupervised learning, with the goal of simplifying and speeding up data transformations while also enhancing model accuracy. Feature engineering is required when working with machine learning models. Regardless of the data or architecture, a terrible feature will have a direct impact on your model.
Now to understand it in a much easier way, let’s take a simple example. Below are the prices of properties in x city.It shows the area of the house and total price.Select important features and construct more meaningful features from the raw data that we agthered.Examples of predictive modeling include estimating the quality of a sales lead, the likelihood of spam or the probability someone will click a link or buy a product. These capabilities are often baked into various business applications, so it is worth understanding the mechanics of predictive modeling to troubleshoot and improve performance.
Although predictive modeling implies a focus on forecasting the future, it can also predict outcomes (e.g., the probability a transaction is fraudulent). In this case, the event has already happened (fraud committed). The goal here is to predict whether future analysis will find the transaction is fraudulent. Predictive modeling can also forecast future requirements or facilitate what-if analysis.
"Predictive modeling is a form of data mining that analyzes historical data with the goal of identifying trends or patterns and then using those insights to predict future outcomes," explained Donncha Carroll a partner in the revenue growth practice of Axiom Consulting Partners. "Essentially, it asks the question,Predictive Modeling means " Train machine learning models, evaluate their performance and use them to make predictions".
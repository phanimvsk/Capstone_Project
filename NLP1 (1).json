{
  "data": [
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What is language expert dose in NLP?\n",
              "id": 544575,
              "answers": [
                {
                  "answer_id": 632055,
                  "document_id": 1144856,
                  "question_id": 544575,
                  "text": " this is what a language expert doses, language experts knows various language situations and produces rules for them. Noun .phrase going to noun, noun phrase going to adjective and noun these are actually rules expressing language phenomenon. ",
                  "answer_start": 3840,
                  "answer_end": 4084,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are the two main kinds of machine learning in ambiguity?give examples?",
              "id": 544658,
              "answers": [
                {
                  "answer_id": 633810,
                  "document_id": 1144856,
                  "question_id": 544658,
                  "text": " These are 2 main tasks of machine learning, in machine learning when we talk about classification we say that entities are given class labels. For example, the objects in this class room can be given different levels depending on what these entities are. For example, I am sitting on a chair the entity on which I am sitting as been given the level of chair, the object in front of me is a table. So, this entity is given the level of table. So, in classification we have entities and we give them labels how does how does it apply to the situation in front of us namely the ambiguity",
                  "answer_start": 9317,
                  "answer_end": 9902,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are all the possible cues which have been described in different languages?",
              "id": 544685,
              "answers": [
                {
                  "answer_id": 633897,
                  "document_id": 1144856,
                  "question_id": 544685,
                  "text": " For English position is the cue or the clue for this ambiguities for Indian languages or nouns these are the case markers and for verbs it is a morphological suffices. . These are the cues proceeding ahead we consider this cues or clues as very critical for our classification task or the disambiguation task. Cues are like attribute value pairs and we can make use of this attribute values of pairs for the installing for launching machine learning algorithm on the natural language data.",
                  "answer_start": 17860,
                  "answer_end": 18350,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are the two kinds of machine learning in statistical approach?",
              "id": 544657,
              "answers": [
                {
                  "answer_id": 633801,
                  "document_id": 1144856,
                  "question_id": 544657,
                  "text": " Statistical natural language processing would admin it that there is ambiguity, but would like to state that this ambiguity is coming from the uncertainty in classification. One the important tasks of machine learning is classification there are 2 to there are 2 different kinds of machine learning, one is classification the other is class telling.",
                  "answer_start": 8967,
                  "answer_end": 9317,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How the classigications are involved in level of gerund on visiting?",
              "id": 544659,
              "answers": [
                {
                  "answer_id": 633838,
                  "document_id": 1144856,
                  "question_id": 544659,
                  "text": " visiting aunts can be nuisance we can give a label of adjective on visiting or the other level of gerund on visiting. These will make the word belong to one or the other class; it can either belong to the adjective class or to the class gerund. So, this is a classification problem and this classification is a class is un result whether or gerund is unresolved. Similarly, the role of aunt is the entity and the classification for these is agent or object, again we are talking of 2 levels agent and object and the role of aunt will be long to one of these 2 classes’ agent or object. Now this is a nice point of view, because we are making use of machine learning paradigm",
                  "answer_start": 9935,
                  "answer_end": 10610,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is the meaning of ambiguity in machine learning?",
              "id": 544660,
              "answers": [
                {
                  "answer_id": 633839,
                  "document_id": 1144856,
                  "question_id": 544660,
                  "text": "We are making use of the terminology of machine learning and saying that ambiguity is nothing but uncertainty in classification and this ambiguity is resolved by making use of cues from the sentence. ",
                  "answer_start": 10612,
                  "answer_end": 10812,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Who produces annotation?",
              "id": 544755,
              "answers": [
                {
                  "answer_id": 634095,
                  "document_id": 1144856,
                  "question_id": 544755,
                  "text": "When annotation is done it is done by human beings people who understand the language and the people who understand the meaning of the words. So, as a human being I produced N on people, I produce V on laugh, I produce A on heartily with the understanding that these words have noun role, verb role and adverb role respectively.",
                  "answer_start": 24723,
                  "answer_end": 25051,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How are the 2 views are different from each other in NLP?explain?",
              "id": 544560,
              "answers": [
                {
                  "answer_id": 631932,
                  "document_id": 1144856,
                  "question_id": 544560,
                  "text": "the difference between these 2 views. Why is that that there are 2 views of natural language processing? There are 2 predominant approaches the first approach is the classical approach we have seen many different stages of natural language processing namely phonetics, phonology, and so on, at every stage there are ambiguities which have been discussed extensively. In classical view of natural language processing, the owners of processing is on human beings. In this view a machine essentially executes the instructions given by a human being. ",
                  "answer_start": 538,
                  "answer_end": 1085,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "what are different types of views in NLP?",
              "id": 544559,
              "answers": [
                {
                  "answer_id": 631901,
                  "document_id": 1144856,
                  "question_id": 544559,
                  "text": " 2 views of language technology. Let us look at the presentation this slide, and what we see here is that there are 2 views of natural language processing. . The first view is classical view, layered processing, and various ambiguities which we have been discussing over last few lectures a last 3 lectures actually, and the other very predominant view is statistical or machine learning view",
                  "answer_start": 105,
                  "answer_end": 497,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How the classification done in machine learning give an example?",
              "id": 544661,
              "answers": [
                {
                  "answer_id": 633840,
                  "document_id": 1144856,
                  "question_id": 544661,
                  "text": " Proceeding further we ask what kind of cues is available to resolve this ambiguity. When we do classification in machine learning we work on what is called the features of the entities we classify the entity depending on the features. For example, a chair is classified as a chair based on features like it as four legs, there is back rest, and there is an area where the person sits and so on.",
                  "answer_start": 10814,
                  "answer_end": 11209,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are the different stages in NLP?",
              "id": 544561,
              "answers": [
                {
                  "answer_id": 631957,
                  "document_id": 1144856,
                  "question_id": 544561,
                  "text": " The first stage was Phonetics and Phonology and then came Morphology, Lexical analysis, Syntactic analysis, Semantic analysis, Pragmatics and Discourse",
                  "answer_start": 1188,
                  "answer_end": 1340,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Explain how the object and agent are used in a sentence of position of the word?",
              "id": 544663,
              "answers": [
                {
                  "answer_id": 633853,
                  "document_id": 1144856,
                  "question_id": 544663,
                  "text": "one of the cues especially for English sentences is the position of the word with respect to a verb. So, if we take the sentence France, beat, Brazil in again then France is to the left of the beat and Brazil is the right. .So, this tells us that France is the agent and Brazil is the object. This is off course discounting the possibility that the sentence could be a passive voice sentence and the entity to the left of the verb could be an object. So, Brazil was beaten by France in this case Brazil is object even though it is to the left of the beat. However when not considering that particular fact we are considering normal active voice sentence France is to the left of beat and Brazil is to the right. So, therefore, there is no ambiguity classification France is the agent Brazil is the object. So, agent object marking in English is done by means of these very important cues namely the position of the gerund with respect to the verb left or right.",
                  "answer_start": 12020,
                  "answer_end": 12981,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Which sentence is very famous in NLP literature?",
              "id": 544758,
              "answers": [
                {
                  "answer_id": 634098,
                  "document_id": 1144856,
                  "question_id": 544758,
                  "text": " it is possible to have some meaningless pairing this very famous sentence from which has been made immortal in natural language processing. .. This sentence, colorless green ideas sleep furiously. This is a sentence which is very famous in N L P literature has lot of historic value. Now this sentence is change in many different ways, but one of those strange things about this sentence is this very unusual verb adverb combinations sleep and furiously. Sleep is a peaceful activity and furiously is a is an intense vigorous state and these 2 words are therefore, mutually incompatible. So, if you put sleep and furiously together it is a strange combination and people would raise eyebrows looking at this particular sentence. So, people laugh heartily was not a strange sentence we made use of all word knowledge and also knowledge of the language knowledge of the properties of the words. ",
                  "answer_start": 25370,
                  "answer_end": 26264,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Based on what features the classification happens in  disambiguition?",
              "id": 544662,
              "answers": [
                {
                  "answer_id": 633845,
                  "document_id": 1144856,
                  "question_id": 544662,
                  "text": ", there are features some features are distinguishing for that particular entity other features may be common with other entities. For example, the back rest is a critical feature for the chair to be a chair the entity must have a back rest. So, by looking at this kind of features we identify the object or the entity and we give it a class label. So, features can produce our decision so we understand that the classification happen by making use of the features. And the features actually come from the sentence itself and the sentence contains the tokens or the words. So, these words and token are used as cues let us look at the slide and we try to investigate what cues are used for disambiguation. ",
                  "answer_start": 11310,
                  "answer_end": 12016,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are the various constituents of machne learning tasks?",
              "id": 544690,
              "answers": [
                {
                  "answer_id": 633898,
                  "document_id": 1144856,
                  "question_id": 544690,
                  "text": " the various constituents of machine learning tasks, any machine learning task first has to specify what the goal of the task is does it belong to classification or is it a clustering kind of task? Then we have to clearly demarcate the features and the attributes for example, in natural language the feature should be word position the morphology word label that means the word category noun verb etcetera. The actual values of these features for example, for what position it could be the left or the right position with respect to the word the value of the morphological feature could be a particular suffix. For example, [FL] for past tense in the word label or word category the value for that could be noun, verb, etcetera. Then having look at this three features we take the next most important constituent which is the training data, the corpus or the electronic text which is annotated or an .annotated will explain annotation or an annotation in a minute. These forms an important constituent then there is this test data the test corpus which is important for evaluation the machine learning algorithm.",
                  "answer_start": 18368,
                  "answer_end": 19481,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How the human beings are involved in creating NLP?Explain with an example?",
              "id": 544563,
              "answers": [
                {
                  "answer_id": 631993,
                  "document_id": 1144856,
                  "question_id": 544563,
                  "text": " there are human beings involved who create rules guided by linguistics, lexicography, and knowledge of language and so on which makes the machine process natural language data or information. Just to take an example, if we take the example of syntactic analysis, where one needs to phrase a sentence what happens is that? A linear structure is given, a sentence is given and from the sentence we obtain a tree corresponding to the sentence. We identify the noun phrase and verb phrase within the verb phrase we find out the verb and so on. This whole processing happens by means of grammatical rules which a human being has encoded somebody who understands the language well has shut down and produced the grammatical rules.",
                  "answer_start": 1366,
                  "answer_end": 2091,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How are cues used in Indian language?",
              "id": 544665,
              "answers": [
                {
                  "answer_id": 633865,
                  "document_id": 1144856,
                  "question_id": 544665,
                  "text": "In Indian languages and many other languages of the world were the world order is relatively free we have to make use of some other cues. So, France, beat, Brazil in the football game in this case France and Brazil have fixed positions in English language, but for an Indian language these need not be the case. ",
                  "answer_start": 12982,
                  "answer_end": 13294,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is annotation in NLP?Give an example?",
              "id": 544693,
              "answers": [
                {
                  "answer_id": 633901,
                  "document_id": 1144856,
                  "question_id": 544693,
                  "text": ". Annotation is very critical for statistical natural language processing types on annotation so we illustrate annotation means labeling producing labels. Let me give an example of this suppose we have the sentence people laugh heartily. They may be laughing at a joke or a particular situation people laugh heartily so there are 3 words. Our corpus now is 3 words long on these if you produce annotation can be of many different kinds. .. So, let us first do the simplest possible annotation. Simplest annotation, part of speech label annotation we said is a labeling task we are doing part of speech label. So, people laugh heartily we produce the following annotation we say that this is a noun underscore noun, this is a verb underscore verb, and this an adverb let say we produce a very character A. So, N is noun, V is verb, A is adverb so what we have done we have annotated our corpora people laugh heartily with the labels N V A respectively. This is simplest kind of annotation the part of speech annotation.",
                  "answer_start": 19989,
                  "answer_end": 21007,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Who are the complete owners of the NLP? what is the role in NLP?",
              "id": 544584,
              "answers": [
                {
                  "answer_id": 632131,
                  "document_id": 1144856,
                  "question_id": 544584,
                  "text": " in classical view of natural language processing the complete owners or the burden is on this kind of rules which are created by human beings, this was the scenario in natural language processing. Rules and knowledge come from human beings the advent of wave change the scenario in a very dramatic way.",
                  "answer_start": 4087,
                  "answer_end": 4390,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Rules governed and are given by whom?",
              "id": 544646,
              "answers": [
                {
                  "answer_id": 633721,
                  "document_id": 1144856,
                  "question_id": 544646,
                  "text": " in detail which is completely rule governed and rules are given by human beings these rules contain knowledge.",
                  "answer_start": 5594,
                  "answer_end": 5705,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are free word order languages in NLP?",
              "id": 544666,
              "answers": [
                {
                  "answer_id": 633880,
                  "document_id": 1144856,
                  "question_id": 544666,
                  "text": "suppose we take this sentence France, beat, Brazil the Hindi sentence should be France [FL] Brazil [FL], but you can also write Brazil [FL] France [FL]. So, the same meaning is conveyed by these 2 different orders France [FL] Brazil [FL], Brazil [FL] France [FL]. Whereas for English the order is fixed France, beat, Brazil, if you change the order Brazil, beat, France then the meaning also gets changed, not so in case of in .this sentence, not so in this case many Indian language sentences, France [FL] Brazil [FL], Brazil [FL] France [FL]. These kind of languages were the word order can be changed are called free word order languages. ",
                  "answer_start": 13366,
                  "answer_end": 14008,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is a semantic annotation?",
              "id": 544694,
              "answers": [
                {
                  "answer_id": 633902,
                  "document_id": 1144856,
                  "question_id": 544694,
                  "text": "what could be a more complex annotation? . .More complex annotation we say that people now we will produce the annotation below the words. Because we are creating more complex annotation people laugh heartily, so in this case people is a noun we can say takes S for plural these an annotation animate this is a semantic annotation. ",
                  "answer_start": 21056,
                  "answer_end": 21388,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are used in evaluating the algorithm in NLP?",
              "id": 544761,
              "answers": [
                {
                  "answer_id": 634101,
                  "document_id": 1144856,
                  "question_id": 544761,
                  "text": "Training data where the corpus is marked with different levels of training test data, the test corpus or the test text which are used for evaluating the algorithm. And there are accuracy of the classification in the form of precision, recall, F valve, MAP Score and test of significance. We will have occasion to explain precision and recall which I will do after some time. .. Now let us understand the output of machine learning N L P system. ",
                  "answer_start": 26623,
                  "answer_end": 27068,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Explain about the grammetical role in NLP using an example.",
              "id": 544565,
              "answers": [
                {
                  "answer_id": 632024,
                  "document_id": 1144856,
                  "question_id": 544565,
                  "text": "when this grammar is written, the person producing this grammar has to anticipate all possible language phenomenon which exits in that language, and try to capture them in turns of grammatical rules. So, let me show you an example of a grammatical role by writing it on the paper. .. So, suppose I say that in noun phrase N P, this is the symbol for a noun phrase N P goes to a noun. So, that means a noun phrase can be expressed by a single noun or a noun phrase can be an adjective and a noun.",
                  "answer_start": 2097,
                  "answer_end": 2592,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "In second view which approach is used in NLP?",
              "id": 544647,
              "answers": [
                {
                  "answer_id": 633731,
                  "document_id": 1144856,
                  "question_id": 544647,
                  "text": " the second approach is the possibility of using statistical or machine learning approach to uncover these rules and regularities underlying the CORPUS or the electronic text.",
                  "answer_start": 5709,
                  "answer_end": 5884,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is the output we get from this machine learning system in NLP.",
              "id": 544762,
              "answers": [
                {
                  "answer_id": 634102,
                  "document_id": 1144856,
                  "question_id": 544762,
                  "text": "The first option is we could get a set of rules, so the rule can be in this form if the word to the left of the word is a noun. And has animacy feature that means the noun is animate then it is the likely agent of the action denoted by the verb. So, since people the word people was to the left of the word laugh and people is also animate that it is very likely the agent of the action denoted by the verb namely laugh. So, taking more examples the child broke the toy here child is the agent because child is to the left of break and it is also animate",
                  "answer_start": 27379,
                  "answer_end": 27933,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Further which approach is used in NLP? ",
              "id": 544648,
              "answers": [
                {
                  "answer_id": 633739,
                  "document_id": 1144856,
                  "question_id": 544648,
                  "text": "further, we find that there are stages of natural language processing and everywhere one could make use of either the classical approach natural language processing or one could make use of statistical techniques the data driven approach to do natural language processing.",
                  "answer_start": 5998,
                  "answer_end": 6270,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is the particular factor involved in free order languages?",
              "id": 544668,
              "answers": [
                {
                  "answer_id": 633889,
                  "document_id": 1144856,
                  "question_id": 544668,
                  "text": "Notice that France beat Brazil there were no other language particles in this sentence only those entities which are actors in these situation. France and Brazil are the actors in this situation France is the agent, Brazil is the object, beat is the activity there is a beat activity in this. ",
                  "answer_start": 14239,
                  "answer_end": 14532,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is the difference between the classical NLP and statistical NLP?",
              "id": 544763,
              "answers": [
                {
                  "answer_id": 634103,
                  "document_id": 1144856,
                  "question_id": 544763,
                  "text": "we obtain the rules and these rules are embedded in the computer the rules come from the linguist, who is the human being. In statistical N L P this rules are the probabilities they come from the textual data namely the corpus and the machine works with those rules. So, in both cases there are rules and it could also probability values, but classical N L P they come from human beings and in statistical N L P they come from textual data by means of machine leaning algorithm.",
                  "answer_start": 29385,
                  "answer_end": 29863,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Hpw morphology works in NLP?",
              "id": 544649,
              "answers": [
                {
                  "answer_id": 633752,
                  "document_id": 1144856,
                  "question_id": 544649,
                  "text": " morphology, we discussed syntactic analysis some time back if we discuss morphology. Now morphological rules are driven given by language experts, but there are lines of work where different word forms are given. And from the word forms one identifies the suffixes and tries to uncover the rules which govern morphology. So, it is possible to create a morphology analyzer by making use of word forms and these word forms can be processed by machine language techniques for creating a morphology analyzer.",
                  "answer_start": 6295,
                  "answer_end": 6800,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Mention some of the stages used in these 2 approaches?",
              "id": 544650,
              "answers": [
                {
                  "answer_id": 633762,
                  "document_id": 1144856,
                  "question_id": 544650,
                  "text": " all the stages that we have discussed morphology, lexica analysis, syntactic analysis, semantic analysis, pragmatics, and discourse everywhere one can make use of these 2 approaches.",
                  "answer_start": 6804,
                  "answer_end": 6987,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Using object and agent, how indian language is different from free order languages?",
              "id": 544670,
              "answers": [
                {
                  "answer_id": 633891,
                  "document_id": 1144856,
                  "question_id": 544670,
                  "text": "When we come to Indian languages the actors are same, but there expression in the sentence are done with the mediation of other language particles there is this [FL] which is coming after France there is this [FL] which is coming after Brazil. This [FL] and [FL] has language particles are critical for the meaning of the sentence. [FL] shows France is the agent [FL] shows Brazil is the object since [FL] and [FL] have this very crucial role to play. They can be moved along with the nouns without changing the meaning of the sentence. Now since [FL] is the agent indicator the position is now less importance, if u carry [FL] with France then u know that France is agent if u carry [FL] with Brazil you know Brazil is the object. So, a just pay some attention to this point this is a very crucial point in the English sentence France beat Brazil the, who is the agent? who is the object? This information is encoded in the position of the nouns. Noun is to the left of beat Brazil is to the right of beat and that shows who the agent is and who the object is.",
                  "answer_start": 14532,
                  "answer_end": 15593,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How can a very large textual entity is produced?",
              "id": 544698,
              "answers": [
                {
                  "answer_id": 633906,
                  "document_id": 1144856,
                  "question_id": 544698,
                  "text": "We start with words of a language the words of a text or sentence, so these words are placed one after the other to produce a meaningful sentence, sentences are produced one after the other to produce a meaningful paragraphs. Paragraphs are produced one after the other to produce meaningful chapters; chapters form a book and so on. So, gradually from words we go on building bigger and bigger textual units and ultimately produce a very large textual entity.",
                  "answer_start": 23186,
                  "answer_end": 23646,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is text in NLP? why it is available ?how can it be processed?",
              "id": 544589,
              "answers": [
                {
                  "answer_id": 632170,
                  "document_id": 1144856,
                  "question_id": 544589,
                  "text": "Because of the internet a large amount of text in electronic form became available on the web and this text also can be processed by a machine. So, machine process able text in large volume became available. And this kind of text was a very reach repository gold minds are to say of language phenomena. Now, here was a possibility were these language or text could be processed by a machine. And the regularities in the language or the constrains could be uncovered from this text.",
                  "answer_start": 4391,
                  "answer_end": 4872,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is the role of sementic information in Indian languages?",
              "id": 544671,
              "answers": [
                {
                  "answer_id": 633892,
                  "document_id": 1144856,
                  "question_id": 544671,
                  "text": "you cannot take liberty with the position of the nouns otherwise the agent and object roles are disturbed and that disturbs the meaning of the sentence. In case of Indian language sentences in particular Hindi here the agent and object information are indicated by [FL] and [FL]. So, these make the position information redundant and therefore, we can play with the order of the words. So, I hope this point is clear to you in English position encodes semantic role information in Indian languages case markers typically encode the semantic role information.",
                  "answer_start": 15598,
                  "answer_end": 16156,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Explain how Noun phrase is used in the NLP with an example in all possible situations?",
              "id": 544570,
              "answers": [
                {
                  "answer_id": 632036,
                  "document_id": 1144856,
                  "question_id": 544570,
                  "text": " noun phrase going to noun could be boy, noun phrase going to be adjective and noun could be a little boy. Noun phrase can also go to noun and preposition phrase for example, boy with toys. So, all these are noun phrases let us look at the lines once again noun phrase can be noun. For example, boy noun phrase can be adjective and noun little boy, noun phrase can be a noun with a preposition phase boy with toys. Preposition phase again can be expanded as a preposition P and a noun phrase coming after that. So, preposition again can be preposition phase can be P at N P that means preposition at noun phrase and P in turn can be things like with, by, in, for and so on. So, you can see what I wanted to give a grammar for a noun phrase. So, what are the possibilities of a noun phrase, noun phrase can be a single noun, noun phrase can be an adjective and noun, noun phrase can be noun followed by a preposition phrase. Preposition phase on the other hand is preposition followed by a noun phrase, preposition can be with, by, in, for and so on. So these shows that to capture a language phenomenon and to give its grammar, we need to anticipate all possible situations we have to understand all possible situations.",
                  "answer_start": 2615,
                  "answer_end": 3835,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What could be the data driven machine learning based approach to ambiguity resolution?",
              "id": 544652,
              "answers": [
                {
                  "answer_id": 633765,
                  "document_id": 1144856,
                  "question_id": 544652,
                  "text": "If we see this sentence here visiting aunts can be a nuisance this is an ambiguity sentence. Let us understand the ambiguity in this was discussed before I just repeat what the ambiguity is, the word visiting can be an adjective or it could be a gerund the ing from of a verb which is gerund. And this ambiguity can be caught at the part of speech tagging level and this ambiguity may or may not be resolved, but ambiguity is really the part of speech ambiguity.",
                  "answer_start": 7119,
                  "answer_end": 7581,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is the technical name for the text in NLP?",
              "id": 544591,
              "answers": [
                {
                  "answer_id": 632177,
                  "document_id": 1144856,
                  "question_id": 544591,
                  "text": " There is a technical name for the text let me write it down, the technical name for text is CORPUS I write in an very bold font and large font, because corpus is highly important very important in N L P in natural language processing. ",
                  "answer_start": 4872,
                  "answer_end": 5108,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is the second ambiguity in NLP?",
              "id": 544653,
              "answers": [
                {
                  "answer_id": 633769,
                  "document_id": 1144856,
                  "question_id": 544653,
                  "text": " the second ambiguity comes from the role of aunt. Visiting aunts can be nuisance; the question is who the agent of visiting is? The agent of visiting can be aunts are the visitors or the agent of visiting can be the speaker himself or herself. The speaker is complaining that visiting aunts can be nuisance the speaker does not want to visit aunts in which case if the speaker is the agent then the object of visit is aunts. ",
                  "answer_start": 7621,
                  "answer_end": 8047,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is the term case marker means in Indian languages?",
              "id": 544673,
              "answers": [
                {
                  "answer_id": 633894,
                  "document_id": 1144856,
                  "question_id": 544673,
                  "text": "The term is called case marker also called [FL] in Indian languages. This came from Sanskrit tradition [FL] so in a Indian languages case marker or [FL] carry the semantic role information. ",
                  "answer_start": 16248,
                  "answer_end": 16438,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are aunts in NLP?",
              "id": 544654,
              "answers": [
                {
                  "answer_id": 633771,
                  "document_id": 1144856,
                  "question_id": 544654,
                  "text": " aunts are either objects of visit or agent of visit, so we have what is called the semantic role ambiguity aunt can be agent of visit or object of visit.",
                  "answer_start": 8050,
                  "answer_end": 8204,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "In Marathi how the case marker is involved.",
              "id": 544674,
              "answers": [
                {
                  "answer_id": 633895,
                  "document_id": 1144856,
                  "question_id": 544674,
                  "text": "In Marathi also you can use the same case for the particular [FL] that indicates the agent is role Brazil [FL] in Hindi Marathi Brazil [FL]. So, this shows the object role thus the ambiguity is resolved by means of case marker it. We can also see that in Indian languages morphology can do disambiguation France beat Brazil in this case the word beat has ambiguity, because beat can be a noun. For example, heart beat for heart beat is a noun France beat Brazil beat is a verb these ambiguity does not exist for Indian language.",
                  "answer_start": 16738,
                  "answer_end": 17266,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What happens when we have CORPUS in NLP?",
              "id": 544593,
              "answers": [
                {
                  "answer_id": 632203,
                  "document_id": 1144856,
                  "question_id": 544593,
                  "text": "So, when we have CORPUS in electronic form large amount of text in electronic form we can apply what is called machine learning algorithms, machine learning text techniques on these data? And understand that there are regularities which are waiting to be uncovered and which can then be used for natural language processing. ",
                  "answer_start": 5108,
                  "answer_end": 5433,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Explain about aunts visiting in NLP?",
              "id": 544655,
              "answers": [
                {
                  "answer_id": 633777,
                  "document_id": 1144856,
                  "question_id": 544655,
                  "text": "if that is the case if aunts are visiting, if aunts are the visitors then visiting becomes an adjective what kind of aunts? Who are visiting, so these are visiting aunts and if aunts are being visited if the speaker is visiting the aunt? Then visiting is adjutant it is a verb and it is denoting the act of visiting. So, we can trace the ambiguity of this sentence as either visiting being an adjective or a gerund and also role of aunt being ambiguous. .Depending on this ambiguity these sentence as 2 meanings whether aunts are being visited or aunts themselves are visiting.",
                  "answer_start": 8209,
                  "answer_end": 8786,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Whera the ambiguity comes from?",
              "id": 544656,
              "answers": [
                {
                  "answer_id": 633787,
                  "document_id": 1144856,
                  "question_id": 544656,
                  "text": "this ambiguity the classical view of this ambiguity is that these ambiguity exits and the ambiguity come from different Symantec roles nod different part of speech of visiting.",
                  "answer_start": 8791,
                  "answer_end": 8967,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "Mod-01 Lec-04 Two approaches to NLP\n\nThis is lecture 4 on natural language processing; we will talk about 2 views of language technology. Let us look at the presentation this slide, and what we see here is that there are 2 views of natural language processing. . The first view is classical view, layered processing, and various ambiguities which we have been discussing over last few lectures a last 3 lectures actually, and the other very predominant view is statistical or machine learning view. Let us spend some time on understating the difference between these 2 views. Why is that that there are 2 views of natural language processing? There are 2 predominant approaches the first approach is the classical approach we have seen many different stages of natural language processing namely phonetics, phonology, and so on, at every stage there are ambiguities which have been discussed extensively. In classical view of natural language processing, the owners of processing is on human beings. In this view a machine essentially executes the instructions given by a human being. .. Let us look at this slide and remember what we saw on various stages of natural language processing. The first stage was Phonetics and Phonology and then came Morphology, Lexical analysis, Syntactic analysis, Semantic analysis, Pragmatics and Discourse. In each of these stages, there are human beings involved who create rules guided by linguistics, lexicography, and knowledge of language and so on which makes the machine process natural language data or information. Just to take an example, if we take the example of syntactic analysis, where one needs to phrase a sentence what happens is that? A linear structure is given, a sentence is given and from the sentence we obtain a tree corresponding to the sentence. We identify the noun phrase and verb phrase within the verb phrase we find out the verb and so on. This whole processing happens by means of grammatical rules which a human being has encoded somebody who understands the language well has shut down and produced the grammatical rules. Now, when this grammar is written, the person producing this grammar has to anticipate all possible language phenomenon which exits in that language, and try to capture them in turns of grammatical rules. So, let me show you an example of a grammatical role by writing it on the paper. .. So, suppose I say that in noun phrase N P, this is the symbol for a noun phrase N P goes to a noun. So, that means a noun phrase can be expressed by a single noun or a noun phrase can be an adjective and a noun. Let me give an example noun phrase going to noun could be boy, noun phrase going to be adjective and noun could be a little boy. Noun phrase can also go to noun and preposition phrase for example, boy with toys. So, all these are noun phrases let us look at the lines once again noun phrase can be noun. For example, boy noun phrase can be adjective and noun little boy, noun phrase can be a noun with a preposition phase boy with toys. Preposition phase again can be expanded as a preposition P and a noun phrase coming after that. So, preposition again can be preposition phase can be P at N P that means preposition at noun phrase and P in turn can be things like with, by, in, for and so on. So, you can see what I wanted to give a grammar for a noun phrase. So, what are the possibilities of a noun phrase, noun phrase can be a single noun, noun phrase can be an adjective and noun, noun phrase can be noun followed by a preposition phrase. Preposition phase on the other hand is preposition followed by a noun phrase, preposition can be with, by, in, for and so on. So these shows that to capture a language phenomenon and to give its grammar, we need to anticipate all possible situations we have to understand all possible situations. Now, this is what a language expert doses, language experts knows various language situations and produces rules for them. Noun .phrase going to noun, noun phrase going to adjective and noun these are actually rules expressing language phenomenon. So, in classical view of natural language processing the complete owners or the burden is on this kind of rules which are created by human beings, this was the scenario in natural language processing. Rules and knowledge come from human beings the advent of wave change the scenario in a very dramatic way. Because of the internet a large amount of text in electronic form became available on the web and this text also can be processed by a machine. So, machine process able text in large volume became available. And this kind of text was a very reach repository gold minds are to say of language phenomena. Now, here was a possibility were these language or text could be processed by a machine. And the regularities in the language or the constrains could be uncovered from this text. There is a technical name for the text let me write it down, the technical name for text is CORPUS I write in an very bold font and large font, because corpus is highly important very important in N L P in natural language processing. So, when we have CORPUS in electronic form large amount of text in electronic form we can apply what is called machine learning algorithms, machine learning text techniques on these data? And understand that there are regularities which are waiting to be uncovered and which can then be used for natural language processing. So, going back to our transparencies what we said was there are these 2 views of natural language processing the classical view, classical we have explained. Now in detail which is completely rule governed and rules are given by human beings these rules contain knowledge. And the second approach is the possibility of using statistical or machine learning approach to uncover these rules and regularities underlying the CORPUS or the electronic text. And those rules and regularities can be discovered and used later for natural language processing. .. Proceeding further, we find that there are stages of natural language processing and everywhere one could make use of either the classical approach natural language processing or one could make use of statistical techniques the data driven approach to do natural language processing. For example, if you take morphology, we discussed syntactic analysis some time back if we discuss morphology. Now morphological rules are driven given by language experts, but there are lines of work where different word forms are given. And from the word forms one identifies the suffixes and tries to uncover the rules which govern morphology. So, it is possible to create a morphology analyzer by making use of word forms and these word forms can be processed by machine language techniques for creating a morphology analyzer. So, all the stages that we have discussed morphology, lexica analysis, syntactic analysis, semantic analysis, pragmatics, and discourse everywhere one can make use of these 2 approaches. .. Let us look at the problem of ambiguity, what could be the data driven machine learning based approach to ambiguity resolution? If we see this sentence here visiting aunts can be a nuisance this is an ambiguity sentence. Let us understand the ambiguity in this was discussed before I just repeat what the ambiguity is, the word visiting can be an adjective or it could be a gerund the ing from of a verb which is gerund. And this ambiguity can be caught at the part of speech tagging level and this ambiguity may or may not be resolved, but ambiguity is really the part of speech ambiguity. So, this is the first ambiguous entity, the second ambiguity comes from the role of aunt. Visiting aunts can be nuisance; the question is who the agent of visiting is? The agent of visiting can be aunts are the visitors or the agent of visiting can be the speaker himself or herself. The speaker is complaining that visiting aunts can be nuisance the speaker does not want to visit aunts in which case if the speaker is the agent then the object of visit is aunts. So, aunts are either objects of visit or agent of visit, so we have what is called the semantic role ambiguity aunt can be agent of visit or object of visit. So, if that is the case if aunts are visiting, if aunts are the visitors then visiting becomes an adjective what kind of aunts? Who are visiting, so these are visiting aunts and if aunts are being visited if the speaker is visiting the aunt? Then visiting is adjutant it is a verb and it is denoting the act of visiting. So, we can trace the ambiguity of this sentence as either visiting being an adjective or a gerund and also role of aunt being ambiguous. .Depending on this ambiguity these sentence as 2 meanings whether aunts are being visited or aunts themselves are visiting. So, this ambiguity the classical view of this ambiguity is that these ambiguity exits and the ambiguity come from different Symantec roles nod different part of speech of visiting. Statistical natural language processing would admin it that there is ambiguity, but would like to state that this ambiguity is coming from the uncertainty in classification. One the important tasks of machine learning is classification there are 2 to there are 2 different kinds of machine learning, one is classification the other is class telling. These are 2 main tasks of machine learning, in machine learning when we talk about classification we say that entities are given class labels. For example, the objects in this class room can be given different levels depending on what these entities are. For example, I am sitting on a chair the entity on which I am sitting as been given the level of chair, the object in front of me is a table. So, this entity is given the level of table. So, in classification we have entities and we give them labels how does how does it apply to the situation in front of us namely the ambiguity? Looking at the slide once again visiting aunts can be nuisance we can give a label of adjective on visiting or the other level of gerund on visiting. These will make the word belong to one or the other class; it can either belong to the adjective class or to the class gerund. So, this is a classification problem and this classification is a class is un result whether or gerund is unresolved. Similarly, the role of aunt is the entity and the classification for these is agent or object, again we are talking of 2 levels agent and object and the role of aunt will be long to one of these 2 classes’ agent or object. Now this is a nice point of view, because we are making use of machine learning paradigm. We are making use of the terminology of machine learning and saying that ambiguity is nothing but uncertainty in classification and this ambiguity is resolved by making use of cues from the sentence. .. Proceeding further we ask what kind of cues is available to resolve this ambiguity. When we do classification in machine learning we work on what is called the features of the entities we classify the entity depending on the features. For example, a chair is classified as a chair based on features like it as four legs, there is back rest, and there is an area where the person sits and so on. If this entity does not have the back rest even if the person can sit on it is no longer a chair. So, there are features some features are distinguishing for that particular entity other features may be common with other entities. For example, the back rest is a critical feature for the chair to be a chair the entity must have a back rest. So, by looking at this kind of features we identify the object or the entity and we give it a class label. So, features can produce our decision so we understand that the classification happen by making use of the features. And the features actually come from the sentence itself and the sentence contains the tokens or the words. So, these words and token are used as cues let us look at the slide and we try to investigate what cues are used for disambiguation. So, one of the cues especially for English sentences is the position of the word with respect to a verb. So, if we take the sentence France, beat, Brazil in again then France is to the left of the beat and Brazil is the right. .So, this tells us that France is the agent and Brazil is the object. This is off course discounting the possibility that the sentence could be a passive voice sentence and the entity to the left of the verb could be an object. So, Brazil was beaten by France in this case Brazil is object even though it is to the left of the beat. However when not considering that particular fact we are considering normal active voice sentence France is to the left of beat and Brazil is to the right. So, therefore, there is no ambiguity classification France is the agent Brazil is the object. So, agent object marking in English is done by means of these very important cues namely the position of the gerund with respect to the verb left or right. In Indian languages and many other languages of the world were the world order is relatively free we have to make use of some other cues. So, France, beat, Brazil in the football game in this case France and Brazil have fixed positions in English language, but for an Indian language these need not be the case. Let us look at the Hindi sentence corresponding to this sentence. . So, suppose we take this sentence France, beat, Brazil the Hindi sentence should be France [FL] Brazil [FL], but you can also write Brazil [FL] France [FL]. So, the same meaning is conveyed by these 2 different orders France [FL] Brazil [FL], Brazil [FL] France [FL]. Whereas for English the order is fixed France, beat, Brazil, if you change the order Brazil, beat, France then the meaning also gets changed, not so in case of in .this sentence, not so in this case many Indian language sentences, France [FL] Brazil [FL], Brazil [FL] France [FL]. These kind of languages were the word order can be changed are called free word order languages. So, Indian languages are quit prominently free word order languages. But if you are designing if you are observing carefully then you can make out that this free word order came because of a particular factor what was that factor? Notice that France beat Brazil there were no other language particles in this sentence only those entities which are actors in these situation. France and Brazil are the actors in this situation France is the agent, Brazil is the object, beat is the activity there is a beat activity in this. When we come to Indian languages the actors are same, but there expression in the sentence are done with the mediation of other language particles there is this [FL] which is coming after France there is this [FL] which is coming after Brazil. This [FL] and [FL] has language particles are critical for the meaning of the sentence. [FL] shows France is the agent [FL] shows Brazil is the object since [FL] and [FL] have this very crucial role to play. They can be moved along with the nouns without changing the meaning of the sentence. Now since [FL] is the agent indicator the position is now less importance, if u carry [FL] with France then u know that France is agent if u carry [FL] with Brazil you know Brazil is the object. So, a just pay some attention to this point this is a very crucial point in the English sentence France beat Brazil the, who is the agent? who is the object? This information is encoded in the position of the nouns. Noun is to the left of beat Brazil is to the right of beat and that shows who the agent is and who the object is. So, you cannot take liberty with the position of the nouns otherwise the agent and object roles are disturbed and that disturbs the meaning of the sentence. In case of Indian language sentences in particular Hindi here the agent and object information are indicated by [FL] and [FL]. So, these make the position information redundant and therefore, we can play with the order of the words. So, I hope this point is clear to you in English position encodes semantic role information in Indian languages case markers typically encode the semantic role information. .. Let me write down a very important term for you, we have introduced this term just now. The term is called case marker also called [FL] in Indian languages. This came from Sanskrit tradition [FL] so in a Indian languages case marker or [FL] carry the semantic role information. So, that is it so we asked how is the classification solved classification problem solved, because classification problem needs to be solved to resolve the ambiguity. Here we find that for English sentence the cue was the position for Indian language sentence the case marker is the cue France [FL]. In Marathi also you can use the same case for the particular [FL] that indicates the agent is role Brazil [FL] in Hindi Marathi Brazil [FL]. So, this shows the object role thus the ambiguity is resolved by means of case marker it. We can also see that in Indian languages morphology can do disambiguation France beat Brazil in this case the word beat has ambiguity, because beat can be a noun. For example, heart beat for heart beat is a noun France beat Brazil beat is a verb these ambiguity does not exist for Indian language. Because for Indian language the Hindi sentence will be France [FL] Brazil [FL] [FL] [FL] this is a verb and this is a verb is simply shown by the fact that it takes the suffix [FL]. This [FL] is a past tense marker it is an indicator of past tense that gets attached to the root verb [FL] [FL] is to defeat or to beat and Marathi example is shown here [FL] [FL]. So, these suffixes show that this word is a verb it does not have to face the .ambiguity that English beat has become noun or verb. In Hindi there is no such ambiguity so let us recount all possible cues which have been described. For English position is the cue or the clue for this ambiguities for Indian languages or nouns these are the case markers and for verbs it is a morphological suffices. . These are the cues proceeding ahead we consider this cues or clues as very critical for our classification task or the disambiguation task. Cues are like attribute value pairs and we can make use of this attribute values of pairs for the installing for launching machine learning algorithm on the natural language data. Lets recount here the various constituents of machine learning tasks, any machine learning task first has to specify what the goal of the task is does it belong to classification or is it a clustering kind of task? Then we have to clearly demarcate the features and the attributes for example, in natural language the feature should be word position the morphology word label that means the word category noun verb etcetera. The actual values of these features for example, for what position it could be the left or the right position with respect to the word the value of the morphological feature could be a particular suffix. For example, [FL] for past tense in the word label or word category the value for that could be noun, verb, etcetera. Then having look at this three features we take the next most important constituent which is the training data, the corpus or the electronic text which is annotated or an .annotated will explain annotation or an annotation in a minute. These forms an important constituent then there is this test data the test corpus which is important for evaluation the machine learning algorithm. The accuracy of the of the learning situation that means the classification the accuracy is measured by means of precision recall F values map code etcetera which again will explain. And also mean times we perform what is called test of significance we go from a small sample space to a general class and that requires test of significance. Let me know describe a very important concept the concept of annotation. . Annotation we considered this word annotation. Let me describe annotation for a few minutes. Annotation is very critical for statistical natural language processing types on annotation so we illustrate annotation means labeling producing labels. Let me give an example of this suppose we have the sentence people laugh heartily. They may be laughing at a joke or a particular situation people laugh heartily so there are 3 words. Our corpus now is 3 words long on these if you produce annotation can be of many different kinds. .. So, let us first do the simplest possible annotation. Simplest annotation, part of speech label annotation we said is a labeling task we are doing part of speech label. So, people laugh heartily we produce the following annotation we say that this is a noun underscore noun, this is a verb underscore verb, and this an adverb let say we produce a very character A. So, N is noun, V is verb, A is adverb so what we have done we have annotated our corpora people laugh heartily with the labels N V A respectively. This is simplest kind of annotation the part of speech annotation. Let us do a little more complicated annotation, what could be a more complex annotation? . .More complex annotation we say that people now we will produce the annotation below the words. Because we are creating more complex annotation people laugh heartily, so in this case people is a noun we can say takes S for plural these an annotation animate this is a semantic annotation. So, people are a noun it takes s for plural it is animate it is also a collective noun. So, we have produced these four pieces of information for the word people noun takes S for plural animate collective noun. So, one could imagine many different kinds of annotation many different kinds of annotation and can enrich words with these kind of labels to make it a very informative text. Let us go to laugh is a verb all of us know that what more annotation can you produce this laugh takes e d for past tense this is N annotation laugh. It is a verb of state this is a verb of state that means when people are laughing they are at a particular state. As oppose to let us say verb of motion if you say people run speedily, instead of people laugh heartily people run speedily. In this case the word is run and the word run is a verb of motion the word run is a verb of motion, but when we say people laugh heartily people laugh heartily. So, when they are laughing they are in a particular state so it is a state verb so it is a verb indication a particular state. For heartily when you go to word when you go to the word heartily this is an adverb A produce a letter A for this is adverb of state. So, this is adverb of state we record all this annotation, we have produce 2 annotation marks for heartily 3 for laugh, 4 for people. Now adverbs we know can be of many different kinds adverb can be space adverbs of space, adverb of time adverb of manner, and so on. So, this particular adverb people laugh heartily it will be more correct to say this is an adverb of manner instead of adverb of sate we call it adverb of manner. So, this is the task of annotation and I hope your clear about what happens in annotation, let me summarize this particular point once again it is a very important point. We start with words of a language the words of a text or sentence, so these words are placed one after the other to produce a meaningful sentence, sentences are produced one after the other to produce a meaningful paragraphs. Paragraphs are produced one after the other to produce meaningful chapters; chapters form a book and so on. So, gradually from words we go on building bigger and bigger textual units and ultimately produce a very large textual entity. So, when these words are taken up for processing what we have in front of us is a raw piece of text. .This piece of text is meaningful to a human begins on a expert in the field somebody who has world knowledge, somebody who has a knowledge of language can see that these symbols having meaning not so for a machine. A machine may not be equipped with so much of world knowledge so much of expressive language a machine need annotation. So, when we have a taken 3 words people laugh heartily we had to produce labels on them saying that people is a noun, people is a collective noun, people is a animate. People takes s in the form of plural and all these and many other pieces of information can be put down on the text to enrich it, and these kind of enrichment of the text with labels is called annotation. So, I hope the notion of annotation is very clear to you, this is very critical for natural language processing you have to understand annotation very clearly. Let me make another point which is related to this and a part of great interest, who produces annotation? When annotation is done it is done by human beings people who understand the language and the people who understand the meaning of the words. So, as a human being I produced N on people, I produce V on laugh, I produce A on heartily with the understanding that these words have noun role, verb role and adverb role respectively. How did I know that people is a animate? That is the world knowledge part. As a human being who is a part of society we know people are animate entities and not only that there are more complex issues we know that this is a meaningful sentence this laugh and heartily form a meaningful verb, adverb pair. So, there are it is possible to have some meaningless pairing this very famous sentence from which has been made immortal in natural language processing. .. This sentence, colorless green ideas sleep furiously. This is a sentence which is very famous in N L P literature has lot of historic value. Now this sentence is change in many different ways, but one of those strange things about this sentence is this very unusual verb adverb combinations sleep and furiously. Sleep is a peaceful activity and furiously is a is an intense vigorous state and these 2 words are therefore, mutually incompatible. So, if you put sleep and furiously together it is a strange combination and people would raise eyebrows looking at this particular sentence. So, people laugh heartily was not a strange sentence we made use of all word knowledge and also knowledge of the language knowledge of the properties of the words. And we could understand the meaning of this sentence annotated with proper labels so much for annotation. Proceeding further, let us just remember what we say it for machine learning the constituents are goal classification of clustering, features or attributes are the clues for classification, values of the features they decide what the decision would be? Training data where the corpus is marked with different levels of training test data, the test corpus or the test text which are used for evaluating the algorithm. And there are accuracy of the classification in the form of precision, recall, F valve, MAP Score and test of significance. We will have occasion to explain precision and recall which I will do after some time. .. Now let us understand the output of machine learning N L P system. We have said that the statistical approach natural language processing makes use of statistical technique it makes use of classification algorithms to produce levels. And now let us understand when we apply machine learning algorithm on textual data what is the output we get from this machine learning system. The first option is we could get a set of rules, so the rule can be in this form if the word to the left of the word is a noun. And has animacy feature that means the noun is animate then it is the likely agent of the action denoted by the verb. So, since people the word people was to the left of the word laugh and people is also animate that it is very likely the agent of the action denoted by the verb namely laugh. So, taking more examples the child broke the toy here child is the agent because child is to the left of break and it is also animate. In the sentence the window broke the window is not the agent because even though it is left of break it is in animate. So, both the conditions have to be satisfied the word has to be the left of the verb and it must have the animacy feature. .. There is another way the output of the machine learning N L P system can be produced. This is option number 2 and the output can be a set of probability values what we saw earlier was a rule and actual rule where as in this case the output is the set of probability values. So, it is expressed in this form the word is to the left of the word and has animacy. So, in this case the probability of the word being an agent is much more than the probability of the word being an object which again is more than probability of the word being and instrument. So, everywhere you can see we are expressing the probability by means of a conditional expression. Probability agent given that word is the left of the word and has animacy, the word being an agent is the event we are considering. So, probability of being an agent is more than the probably of being an object is more than the probably of being an instrument. So, this is the way the probability value can be produced, this is to be contrasted with the output that we saw last time this was the rules. .. Now, we will finish this lecture with a very quick remark on the difference between classical N L P and the statistical N L P. In classical N L P, we obtain the rules and these rules are embedded in the computer the rules come from the linguist, who is the human being. In statistical N L P this rules are the probabilities they come from the textual data namely the corpus and the machine works with those rules. So, in both cases there are rules and it could also probability values, but classical N L P they come from human beings and in statistical N L P they come from textual data by means of machine leaning algorithm. We will make more insightful remarks on these things in the next lecture.\n",
          "document_id": 1144856
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What is Artificial Intelligence?",
              "id": 541114,
              "answers": [
                {
                  "answer_id": 614948,
                  "document_id": 1144858,
                  "question_id": 541114,
                  "text": " Artificial intelligence is called the forcing function for computer science. Computer science has grown, by lips and bounds in recent years and one of the reasons for that has been artificial intelligence. Artificial intelligence has always pushed in the boundary of computer science and engineering by demanding more and more from the machine.",
                  "answer_start": 1486,
                  "answer_end": 1831,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are the three layers present in the Transparency of expert sysetem?",
              "id": 541113,
              "answers": [
                {
                  "answer_id": 614947,
                  "document_id": 1144858,
                  "question_id": 541113,
                  "text": " there are this three layers: Search, logic and knowledge representation, forms the 1st layer. The next layer is: Machine learning and planning. The final layer is: Natural language processing, vision, robotics and expert systems.",
                  "answer_start": 1057,
                  "answer_end": 1287,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Describe about the lower most layer in the Transparency of expert system?",
              "id": 541115,
              "answers": [
                {
                  "answer_id": 614949,
                  "document_id": 1144858,
                  "question_id": 541115,
                  "text": "money and withdraws money from, the other meaning of bank is the bank of river, the side of the river, the land mass of the river, the land mass which is on side of the river. So, when I say I went to the bank to withdraw some money, which meaning of bank did I have in mind?",
                  "answer_start": 5264,
                  "answer_end": 5539,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Given an example of expert system?",
              "id": 541116,
              "answers": [
                {
                  "answer_id": 614950,
                  "document_id": 1144858,
                  "question_id": 541116,
                  "text": " example, the task could be diagnosis of diseases and curing this. A doctor is known to operate with a number of rules, a very large number of rules obtained by years of education and practice on patience. So, the expert system is concerned with emulating this behavior of the expert.",
                  "answer_start": 2681,
                  "answer_end": 2965,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Describe about the 2nd layer on the expert system?",
              "id": 541117,
              "answers": [
                {
                  "answer_id": 614951,
                  "document_id": 1144858,
                  "question_id": 541117,
                  "text": "the 2nd layer. We find that machine learning and planning feed into a number of layers in the outer most category. For example, natural language processing is fed by machine learning and natural language processing is also fed by knowledge representation. The reason for this is that in current world, natural language processing is using lots of statistical techniques. Statistical techniques are machine learning techniques; they make use of the knowledge contained in the data. In today’s internet world we have a large amount of text, in the form of a number of documents: estimable pages, p d f pages, word pages, power point presentations and so on and so forth. The internet is full of textual documents. So, these textual documents have to be made use of, a program has to make sense of this textual document, that requires natural language processing technique",
                  "answer_start": 3022,
                  "answer_end": 3891,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Explain about the top layer of the  expert system ?",
              "id": 541118,
              "answers": [
                {
                  "answer_id": 614959,
                  "document_id": 1144858,
                  "question_id": 541118,
                  "text": " the 1st layer is: search, logic and knowledge representation. In Search the machine is faced with a number of choices, a number of choices as it computes. Search algorithms try to find out the best possible strategy, the optimal strategy for computer. Now, one might ask in natural language processing is it necessary to conduct search",
                  "answer_start": 4522,
                  "answer_end": 4858,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": " NLP drawn from ?",
              "id": 541123,
              "answers": [
                {
                  "answer_id": 614965,
                  "document_id": 1144858,
                  "question_id": 541123,
                  "text": " natural language processing draws from: search, logic, knowledge representation. It also draws for machine learning and different areas of artificial intelligence like: vision, robotics, expert systems also draw from many different areas of A I",
                  "answer_start": 7342,
                  "answer_end": 7587,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How words are composed in NLP?",
              "id": 541128,
              "answers": [
                {
                  "answer_id": 614973,
                  "document_id": 1144858,
                  "question_id": 541128,
                  "text": "morphology fundamentals, morphological diversity of Indian languages, morphology paradigms, finite state machine based morphology, automatic morphology, learning, shallow parsing, named entities, maximum entropy models and random fields",
                  "answer_start": 11243,
                  "answer_end": 11479,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Describe the morphology process in NLP? ",
              "id": 541134,
              "answers": [
                {
                  "answer_id": 614979,
                  "document_id": 1144858,
                  "question_id": 541134,
                  "text": "English is very simple language in terms of morphology. English produces what forms many of which are quite simple. For example, to form a future tense from go you just have to plug will before go, will is called an oscillary form. In Hindi you will have to say . the word . comes from two morphine’s . to go ((Refer Time.) will go will. So, . plus produces ((Refer Time: 16:08)). Therefore, it make sense to take the word . and break it into two pieces . and, this known as morphology processing",
                  "answer_start": 12329,
                  "answer_end": 12825,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Explain brief about  NLP?",
              "id": 541127,
              "answers": [
                {
                  "answer_id": 614972,
                  "document_id": 1144858,
                  "question_id": 541127,
                  "text": " natural language processing is the forcing function for artificial intelligence itself. In natural language processing, we are concerned with day to day communication. Now, day to day communication requires understanding: the words, the phrases, the structures, the syntactic processing, the meaning of the sentences all these are extremely important even for artificial intelligence. And therefore, when we make it advancement industry language processing it impacts artificial intelligence as a field. An artificial intelligence in its own turn advances the frontiers of natural language processing. So, I think I am clear about the whole chain of influencing the different fields do. N L P influences A I, A I influences artificial intelligence, N L P advances A I, A I advances computer science and engineering. Let us move ahead. . I would like to spent some time on the course content. The top level topics which are mentioned here are: sound, words and word forms. .. In the next slide: structures, meaning, and web 2.0 applications. If we move to the 1st topic . sound, sound is concerned with the biology of speech processing. Natural language comes in two different forms: one is the spoken utterances, the other one is written communication. If we look at the biological processing of speech, how do human beings utter understand speech? Human beings hear words, the sound patterns which come to the ear and those speech patterns are understood by the brain. There are specific areas of brain, designated for auditory signal processing ok. And, these speech sound is converted in two patterns which are stored in the brain and they in turned activate our self’s to perform some action. We utter some sentences in response to speech or we take some action.",
                  "answer_start": 7852,
                  "answer_end": 9619,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Which analysis happens to be extremely well researched topic in NLP?",
              "id": 543794,
              "answers": [
                {
                  "answer_id": 628186,
                  "document_id": 1144858,
                  "question_id": 543794,
                  "text": "Parsing or syntactic analysis happens to be an extremely well research topic in natural language processing. ",
                  "answer_start": 14853,
                  "answer_end": 14962,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Where we can observe Syntactic analysis or parsing rather than NLP?\n ",
              "id": 543799,
              "answers": [
                {
                  "answer_id": 628187,
                  "document_id": 1144858,
                  "question_id": 543799,
                  "text": "Syntactic analysis or parsing is also seen in other branches of computer science like, compilers and programming languages.",
                  "answer_start": 15082,
                  "answer_end": 15205,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are the topics associated within the NLP?\n",
              "id": 543807,
              "answers": [
                {
                  "answer_id": 628188,
                  "document_id": 1144858,
                  "question_id": 543807,
                  "text": "I mention the topics here as: lexical knowledge networks, word net theory, Indian language word nets and multilingual dictionaries, semantic roles, word sense disambiguation, W S D and multilinguality, metaphors, co references, a very large number of topics. All of them are complex difficult topics.",
                  "answer_start": 16366,
                  "answer_end": 16666,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Describe an example that defines lexcial knowledge?\n",
              "id": 543808,
              "answers": [
                {
                  "answer_id": 628189,
                  "document_id": 1144858,
                  "question_id": 543808,
                  "text": "To take an example, dog is an animal. We look at dogs and we also have this class of animals. What do dogs have? Dogs have: tails, eyes, legs, hair and so on. Animals also have many different properties. Most of the animals are moving, most of the animals pro create produce children’s. And, most of the animals: drink water, eat food and so on and forth. Now, dog being a member of animal family in held’s all these properties. So, there is an intimate meaning linkage between dog and animal. So, what are we talking about here? We are talking about not the word, not the word dog and animal. We are talking about meanings of the words dog and animal. How they relate to each other. So, this is what is represented in lexical knowledge networks and it took a long time for natural language .",
                  "answer_start": 17129,
                  "answer_end": 17921,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What sentiment analysis describes?",
              "id": 543809,
              "answers": [
                {
                  "answer_id": 628190,
                  "document_id": 1144858,
                  "question_id": 543809,
                  "text": "sentiment analysis is concerned with: how to look at a document, how to process the content of the document and then find out what is the document writer ok or the speaker say about a particular entity, an organization or a person. Is the person positively oriented towards the person or the organization or is the persons opinion negative.",
                  "answer_start": 19816,
                  "answer_end": 20156,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Describe an example of sentiment analysis?",
              "id": 543811,
              "answers": [
                {
                  "answer_id": 628193,
                  "document_id": 1144858,
                  "question_id": 543811,
                  "text": " For example, take a bank and you look at the blogs, that the users of the bank express their opinions seen blog. You have lot of textual data in electronic form and you would like to understand, is the blog praising the bank or is it expressing opinion against the bank. This is the concerned of the field call sentiment analysis.",
                  "answer_start": 20156,
                  "answer_end": 20487,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Describe cross lingual information retrieval with legitimate example.",
              "id": 543812,
              "answers": [
                {
                  "answer_id": 628194,
                  "document_id": 1144858,
                  "question_id": 543812,
                  "text": "In India the comfort level of English is not very high. It is known that about 5 to 6 percent of Indian population is comfortable in usage of English. So, for such people when there is information need has to be met, they should be able to posed query in their own language, obtain information in their own language. But, at the background what is happening is the web is processing the query looking at large amount of English documents and then producing an answer in the language of the user. This is known as cross lingual information retrieval and cross lingual retrieval is a very relevant and current problem for many countries and India is no exceptions ",
                  "answer_start": 22105,
                  "answer_end": 22767,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What applications gives good overview of what is going on in NLP?",
              "id": 543813,
              "answers": [
                {
                  "answer_id": 628195,
                  "document_id": 1144858,
                  "question_id": 543813,
                  "text": "web 2.0 applications like: sentiment analysis, text entailment, machine translation and cross lingual, information retrieval will be covered. These gives an overview ",
                  "answer_start": 23206,
                  "answer_end": 23372,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is QSA triangle in NLP?",
              "id": 543814,
              "answers": [
                {
                  "answer_id": 628196,
                  "document_id": 1144858,
                  "question_id": 543814,
                  "text": "Q is the query, S is a search and analytics is the intelligent processing of information on the web. This is known as the Q S A triangle, a very famous concept in the scenario of web. Q query, S search and A analytics",
                  "answer_start": 23731,
                  "answer_end": 23948,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are the Search and Query component mean?",
              "id": 543815,
              "answers": [
                {
                  "answer_id": 628197,
                  "document_id": 1144858,
                  "question_id": 543815,
                  "text": "When the user is posing a query, this query is process by the search engine and document searched. So, this is the search component. The 1st component was the query component",
                  "answer_start": 24113,
                  "answer_end": 24287,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Define natural language processing goals?",
              "id": 543816,
              "answers": [
                {
                  "answer_id": 628198,
                  "document_id": 1144858,
                  "question_id": 543816,
                  "text": "natural language processing has two goals: the science goal and the engineering goal. The science goal and engineering goal they go hand in hand. They work in tandem. In science goal, the aim is to understand how language is produced and how language is understood by an intelligent entity",
                  "answer_start": 25588,
                  "answer_end": 25877,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Describe the legitimate examples of NLP.",
              "id": 543817,
              "answers": [
                {
                  "answer_id": 628199,
                  "document_id": 1144858,
                  "question_id": 543817,
                  "text": " turing test",
                  "answer_start": 29602,
                  "answer_end": 29614,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Mention three problems when we are dealing with Phonetics in NLP?",
              "id": 543841,
              "answers": [
                {
                  "answer_id": 628223,
                  "document_id": 1144858,
                  "question_id": 543841,
                  "text": "when we have phonetics and phonology we are dealing with speech sounds. We have to deal with a three problems: one homophones, two near homophones, three word boundary. So, these are the three different problems we deal with when we are dealing with speech sound. ",
                  "answer_start": 39892,
                  "answer_end": 40156,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Who proposed Call turing test?",
              "id": 543818,
              "answers": [
                {
                  "answer_id": 628200,
                  "document_id": 1144858,
                  "question_id": 543818,
                  "text": "call turing test, which was proposed by one of the great, I would say one of the great man of computer science and mathematics Ailon Turing, who proposed that a particular test can be conducted to find out if a machine is truly intelligent.",
                  "answer_start": 29598,
                  "answer_end": 29838,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is Call turing test?",
              "id": 543835,
              "answers": [
                {
                  "answer_id": 628217,
                  "document_id": 1144858,
                  "question_id": 543835,
                  "text": "famous test called turing test. In turing test, our goal is to see if a machine is truly intelligent, if the program psi truly intelligent. And this is proposed by Ailon Turing to test a program for its intelligence. There are many criticisms, many philosophical criticisms against turing test. However, the test has state, over the years the test has been studied by A I students, A I researcher, so much so, now a days you have a competition. In this competition you essentially conduct a turing test to find out if a program is truly intelligent or not.",
                  "answer_start": 30607,
                  "answer_end": 31163,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is Eliza in NLP?",
              "id": 543836,
              "answers": [
                {
                  "answer_id": 628218,
                  "document_id": 1144858,
                  "question_id": 543836,
                  "text": "Eliza, which is a very famous program, one of the 1st programs to demonstrate natural language processing. ",
                  "answer_start": 31521,
                  "answer_end": 31628,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is the crux of NLP?",
              "id": 543837,
              "answers": [
                {
                  "answer_id": 628219,
                  "document_id": 1144858,
                  "question_id": 543837,
                  "text": "we come to probably the most important starting discussion of natural language processing namely ambiguity. So, we write here ambiguity. This is what makes natural language processing challenging and this is the crux of the problem. Ambiguity is there everywhere at all stages of natural language processing and we proceed to elaborate on that. .. It is known that there are different stages of language processing.",
                  "answer_start": 36520,
                  "answer_end": 36935,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are the different stages of language processing?",
              "id": 543838,
              "answers": [
                {
                  "answer_id": 628220,
                  "document_id": 1144858,
                  "question_id": 543838,
                  "text": "The stages are listed here: phonetic and phonology, morphology, lexical analysis, syntactic analysis, semantic analysis, pragmatics and finally discourse. So, all this topics are very well known in natural language processing and speech.",
                  "answer_start": 36936,
                  "answer_end": 37173,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Describe Phonetics in NLP?",
              "id": 543839,
              "answers": [
                {
                  "answer_id": 628221,
                  "document_id": 1144858,
                  "question_id": 543839,
                  "text": "Phonetics is concerned with the processing of speech. The challenges in this are homophones namely strings of alphabets or words which sound similar. So, bank in the financial sense and bank in the river sense. They sound similar. Therefore, they are called homophones.",
                  "answer_start": 37495,
                  "answer_end": 37764,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are homophones?",
              "id": 543840,
              "answers": [
                {
                  "answer_id": 628222,
                  "document_id": 1144858,
                  "question_id": 543840,
                  "text": " homophones are those which have very close sound, ",
                  "answer_start": 37769,
                  "answer_end": 37820,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Describe about Morphology?\n",
              "id": 543842,
              "answers": [
                {
                  "answer_id": 628224,
                  "document_id": 1144858,
                  "question_id": 543842,
                  "text": "Morphology, as described before, deals with word formation rules from the root words. For examples, the nouns: boy boys, gender marking, zar zarina. They come from the root word boy or zar, . for example. They are also, they corresponds to gender marking. Verbs give rise to different forms through tense like stretch stretched, aspect for example, perfective sit. From sit we can obtain had, modality for example, request the root word is .. From this, we obtain .. So, 1st crucial step in natural language processing is morphology. We have to detect all the morphemes contain in a large word string.",
                  "answer_start": 40220,
                  "answer_end": 40821,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are the languages rich and poor morphology and describe the pro's and con's of it?",
              "id": 543843,
              "answers": [
                {
                  "answer_id": 628225,
                  "document_id": 1144858,
                  "question_id": 543843,
                  "text": "languages which are reach in morphology are Dravidian languages: Tamil, Telugu, Malayalam, Hungarian and Turkish in European. Languages which are poor in morphology are Chinese and English. Chinese hardly uses any morphological suffixes. English is also not very rich in morphological variations. Languages with rich morphology have the advantage of easier processing at higher stages of processing. .Since, we have dealt with the word, in all its suffixes prefixes and so we have made a lot of progress towards word meaning. A task of great interest to computer science is finite state machines for word morphology. So, computer science comes in handy here. There are word formation rules and the suffixes which get added to the word they coming particular word. ",
                  "answer_start": 40826,
                  "answer_end": 41590,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is morphology analysis?",
              "id": 541135,
              "answers": [
                {
                  "answer_id": 614980,
                  "document_id": 1144858,
                  "question_id": 541135,
                  "text": "morphological analysis. .The opposite process is called morphology generation or morphology syntheses. We have a root word and from the root word we should be able to produce the word form. Again to take an example in English, suppose the root word is transport, we transport some material. Now, if I say that this word transport is for singular number and present tense, he transports some material.",
                  "answer_start": 12827,
                  "answer_end": 13227,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Who is the professor of Computer Science and Engineering at IIT Bombay , delivering course on NLP?",
              "id": 541112,
              "answers": [
                {
                  "answer_id": 614946,
                  "document_id": 1144858,
                  "question_id": 541112,
                  "text": " Pushpak Bhattacharyya, professor of Computer Science and Engineering at IIT Bombay, delivering a course on natural language processing. ",
                  "answer_start": 35,
                  "answer_end": 172,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "Mod-01 Lec-01 Introduction\n\nThis is Pushpak Bhattacharyya, professor of Computer Science and Engineering at IIT Bombay, delivering a course on natural language processing. Natural language processing is a very important topic in today’s world of internet. In the, in this age there is lot of information on the web in the form of text. It is a very important concern in today’s world to obtain information from this text and use it for various purposes. This is the motivation for understanding natural language processing, its tools, techniques, philosophy and principle, let us go ahead. . The course instructor is myself, Doctor Pushpak Bhattacharyya. My home page is www.cse.iitb.ac.in tilde p b. Areas of expertise are natural language processing and Machine learning. Course home page, which will be created, is slightly to be under www.cdeep.iitb.ac.in slash tilde n l p 2010. .. Moving forward, we give a perspective on natural language processing, different areas of artificial intelligence and their inter dependencies. If you look at this diagram there are this three layers: Search, logic and knowledge representation, forms the 1st layer. The next layer is: Machine learning and planning. The final layer is: Natural language processing, vision, robotics and expert systems. I would like to spend some time understanding these areas and their inter relationships. Before that, let me talk about the importance of artificial intelligence in computer science and engineering. Artificial intelligence is called the forcing function for computer science. Computer science has grown, by lips and bounds in recent years and one of the reasons for that has been artificial intelligence. Artificial intelligence has always pushed in the boundary of computer science and engineering by demanding more and more from the machine. It is understood that, the machine should come closer and closer to human beings in terms of its usage and its application. If we look at the lower most layer in the transparency, if you see this here, natural language processing forms the left most corner block, followed by vision, computer vision then robotics then expert systems. I would like to make some remarks on this. Natural language processing is concerned with, the computer being able to process human light languages like: English, French, Marathi, Hindi and so on. In computer vision the machine processes seen and understands, how to operate in the seen. In .robotics there is an embedded software inside the robot, asking it to perform various actions like navigating on a terrine. Expert system is concerned with, the expert level performance of a software on a specific task. For example, the task could be diagnosis of diseases and curing this. A doctor is known to operate with a number of rules, a very large number of rules obtained by years of education and practice on patience. So, the expert system is concerned with emulating this behavior of the expert. Let us move on to the, feeding disciplines which are at the 2nd layer. We find that machine learning and planning feed into a number of layers in the outer most category. For example, natural language processing is fed by machine learning and natural language processing is also fed by knowledge representation. The reason for this is that in current world, natural language processing is using lots of statistical techniques. Statistical techniques are machine learning techniques; they make use of the knowledge contained in the data. In today’s internet world we have a large amount of text, in the form of a number of documents: estimable pages, p d f pages, word pages, power point presentations and so on and so forth. The internet is full of textual documents. So, these textual documents have to be made use of, a program has to make sense of this textual document, that requires natural language processing technique. Now, the point here is that suppose human beings are ask to make sense of all these data. Then how many pages can human being really shift through, in let say 24 hours of time or even if you take you know working hour of 8 hours per day. How much of data can human being possibly see? That is the reason why it is important to develop machine learning techniques, statistical techniques which look at the data and obtain the knowledge content of the data. This is the importance of machine learning. Let us go to the transparency again and see that machine learning is feeding into natural language processing. Here, we find that the 1st layer is: search, logic and knowledge representation. In Search the machine is faced with a number of choices, a number of choices as it computes. Search algorithms try to find out the best possible strategy, the optimal strategy for computer. Now, one might ask in natural language processing is it necessary to conduct search? We will see many examples, where we are faced with a number of choices, when we are processing the textual data and search is very important for this. .I will give you a very small example. Suppose, I utter the word, “I went to the bank to withdraw some money”. Now, it is known that bank is a very ambiguous word. Bank contains two meanings: one meaning of bank is the financial bank where one deposits money and withdraws money from, the other meaning of bank is the bank of river, the side of the river, the land mass of the river, the land mass which is on side of the river. So, when I say I went to the bank to withdraw some money, which meaning of bank did I have in mind? This requires search. A program will have to read the sentence left to right, I went to the bank to with draw some money. Until it comes to money it is difficult for the machine or even a human being to understand that we are talking about the financial sense of bank. So, this a very simple example to show, that we conduct search and we solve problems of search when we understand natural language. We will have many examples coming up when we discuss ambiguity of natural language processing. So, let us look at the transparency once again and understand the importance of logic. What does logic do? Logic is a vehicle for reasoning and inference. Logic is a vehicle for inferencing in the following sense, a number of rules and pieces of knowledge are given in logic al formalism. So, in logic we are concerned with a number of constructs like if x is true then y is true. So, if x is true then y is true that says that, whenever we can satisfy the values of x, the value of y is also satisfied. In natural language processing, logic if forms a very crucial component because the textual knowledge has to be converted into logical forms which a machine can process. So, this is the importance of logic and mainly proposition calculus, predicate calculus and some forms of non monotonic logic are used for natural language processing. Finally, we see this box, knowledge representation. Knowledge representation is again critical for natural language processing because, the sentence is contain knowledge and these knowledge has to be extracted and embedded in the machine. So, this is a very important problem again. So, let me summaries this transparency. In this transparency we see the importance of natural language processing and its place in the whole business of artificial Intelligence. So, natural language processing draws from: search, logic, knowledge representation. It also draws for machine learning and different areas of artificial intelligence like: vision, robotics, expert systems also draw from many different areas of A I as shown in the .diagram. If you look at the last sentence given in the transparency, A I is the forcing function for computer science. That tells a story that artificial intelligence pushes the frontier of computer science. We can take a step forward and say that natural language processing is the forcing function for artificial intelligence itself. In natural language processing, we are concerned with day to day communication. Now, day to day communication requires understanding: the words, the phrases, the structures, the syntactic processing, the meaning of the sentences all these are extremely important even for artificial intelligence. And therefore, when we make it advancement industry language processing it impacts artificial intelligence as a field. An artificial intelligence in its own turn advances the frontiers of natural language processing. So, I think I am clear about the whole chain of influencing the different fields do. N L P influences A I, A I influences artificial intelligence, N L P advances A I, A I advances computer science and engineering. Let us move ahead. . I would like to spent some time on the course content. The top level topics which are mentioned here are: sound, words and word forms. .. In the next slide: structures, meaning, and web 2.0 applications. If we move to the 1st topic . sound, sound is concerned with the biology of speech processing. Natural language comes in two different forms: one is the spoken utterances, the other one is written communication. If we look at the biological processing of speech, how do human beings utter understand speech? Human beings hear words, the sound patterns which come to the ear and those speech patterns are understood by the brain. There are specific areas of brain, designated for auditory signal processing ok. And, these speech sound is converted in two patterns which are stored in the brain and they in turned activate our self’s to perform some action. We utter some sentences in response to speech or we take some action. We perform in real life world moving our hands, legs and so on. So, speech processing refers to concept formation in the brain, it also refers to taking action in the real life world. So, the topics that are mention there pertain to different areas of speech processing, the biology of speech, phonetics, phonology, place articulation and many different statistical techniques which are needed for processing of speech. Now, why is speech important for natural language process? Speech is important because speech gives many different statistical techniques consumed by natural language processing into today’s world. Earlier when natural language processing used to be completely reliant on a linguist expertise, a language experts proficiency, a lexicographers proficiency and so on. It was completely human regain. .Now, it is seem that there is lot of data, it textual form on the web and we can use machine learning techniques to make sense of these data ok. So, where do this techniques come from? These techniques come from two fields namely: speech and computer vision. They have been for a long time processing signals and patterns using machine learning techniques, statistical techniques. And, today’s natural language processing cannot ignore those techniques. In fact, they benefit a lot from the application of those techniques. So, the main point I am making here is that speech actually provides natural language processing with its own statistical approach, statistical techniques. Moving forward word and word forms, look at the 2nd point here words and word forms. Words and word forms I mentioned here: morphology fundamentals, morphological diversity of Indian languages, morphology paradigms, finite state machine based morphology, automatic morphology, learning, shallow parsing, named entities, maximum entropy models and random fields, I have listed out a number of topics. Let me explain to you in brief what I mean here. Words come in many different forms and our concern is to be able process words very skillfully. Words form the 1st step, when you process language it is the words which we have to deal with in written communication for example. I took this example, very famous example in natural language processing, where the sentence was, “I went to the bank to with draw some money”. It is also possible to say: I will go to the bank to with draw some money, I will go to banks to with draw some money, I will go to banks to with draw all my money. So, look at this, look at what is happening. What is happening is that the same word is coming in many different forms. For example, banks is coming from the world bank, we will go went, they come from the root word go. Now, English is very simple language in terms of morphology. English produces what forms many of which are quite simple. For example, to form a future tense from go you just have to plug will before go, will is called an oscillary form. In Hindi you will have to say . the word . comes from two morphine’s . to go ((Refer Time.) will go will. So, . plus produces ((Refer Time: 16:08)). Therefore, it make sense to take the word . and break it into two pieces . and, this known as morphology processing, morphological analysis. .The opposite process is called morphology generation or morphology syntheses. We have a root word and from the root word we should be able to produce the word form. Again to take an example in English, suppose the root word is transport, we transport some material. Now, if I say that this word transport is for singular number and present tense, he transports some material. So, given the root word transport and the fact that the tense is present tense and the person is 3rd person singular number, transport becomes transports and s is added to transport. So, this is known as morphology generation or syntheses. Imagine a machine which is required to do natural language processing and natural language generation. So, what is given to the machine is let us say c, machine is suppose to describe as and it sees a human being transporting some material from point a to point b. So, the machine will have to produce the sentence, “he is transporting material from point a to point b”. The word transport now have become transporting. This is the morphology process and a number of computer algorithms have been devised to deal with morphological processing. How can we efficiently process words and obtain their root forms? So, in this course we would like to see finial state machine base morphology. How morphology is processed by means of finial state machines. We will cover this topic in some detail just to show how language and computer science come together in the form of a very simple machine namely the finite state machines. We go to the next transparency. We come to now more advanced topics: structure, meaning and web 2.0 applications. In structures, I will mention the topic of: theories of parsing, parsing algorithms, robust and scalable parsing on noisy text as in web documents, hybrid of rule based and probabilistic parsing, scope ambiguity and attachment ambiguity resolution. All these are technical terms which will be explained soon. But, it will make the main point here. Parsing or syntactic analysis happens to be an extremely well research topic in natural language processing. All other areas of natural language processing have been investigated but not so much as parsing or syntactic analysis. Syntactic analysis or parsing is also seen in other branches of computer science like, compilers and programming languages. But, there we are dealing with a much simpler problem. The problem of parsing a programming language, a piece of program is parsed. This has hardly any complexity compare to natural language, a C program or FORTRAN program .or paschal java program, they do not have the complexity of natural language sentences, paragraphs and chapters. When we have a running piece of text, large amount of text we processed by a machine. And, we have to isolate the words, the morphine within the words, the morphological processing, the phrases which are present in the sentence: noun phrase, word phrase, which we will deal with after sometime. All these structures which are detected from the sentences correspond to syntactic analysis or structure processing. This is an extremely well understood area and a number of algorithms exist in this I will cover those algorithms in detail. Parsing will form an important component of our discussions. From structures we come to the next topic, if you look at the transparency again it is meaning. Meaning is the ultimate aim of natural language processing. How do we extract the meaning of sentences? This is our main concern. I mention the topics here as: lexical knowledge networks, word net theory, Indian language word nets and multilingual dictionaries, semantic roles, word sense disambiguation, W S D and multilinguality, metaphors, co references, a very large number of topics. All of them are complex difficult topics. I would like to again spend some time on this topic. Meaning I said is the main concerned of natural language processing. How do we understand meaning? Now, in this business something that comes to big help is called word net and dictionaries and anthologies ok, they form very important components of meaning detection and meaning representation. Now, word nets and lexical knowledge networks are nothing but meaning representations and their interconnections. To take an example, dog is an animal. We look at dogs and we also have this class of animals. What do dogs have? Dogs have: tails, eyes, legs, hair and so on. Animals also have many different properties. Most of the animals are moving, most of the animals pro create produce children’s. And, most of the animals: drink water, eat food and so on and forth. Now, dog being a member of animal family in held’s all these properties. So, there is an intimate meaning linkage between dog and animal. So, what are we talking about here? We are talking about not the word, not the word dog and animal. We are talking about meanings of the words dog and animal. How they relate to each other. So, this is what is represented in lexical knowledge networks and it took a long time for natural language .processing to understand that meaning networks are crucial for natural language processing. We will spent a quite an amount of time on word nets at I I T Bombay we have done lot of research and development in word net building. And, I would like to describe our work on Hindi word net, Marathi word net, our effort at create creating Indian language word nets all over the country which is advancing the state of art in natural language processing in this country. So, meaning representation through word net anthology dictionary will form an important component of our discussions. Coming to the next topic which is web 2.0 applications I mention the items as: sentiment analysis, text entailment, robust and scalable machine translation, question answering in multilingual setting, cross lingual information retrieval. What do I mean by all this? Those of you who are keeping track of what is going on in the internet, internet is again going through a revolution. Internet itself has caused a revolution in human life. Civilization has been profoundly influence by web, by internet, things which we were not imaginable before, the advent of internet is happening regularly today, absolutely regularly. So, web is now coming up with its next version, which is web 2.0. I mention some topics here like: sentiment analysis, text entailment, machine translation in the large scale and so on and so forth. Let us just take the 1st topic, sentiment analysis. If you think carefully we have a completely new world order now. Never before was so much of public opinion was available in electronic form ok. Common man can access information about any organization any person, just through the click of a mouse, so much of information about persons and organization organizations are available on the web in a completely electronic form. This is a completely new scenario. It did not exist before. So, sentiment analysis is concerned with: how to look at a document, how to process the content of the document and then find out what is the document writer ok or the speaker say about a particular entity, an organization or a person. Is the person positively oriented towards the person or the organization or is the persons opinion negative. For example, take a bank and you look at the blogs, that the users of the bank express their opinions seen blog. You have lot of textual data in electronic form and you would like to understand, is the blog praising the bank or is it expressing opinion against the bank. This is the concerned of the field call sentiment analysis. In sentiment analysis, we would like to develop programs which automatically understand the opinion .of the users from the electronic text. This is known as sentiment analysis or polarity detection. So similarly, text entitlement is concerned with inferencing of text. Given two pieces of text are they consistent with each other, does one text follow from the other? In large scale machine transitions which is a very old field and extremely relevant for a country like India where multiple languages are spoken, written. The concerned is to able to translate from one language to another like: English to Hindi, Hindi to Marathi and Marathi to Bengali and so on. At I I T Bombay, we again have large scale activity on machine transition. The final topic I mention there is cross lingual information retrieval. If you think about it in a country like India, cross lingual information retrieval forms a very important problem. Users have information it. Where do they go for their information need? Earlier, when the web did not exist users is to go to libraries, obtain their information from the library. Now, a day’s people click, click a mouse or they use keyboard they go to the web and obtain the information from to the web. Now, imagine what kind of problem a user will face, if the language of the user is not English? The web, the a large a large part of a is in English. The user has to suppose the query in English, obtain information in English and then understand the document. If the user is not comfortable with English, then the user is handicapped. This is known as the problem of language barrier. In India the comfort level of English is not very high. It is known that about 5 to 6 percent of Indian population is comfortable in usage of English. So, for such people when there is information need has to be met, they should be able to posed query in their own language, obtain information in their own language. But, at the background what is happening is the web is processing the query looking at large amount of English documents and then producing an answer in the language of the user. This is known as cross lingual information retrieval and cross lingual retrieval is a very relevant and current problem for many countries and India is no exceptions ok. So, these in an our shell is at over view of the topics I would like to cover in summary. We will look at speech processing techniques. We will look at how words are processed and stored, morphological processing dictionaries. We will understand the techniques of syntactic analysis parsing, meaning representation is done in the dictionaries, word nets and anthologies. We would like to discuss those topics. And finally, some of the web 2.0 applications like: sentiment analysis, text entailment, machine translation and cross lingual, information retrieval will be covered. These gives an overview and I suppose .this is a an existing set of topics and, once these topics are covered one gets a good overview of what is going on in naturally language processing. . We will move forward now, with some of the central topics. We have said many times that web brings new perspective. If you look at the diagram here, we have what is called the Q S A triangle. Q is the query, S is a search and analytics is the intelligent processing of information on the web. This is known as the Q S A triangle, a very famous concept in the scenario of web. Q query, S search and A analytics ok. And, this actually brings in many fine points of discussion. We do not have enough time to going to those details. Let me just make one of the remark and this. When the user is posing a query, this query is process by the search engine and document searched. So, this is the search component. The 1st component was the query component; query has to be processed after. And, when the documents come up, the large documents come up from the search engine, we have to understand what this document mean and do the satisfy our information need. The topic of analytics is concerned with that. It is concerned with how to process these documents intelligently. So, we can imaging a future scenario where the user gives in the query, the documents are searched and the essential to information with respect to that query is presented to the user all by the machine, all by the computer ok. So, after the query is presented search and analytics they work together, they work in synchrony. They work in tandem to produce information for the user to consume for the .user to use that information. That is the Q S A triangle and you can see that this is a documents are mainly in textual form, there lots of documents in image form. The document which are in textual form they required natural language processing techniques to be processed. . Moving forward we now proceed to define natural language processing. As the slide shows it is, natural language processing is a branch of artificial intelligence. We have already dwelt, on this particular issue in one of the transferring before where we showed many different dependencies of A I. Now, natural language processing has two goals: the science goal and the engineering goal. The science goal and engineering goal they go hand in hand. They work in tandem. In science goal, the aim is to understand how language is produced and how language is understood by an intelligent entity ok. For example, how do I process the sentence, “I went to the bank to withdraw some money”. If somebody asked me why did you go to the bank, I will answer to withdraw some money ok. How do I answer this question? You I must of understood the question. I must of understood that the meaning of bank here is a financial bank not river bank. How did I do that? So, this is a cognitive process which is happening in the brain and human beings are extremely good at it. The science goal of natural language processing is to understand these phenomenon. This tremendous phenomenon of: how we process language, how we generate language, how we interact .with our fellow human beings through language, is the science goal. The engineering goal on the other hand, is concerned with the use of the techniques some natural language processing. When we create a natural language processing program, it has been particular use ok. For example, I could use the natural language processing program to read a text I am produce sounds corresponding to the text. This for example, could be very useful to blind person ok. A blind person is not able to read a piece of text himself. So, we give the text to natural language processing program, it automatically reads a document, produces the speech sound and the blind person understands what the meaning of this document is. So, this is a an extremely important utility of language processing. Consider another scenario where the person is not blind but he is speaking. And, as he speaks the speech sounds are interpreted by a speech processing language understanding system and those speech sounds are converted into a textual file. So, imagine a, imagine how the life of a teacher will be comes simpler if such a systematic. The teacher simply comes to the class they leavers the lecture. A software program capture those sounds and produce a textual file which can eventually uploaded, on the teachers home page and he meant on the on the students can make use of the lecture notes. The lecture note was not written by the user, by the teacher not was anything written by the student. A program captured all the sound and produces the lecture note ok. So, this is another very important use namely: the speech understanding and speech encoding into text. There are many such applications of language processing. I mentioned sentiment analysis some time back and this problem, the problem sentiment analysis requires language processing. It is a very important problem. Organizations, now a day’s are very concerned about what the public are saying about on the internet. And, it is impossible for a single human being or even a team human being, to look at the whole web and tell the organization. You know people are saying very nice things about you or saying bad things about you. So, can the employees, software agent, can the software programs which will navigate the web, over the whole web and give to the organization peoples feedback about this. So, these are many different utilizes natural language processing and these pertains to the engineering goal. So, we mentioned two goals: science goal and engineering goal both .have to be kept in mind, for anybody working on natural language processing ok. The excitement of the field comes from this, a this wisteria phenomenon. This very you know deep phenomenon of language being processed in the brain and language being produced. The excitement comes from there, these a science goal. And, the other kind of excitement that comes is that language processing produces useful tools and resources which makes human beings life easier, so science goal and engineering goal. . Preceding further, there was this very famous test call turing test, which was proposed by one of the great, I would say one of the great man of computer science and mathematics Ailon Turing, who proposed that a particular test can be conducted to find out if a machine is truly intelligent. If you look at this diagram there is this test conductor, who is interacting with a machine and a human. The person, the test conducted does not know, where is the machine and where is the human beings. Imagine these two circles to be two different rooms and all the communication takes place through the keyboard. Now, the task is, can the test conductor find out which room contains the machine and which room contains the human being? Can the test conductor find out which is the machine and which the human? So, if the test conductor cannot distinguish between the machine and the human, then the machine is suppose to be intelligent. It should, it is suppose to be passing the test for intelligence. .So, let us spend some time on this test. This is an extremely famous test called turing test. In turing test, our goal is to see if a machine is truly intelligent, if the program psi truly intelligent. And this is proposed by Ailon Turing to test a program for its intelligence. There are many criticisms, many philosophical criticisms against turing test. However, the test has state, over the years the test has been studied by A I students, A I researcher, so much so, now a days you have a competition. In this competition you essentially conduct a turing test to find out if a program is truly intelligent or not. The participant or subjected to something like a turing test and they are given enormous amount as money of price. If the test conductor who is human being cannot detect, if the software program who was a machine indeed or was it actually human being, which was interacting with the test conductor. . Now, the turing test actually inspired something called Eliza, which is a very famous program, one of the 1st programs to demonstrate natural language processing. Though in a very nigh way but it brought out a number of aspects of natural language processing. So, here is the u r l which can be try, it which you can try to interact with Eliza. .. I show a snap shot of Eliza. Look at this screen and look at the 1st sentence here. The whole screen captures interaction with a mechanical psychotherapist. It is a software program which behaves like a psychotherapist. The 1st sentence is, I am the psychotherapist please describe your problem. Each time you are finished talking type R E T twice that is the return button twice. This is the sentence coming from the machine or the program and the human being answers saying I have a terrible headache. Here it is, I have a terrible headache. The machines response is maybe you should consult a doctor of medicine, I am a psychiatrist. So, this is a very nice answer, if you can appreciate this point is a very nice answer, very natural answer, any psychotherapist or psychiatrist will answer this way. If you have a headache where should you go? You should go to a doctor not to a psychiatrist. Then the human being says, ok I will do that then. Now, the machine comes back and say can you elaborate on that and this is a bit of a strange response. Why would the entity respond this way can you elaborate on that? The machine is already advice the human being to go to a doctor and the human being also, the patient also as agreed, yes I will go to the doctor. Now, why should the machine come back and say can you elaborate on that. Then the human being says, what are you talking about, no I cannot elaborate see you. So, he is about to leave. I cannot elaborate I will go now, see you later. .Then the machine says, why do you say that? Then the human being says, now you are just talking nonsense, the human being is irritated. Now, the machine says, what makes you believe now I am just talking nonsense? Human being says, you are not making any sense. Then the machine says perhaps your plans have something to do with this. You know, so after can you elaborate on these and after the human being is about irritated and says that he cannot do much about all these conversations. The machine goes into a completely nonsensical mode of communication. Now, you are just talking nonsense. What makes you believe now, I am just talking nonsense and so on. So, what does this show? What does this communication show? The communications shows that initially or even after some level, the machine can fail to be intelligent, can pretend to be intelligent. The moment in the conversation takes a deeper turn it requires more complex listening, more complex background knowledge, lot of experience, the machine shows sign of failure. It begins to ask question which a completely nonsensical and shallow ok. And why does this, why does this happen? Eliza was a program which was created by wise and bomb and the goal was to show that natural language processing actually does not have much substance in this. Nobody will agree with this point of view anymore in today’s world. Natural language processing is understood to be very deep field with remain a some lot of utility. But, in those days wise an bomb set out to showing to the world, there see I can create a program, a software program which can intelligently converts with a human being, without a were informing the human being that it is actually a software agent ok. So, that is the point, the software program is showing that it is powerful enough to deal with language whereas, it actually is not. The internal algorithm was the following: there were a number of templates and queue words which is the software program was looking for all the time and matching it. So, it has for example, a very stock answer. What makes you say dot dot dot ok. And what makes you say that you are not well. So suppose, I say I am not well and the machine response is what makes you say that you are not well. And, there is some cleverness in converting I to you, you too I and so on. But, the whole thing is template based. There is a template will says that whenever you see a sentence and you do not know what to do with this sentence, how to process the sentence? Simply output, what makes you think, what or makes you say something. So, this is this not intelligence, this is hardly intelligent. This a completely superficial processing of the .sentence. Similarly, there were many other templates which are in build in the program and vision bomb try to show that just by activating these templates a machine can meaningfully converse. But, this is not true as the example is showing here. The moment the conversation goes into deeper things the machine begins to failure. Still, the program was inspire by turing test, vision bomb wanted to constructed program which will behave like a human being and compares with a another human being. . Moving forward we come to probably the most important starting discussion of natural language processing namely ambiguity. So, we write here ambiguity. This is what makes natural language processing challenging and this is the crux of the problem. Ambiguity is there everywhere at all stages of natural language processing and we proceed to elaborate on that. .. It is known that there are different stages of language processing. The stages are listed here: phonetic and phonology, morphology, lexical analysis, syntactic analysis, semantic analysis, pragmatics and finally discourse. So, all this topics are very well known in natural language processing and speech. My point here a listing all this topics is that, will see everywhere we have to deal with the problem of ambiguity. Starting for phonetics and phonology up to discourse everywhere, we have the problem of ambiguity coming up and we have to find solutions to those problems. . .Please take the 1st of this list, phonetics. Phonetics is concerned with the processing of speech. The challenges in this are homophones namely strings of alphabets or words which sound similar. So, bank in the financial sense and bank in the river sense. They sound similar. Therefore, they are called homophones. Near homophones are those which have very close sound, for example, the word . and ((Refer Time.) in Hindi. These two words also and used in Marathi, there also used in Bengali. Most Indian languages have these two words if the language is from the Indo European origin. So, . and . sound similar but they are not identical unlike homophones so, near homophones and homophones. We come to this very integrate problem world boundary detection. What is it I have written here, .. This Hindi word ok, this is a Hindi string. This can be broken up in two ways . will come or ((Refer Time.) will come today. So, if you break it at j before j then it is ((Refer Time: 47:24)) will come and if you break it after j then it is . will come today. So, the speech understanding system has to break the word, at the appropriate place. For example, if you break it here . and . then this to morphemes are not making much sense. No listener will break this string in to this two parts . and .. I take this example in English, one of my favorite examples. I got a plate. So, if I says it very quickly, you will not know what I said. I got a plate . or I got a plate ((Refer Time: 48:13)). So, these are the two meanings and when this whole string is given, I got a plate from the context you have to make out, is it I got a plate . or I got a plate .. Similarly, there are these problems are phrase boundary detection. These are example here, I will it as an exercise to you to see, how the phrase boundary when broken at, when broken before as such or after as such and produce two different meanings. A very important problem in phonetics is disfluency. I show some of the strings here: ah, um, ahem etcetera. Now, these strings have no meaning, these earliest says the speaker to organize is thought, the speaker by sometime through these regions of disfluency. If I say, I will go to school but, I do not know what to carry their, I forgot my umbrella so all this etcetera are regions of disfluency. They give the use if the speaker sometime to .organize is thought. So, what they say in this slide, what they said in this slide was that when we have phonetics and phonology we are dealing with speech sounds. We have to deal with a three problems: one homophones, two near homophones, three word boundary. So, these are the three different problems we deal with when we are dealing with speech sound. . We move forward and take the challenges involving morphology. Morphology, as described before, deals with word formation rules from the root words. For examples, the nouns: boy boys, gender marking, zar zarina. They come from the root word boy or zar, . for example. They are also, they corresponds to gender marking. Verbs give rise to different forms through tense like stretch stretched, aspect for example, perfective sit. From sit we can obtain had, modality for example, request the root word is .. From this, we obtain .. So, 1st crucial step in natural language processing is morphology. We have to detect all the morphemes contain in a large word string. So, languages which are reach in morphology are Dravidian languages: Tamil, Telugu, Malayalam, Hungarian and Turkish in European. Languages which are poor in morphology are Chinese and English. Chinese hardly uses any morphological suffixes. English is also not very rich in morphological variations. Languages with rich morphology have the advantage of easier processing at higher stages of processing. .Since, we have dealt with the word, in all its suffixes prefixes and so we have made a lot of progress towards word meaning. A task of great interest to computer science is finite state machines for word morphology. So, computer science comes in handy here. There are word formation rules and the suffixes which get added to the word they coming particular word. Let me take an example from Marathi. The word ., so ((Refer Time: 52:12)) has three different components .. You can also say ((Refer Time.). Now, . they coming particular word ((Refer Time: 52:27)) cannot come before . cannot come before ((Refer Time: 52:30)). So, there is a particular word, in which the suffixes I produced and inserted into the word. So, these automatically become a small parsing problem and this problem is very effectively dealt with by making use of finite state machines. computer science has invested lot of its energy in understanding finite state machine, the algorithm corresponding to that and the theory of finite estate machines. They come in handy, when we deal with morphologic processing. Here we will finish the 1st lecture.\n",
          "document_id": 1144858
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What is the crux of the problem in natural language processing ?",
              "id": 544775,
              "answers": [
                {
                  "answer_id": 634914,
                  "document_id": 1144860,
                  "question_id": 544775,
                  "text": " ambiguity is the crux of the problem in natural language processing",
                  "answer_start": 243,
                  "answer_end": 311,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What makes natural language processing the challenging job ?",
              "id": 544776,
              "answers": [
                {
                  "answer_id": 634923,
                  "document_id": 1144860,
                  "question_id": 544776,
                  "text": "ambiguity makes natural language processing the challenging job ",
                  "answer_start": 316,
                  "answer_end": 380,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Ambiguity arising from how many sources ?",
              "id": 544778,
              "answers": [
                {
                  "answer_id": 634931,
                  "document_id": 1144860,
                  "question_id": 544778,
                  "text": " Ambiguity arising from different sources.",
                  "answer_start": 973,
                  "answer_end": 1015,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": " What are the stages of natural languages processing ?",
              "id": 544777,
              "answers": [
                {
                  "answer_id": 634930,
                  "document_id": 1144860,
                  "question_id": 544777,
                  "text": "the stages of natural languages processing: phonetics and phonology, morphology, lexical analysis, syntactic analysis, semantic analysis, pragmatics, discourse.",
                  "answer_start": 418,
                  "answer_end": 578,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Ambiguity arising from different sources eloborate ?",
              "id": 544779,
              "answers": [
                {
                  "answer_id": 634935,
                  "document_id": 1144860,
                  "question_id": 544779,
                  "text": "the sources of ambiguity by writing down, ambiguity of a sentence arising from multiple meanings of words, multiple attachment points of preposition phrases. These 2 are the most important ambiguity sources. . The third reason is Clause attachment points ok. So, multiple meanings of words, multiple attachment point of preposition phrases and multiple clause attachment points.",
                  "answer_start": 1041,
                  "answer_end": 1419,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "The noun that takes the preposition phrase gets modified by the  ?",
              "id": 544781,
              "answers": [
                {
                  "answer_id": 634968,
                  "document_id": 1144860,
                  "question_id": 544781,
                  "text": "The noun that takes the preposition phrase gets modified by the preposition phrase ",
                  "answer_start": 1749,
                  "answer_end": 1832,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Where can the clauses can get attached to ? ",
              "id": 544782,
              "answers": [
                {
                  "answer_id": 634976,
                  "document_id": 1144860,
                  "question_id": 544782,
                  "text": "The clauses can get attached to different points in the sentence",
                  "answer_start": 2192,
                  "answer_end": 2256,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": " What are Attachment points and the Clausal points?",
              "id": 544780,
              "answers": [
                {
                  "answer_id": 634946,
                  "document_id": 1144860,
                  "question_id": 544780,
                  "text": "A machine will automatically produce a multiple phrases depending on the: Attachment points and the Clausal points",
                  "answer_start": 1633,
                  "answer_end": 1747,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Describe the Semantics in detail with example?",
              "id": 545666,
              "answers": [
                {
                  "answer_id": 637563,
                  "document_id": 1144860,
                  "question_id": 545666,
                  "text": "Higher level knowledge is the needed for disambiguation, which is where semantics comes in to being. I saw the boy with a pony tail. Here, the machine, the parser will produce two phrases. In one case, the attachment will be shown with the boy, with pony tail is attached to the boy. This is a modifier for the boy. In the other case, with a pony tail will be part of the verb phrase. Saw the boy with a .pony tail. Here, the verb see has an object in the form of the boy and with a pony tail is an adjunct for the verb. So, just like I saw with a telescope, the boy. So, this para phrasing would be, I saw with a pony tail the boy. And, we immediately know that this particular sentence or this particular reading does not have any meaning. A pony tail carried out to be instrument of seeing. So, this is the word knowledge which is to be brought to be are. So, these possibilities excluded and now, we have a single phrase for the sentence. I saw the boy with a pony tail means, the boy has the pony tail. ",
                  "answer_start": 2562,
                  "answer_end": 3570,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Describe the example on disambiguation through pragmatics?",
              "id": 545671,
              "answers": [
                {
                  "answer_id": 637564,
                  "document_id": 1144860,
                  "question_id": 545671,
                  "text": "disambiguation through pragmatics. We consider this sentence once again. Old men and women were taken to safe locations. Now, this particular sentences has two meanings. One meaning is that, both men and women were old, the other meaning is, only men were old. Now, old men and women were taken to safe locations. Since, women both young and old, both young and old women were likely to be taken to safe locations. Our surmise or presumption would be that the word old qualifies only men because women both young and old will be taken to safe locations. So, imagine there is an attack on a region, on a country and men women everybody are taken to a safe locations. Young men of course, would go and fight the enemy. Old men will have to take into the safe locations. Similarly, women will have to be taken to safe locations. So, the reading that we prefer is this first reading. Only the men are old and this kind of consideration is known as the pragmatics consideration ok. Here syntax is giving you as 2 possibilities. Semantics is also giving 2 possibilities. It is not excluding the isolating the possibility of women also being old ok. So, up to the level of semantics ambiguity remains. There are two different phrases with old ok, with old being a qualifier for both men and women. Semantic also saying that both men and women can be old. Here comes pragmatics which says that both men and women being old and they been taken to safe location, is less probable. Then the fact that only the men are old and old men and women both are being taken to the safe location ok. So, this is a purely it is known as the pragmatic consideration and here pragmatics is coming and disambiguate.",
                  "answer_start": 3598,
                  "answer_end": 5288,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "Mod-01 Lec-03 Stages of NLP Continue...\n\nWe continue our lecture on natural language processing. This is lecture number 3 and we continue with the stages of natural language processing. . Looking at the slide again reemphasizing, the fact that ambiguity is the crux of the problem in natural language processing and ambiguity makes natural language processing the challenging job that it is. .. We remind ourselves of the stages of natural languages processing: phonetics and phonology, morphology, lexical analysis, syntactic analysis, semantic analysis, pragmatics, discourse. In the last lecture, lecture number 2, we are discussing syntactic analysis. . We showed this example of structural ambiguity. I did not know my P D A had a phone for 3 months, the camera man shot the man with the gun when he was near Tendulkar. This long sentence from P G Wodehouse and this particular caption from Times of India. .All of them have multiple meanings because of the ambiguity. Ambiguity arising from different sources. . I would like to repeat the sources of ambiguity by writing down, ambiguity of a sentence arising from multiple meanings of words, multiple attachment points of preposition phrases. These 2 are the most important ambiguity sources. . The third reason is Clause attachment points ok. So, multiple meanings of words, multiple attachment point of preposition phrases and multiple clause attachment points. .The interaction of these three produces ambiguity of sentences, different meanings of sentences ok. So, we proceed further. . In this slide we are saying that higher level knowledge is needed for disambiguation. A machine will automatically produce a multiple phrases depending on the: Attachment points and the Clausal points. The noun that takes the preposition phrase gets modified by the preposition phrase ok. So, this is a longer noun phrase where the head noun has gotten as a modifier in the form of the preposition phrase. So, this is the preposition phrase ambiguity. The preposition phrase may be attached to the verb where, the whole phrase is like an adjunct for the verb. The other attachment ambiguity is that, which comes from a clause attachment points. The clauses can get attached to different points in the sentence ok. Now, when these different kinds of ambiguity arise, how is it possible that we still understand the meaning of sentence from the context and from the interaction of the sentence with many other sentences in the neighborhood? How does it happen? Many times it happens from, what is there in the slide. Higher level knowledge is the needed for disambiguation, which is where semantics comes in to being. I saw the boy with a pony tail. Here, the machine, the parser will produce two phrases. In one case, the attachment will be shown with the boy, with pony tail is attached to the boy. This is a modifier for the boy. In the other case, with a pony tail will be part of the verb phrase. Saw the boy with a .pony tail. Here, the verb see has an object in the form of the boy and with a pony tail is an adjunct for the verb. So, just like I saw with a telescope, the boy. So, this para phrasing would be, I saw with a pony tail the boy. And, we immediately know that this particular sentence or this particular reading does not have any meaning. A pony tail carried out to be instrument of seeing. So, this is the word knowledge which is to be brought to be are. So, these possibilities excluded and now, we have a single phrase for the sentence. I saw the boy with a pony tail means, the boy has the pony tail. Next example, is that we do disambiguation through pragmatics. We consider this sentence once again. Old men and women were taken to safe locations. Now, this particular sentences has two meanings. One meaning is that, both men and women were old, the other meaning is, only men were old. Now, old men and women were taken to safe locations. Since, women both young and old, both young and old women were likely to be taken to safe locations. Our surmise or presumption would be that the word old qualifies only men because women both young and old will be taken to safe locations. So, imagine there is an attack on a region, on a country and men women everybody are taken to a safe locations. Young men of course, would go and fight the enemy. Old men will have to take into the safe locations. Similarly, women will have to be taken to safe locations. So, the reading that we prefer is this first reading. Only the men are old and this kind of consideration is known as the pragmatics consideration ok. Here syntax is giving you as 2 possibilities. Semantics is also giving 2 possibilities. It is not excluding the isolating the possibility of women also being old ok. So, up to the level of semantics ambiguity remains. There are two different phrases with old ok, with old being a qualifier for both men and women. Semantic also saying that both men and women can be old. Here comes pragmatics which says that both men and women being old and they been taken to safe location, is less probable. Then the fact that only the men are old and old men and women both are being taken to the safe location ok. So, this is a purely it is known as the pragmatic consideration and here pragmatics is coming and disambiguate. The next example in the slide is the Discourse. Example where the other sentences are helping to disambiguating. So, we took the sentence no smoking areas allow hookas inside. We saw that this particular sentences has 2 .meanings. One meaning is that there are special designated areas called: No smoking areas. Those areas will not allow in cigarettes or cigar inside but they will allow hookas. Because, you can have this artificial flavored water kept inside the hooka and one can smoke that so called smoke that and enjoy the experience of hooka. So, no smoking areas they allow hookas, those artificial hookas. The other meaning is that this knows the qualifier the whole sentence, all the remaining words in the sentence. So, this would mean that there is no smoking area. You will not be able to find any smoking area which allows hookas inside. So, they allows cigarettes and cigars but they do not allow hookahs. So, just this constrain with the earlier meaning we talked about. In this earlier meaning, the smoking areas a they did not allows cigars and cigarettes but they allowed hookas. The next meaning is saying that smoking areas are allowing cigars and cigarettes but they are not allowed hookahs, completely opposite meanings. Now, let us see how a particular meaning is isolated from discourse, from the discourse. So, if you look at these sentence. No smoking areas allow hookas inside except the one in hotel grant, this is the discourse. The other sentence is: no smoking allows areas, allow hookas inside but not cigars. So, we have connectives here in the form of except and but and the rest of the text helps disambiguate. Let see how, no smoking areas allows hookas inside, this is that other reading. You will not find any smoking area which allows hookas insides except the one is hotel grant. So, this except one in hotel grant that is helping to disambiguate the previous sentence. No smoking areas allow hookas inside. So, the meaning that is conveyed by this piece text is: you will not find any smoking area which allows hookas inside. The next sentence: no smoking areas allows hookas inside but not sugars not cigars. This is the meaning where, no smoking area is a special designated area where one cannot smoke. So, they allows they allow hookas but not the cigars. So, you can see how an additional piece of text coming after the sentence is helping to disambiguates. So, this is an example in this slide actually we show that even though, syntax can produce multiple phrases. In one case, semantics will exclude one possibility. Next case, pragmatics will exclude possibility and in a last case discourse, other piece of text will exclude possibilities. .. Proceeding further, we now come to particular phenomenon called Garden Pathing. Garden Pathing is really a headache for parsing and there are special kinds of sentences called garden path sentences. Please understand what it means. Let us look at this first sentence here. The horse raced past the garden fell. Second sentence is, the old man the boat. Third sentence is, Twin Bomb Strike on Baghdad kill 25. So, all this sentences have some interesting peculiarity sentence. Let us look at the first sentence. The horse raced past the garden fell, this particular sentence could have been over at garden, the horse race past the garden. What is this fell doing here? Even human being will get a mild shock. Lets us say he will get surprised after having processed all the words of to garden and then encountering fell. So, what you will think? You will think that, I have processed these sentences. I process this words in the sentence. I process the, I processed horse raced past the garden and then I encounter fell. The sentence could very well have been over at garden. Is there a mistake in sentence? Is this sentence grammatically wrong? The sentence is not grammatically wrong except that, after processing garden and thinking that the sentence is over here. We, will have to back track, to account for the next word which is coming. We will have to back track many many words behind and we will have to come back and stop at raced. The sentence can paraphrased as, the horse which was raced past the garden fell, then .there is no problem. So, if we now begin to analysis the sentence, let us not look at the slide any more. We begin to analysis the sentence, the horse raced past the gardens fell. Here, the other paraphrase of the sentence is: the horse which was raced past the garden fell. Now, which was raced past the garden, this is the clause. This is a complete sentence in itself except that it is a relative, it has a relative pronoun which was raced past the garden fell. So, the course sentence is the horse fell subject and predict, subject and verb. The horse fell, which horse? The horse which was raced past the garden. So, raced past the garden is the clause, is modifier for horse. Now, English has this, has this peculiarity. That in the past tense and under certain conditions it can have what is called an Elision and eliding construct. . Let me, write it down. It can have an Elision or Eliding. Eliding means cutting out or dropping out. So, the sentence had a relative pronoun, the horse which was raced past the garden fell. This which was can be dropped. The condition is that in the past tense a relative clause, for a noun. In a past tense, relative clause for a noun can drop the relative pronoun and the verb, the auxiliary verb if that noun is an object and the verb is in past tense. There are the 2 conditions: the relative pronoun along with the auxiliary can be allied or dropped if the noun is an the object and the tense of the verb is past. So, here also you .can see, the horse was raced pass the garden. So, the horse is the object, somebody raced the horse. So, horse is the object and the activity which is racing, it is in the past tense and therefore, which was can be dropped. Therefore, the horse raced past the garden fell is the completely grammatical sentence. Except that, the parsing process will move on go up to garden. Think that the sentence is finished and encounter for fell and it would do the back tracking to discover that race past the garden is actually a modifier for horse with elision of relative pronoun and the option. So, this is an example of very interesting phenomenon which is challenge for phrasing. The phenomenon is that, the sentence seems together over. But, there is an additional textual metal matter, which demands that the whole phrasing process lead to do its works. Go back to particular point, which point it is? How to find out that particular point is accomplish problem. And therefore, these sentences are a big headache for the phrasing process. These sentences are known as garden phrase sentences presumably from this example. This particular example, which mentions the word garden. Another theory is that these sentences seem to lead you, lead the leader of the sentence or the lead the parser of the sentence, along a garden path from where the phrasing machinery will have to back track ok. This is the meaning. So, garden pathing is a very important challenge for all parsing algorithms. Whenever we design new passing algorithms those passing algorithms are tense against garden pass sentences to find out, how efficient there processing is? The next sentence is also garden pathing phenomenon. If you look at this slide, the old man the boat. This is the interesting sentence because here the garden pathing is on the phrase. The old man and the leader expectation is that, this whole thing is noun phrase, the old man. And then, he or she is in for a surprise because the old man the boat. The whole sentence seem to be without the verb. And therefore, an ungrammatical sentence, the verbs have to been disappear. Again, we have to do back tracking and we have to consider other possibilities ok. So, let us consider the sentence once again. The old man the boat. The old man can be noun phrase. What are the other possibilities? The man, the word man can be up. One meaning of man is, man as a noun. The other meaning of man is, man stair. We can manage ship and this would mean that we stair ship. The old man the boat would mean old persons ok old persons. Now, again peculiarity of English is .that one can use the adjectives as nouns. The old means, the old people. The old man the boat, means the old people, many word or stair the boat. There is the meaning of the sentence. Now, in this case what will happen is that, we will think that the sentence is ungrammatical. Because there is no verb here, having come here. If you look at the slide the old man the boat having come here, after man we expect the verb. We do not find the verb here. So, we back track and see, what is the alternate possibilities. The other possibilities is that the word man itself is a verb. In which case the old will be the noun phase, men is the verb and the boat is the objective. So, subject the old man, the verb boat and the boat object, subject verb object everything perfectly. So, this is the grammatical and this is found out by back tracking from before the point. So, this back tracking goes back and says that manage the verb. So, this is a garden pathing phenomenon just like before. Except that in this case the garden pathing is happening, because of the multiple part of speech of man. . Finally, the last sentences twin bomb strike in Baghdad kill 25. This is not a garden pathing sentence parsing but, this happens in the newspaper context. In the newspaper one is used to seeing headlines where the verbs are dropped. Headlines dropped verbs so, twin bombs strike in Baghdad that would finish the news item. Twin bomb strike in Baghdad, then we see kill 25. We know that this is not a normal newspaper heading. Twin bomb strike in Baghdad, instead the heading is complete sentence. Twin bomb strike in Baghdad till 25 and the normal procedure of processing is sentence proceeds. So, the problem here is the following, what I am trying to say is this. That the third sentence is not garden pathing sentence. Typical garden pathing sentence is not of that kind. What is happening is that, we are in particular frame of mind when we are reading a newspaper. So, we finish processing at twin bomb strike in Baghdad. We finish processing here, twin bomb strike in Baghdad, finish processing in here. After finishing we encounter motive and then we revise our opinion about the sentence. We, revise the processing a situation and then proceed with the other possibilities. So, this is the crux of matter in a garden pathing. Something is finished, some processing is finished. There is more material to be processed and therefore, backtrack and begin reprocessing with alternate possibilities. That is the whole crux of matter in garden .pathing. First sentence is the actual class garden path sentence, the second sentence and the third sentence are situation specific or part specific. . Proceed further, we now come to the next stage. What we have done so far is the processing of structure in the sentence. Namely: syntactic processing or parsing. We now, move on to much problem. The deeper problem of semantics, which is a much more complex task. In fact, in natural language processing a lot of progresses happen on syntactic analysis and parsing. There extremely sophisticated and very good passing algorithm. But, natural language processing to go, have to go have to really cover long distance. Before making inroads into the 5 points of semantic processing. So, this slide say all this things. Semantic analysis, the analysis semantic of sentences produces the knowledge representation of the sentence in a form of one of the schemes. The representation knowledge can in terms of predicate calculus or semantic nets or frames or conceptual dependencies and scripts. All of these are classical, extremely well known knowledge representation schemes. Gives predicates calculus is a branch of logic, a very classical field of knowledge representation which is fundamental to any kind of enforcing work. Semantic net is concerned with representation of knowledge in the form of graphs. Where, we have notes at arks capturing relationship between concepts. .So, semantics needs, these are semantics graphs. Frames are structured knowledge representation schemes in the form of slots and figure. Where, you have a table like structure with different slots and there fillers. Conceptual dependencies are representation of knowledge in the form of lenitive constructed and scripts captured typical situations. For example, going to lecture would mean, coming out from the hostel, coming out from home carrying one’s pen, paper, and geometry box etcetera. Walking the road or taking the vehicle and reaching the class, listening to a lecture taking notes, writing an examination, all these are routine activities connected with at beginning lecture. So such things are called scripts. We will cover knowledge presentation in some amount to detail eventually. So, semantic analysis is concerned with representation of a sentence in terms of one or more. Sometime it is more of this knowledge representation schemes. So, I take an example here, john gave a book to Mary. Here there is the give action, the giving action taking place. Who is giving? John is giving. So, john is the agent that is shown here, agent. What is he giving? He is giving a book. That is the object. To whom is he giving the book? Mary. So Mary is the recipient. Therefore, this give action has 3 entities especial entities, without which the give action is not complete. Give action, requires an agent namely john here. Requires a object namely the book here and it requires the very beneficiary of the action namely Mary here, the person who is receiving the object of giving. So, this is an important illustration, in the sense that it shows what is obtained as a result of knowledge extraction from a sentence. John gave a book to Mary is a sentence. From here, the structure that we have obtained is give as the main verb having a agent as john, having book as object and having the recipient as Mary ok. So, this then finishes the story about john giving a book to Mary. Now, this kind of semantic extraction is very, very crucial to natural language processing. Given a sentence if we do not understand, what does semantics of this whole sentence is, then any further processing is impossible. So, that kind of processing happen by means of what is called semantics roles. So, semantics roles capture the relationship of nouns present in a sentence, with the main verb of a sentence, the main action of the sentence. So, john .gave a book to Mary. Here the action is, give action. The nouns are: john, book and Mary and semantics roles are: agent, object and recipient respectively. So, these things: agent, object, and recipient, these are known as semantic roles. They capture the relationship of the noun present in the sentence with the verb of the sentence. Now, when we capture the semantics of the sentence, are ambiguously, preciously, correctly then the semantics roles have become very clear for the sentence. So, to obtain the meaning of a sentence the semantics roles have to identify without any mistake. I make this point to show that, if the semantic roles is not correctly identified, there it can lead to distortion of meaning and there are kinds of ambiguity which arises from the ambiguity of semantics roles. Look at this sentence here in the slide. Ambiguity in semantic roles labeling, we have an English sentence here. Visiting aunts can be a nuisance, it is a very well-known classical sentence in a natural language processing which illustrates the ambiguity of semantics roles. What can one make out from the sentence here? Visiting aunts can be a nuisance, one meaning is aunts who are visiting, aunts who are coming to see us, can be nuisance. In this case, the action is visit, who is performing the action? Aunts. So, aunts are the agents of visiting. The other reading of the sentence is visiting aunts can be a nuisance, where aunts are objects of visiting. So, I am called upon to visit my aunt and I am not happy about this. So, in this case the visitor is I, the agent of visiting is I and the object of the visiting is aunt. So, if you contrast this, with the previous sense of the sentence there the visitor was aunt. So, aunt is the agent, in a next meaning aunt is the object. So, this particular sentence has left the ambiguity of semantic role leveling unreserved. From the sentence one cannot make out, what is the semantic role of aunt? Is aunt the agent of visiting or is aunt the object of visiting? Again here I insist that, you translate the sentence in your own mother tongue and you will see that unless you commit a particular semantics roles, the sentence cannot be translated on ambiguity. You have to leave both the meanings open. So, one for example, if we take Hindi. . in this case I am visiting the aunt, so . the other meaning is visiting aunts, Aunts were visiting us. So, in this case it is Depending on that, the semantic role of aunt is changing and this is making the .sentence. English sentence ambiguous, the Hindi sentence or for that matter any Indian language sentence. I believe will not be ambiguous or in other words, the sentence when translated will have to commit to semantic role disambiguation. We take an example just below it which is an Hindi example . This particular sentence is ambiguous again because of semantic role. What is the action here? The action here is . ok, or to give. So, here what is happening is that a giving action is taking place or feeding action is taking place, which is the action of .. Now, there is no ambiguity with respect to object or what is being given effect. It is very clear it is . Sweets. The problem comes in, who is giving sweets to whom? . You have to look at to me now because I have to perform that action. . I will eat the sweets. So, in this case you are giving me, the sweets. So, I am the beneficiary of given action, I am the recipient the object is clear the object is . There is ambiguity with respect to agent and beneficiary. When I am the beneficiary . I get the sweets . you have the give sweets to me. The other reading is . I will give sweets to you. The other reading was you will give sweets to me. So, there is the semantic role reversal between me and you, in terms of agent and beneficiary. So, in the European languages which are close to Hindi like Marathi and Bengali they retained this ambiguity. In Bengali we have to say .. So, this sentence is ambiguous, because it does not specify who is giving sweets to whom. This sentence is ambiguous in Marathi also but, it is not ambiguous in Dravidian languages. Where you have to produce the sentence after resolving semantic roles because that will decide the case marker and others suffix information on the nouns. The semantic role will have to disambiguated, just like visiting aunts can be nuisance is an ambiguous sentence in a English. But, when we take into Indian language sentence, we have to commit to the semantics role and the ambiguity has to be resolved. Proceeding further, we come to pragmatics. So, what we saw was semantic role labeling which is processing of semantics. When you come to pragmatics, we are concern with how a sentence is processed by a user. When speakers utters the sentence, when listener .listen to that sentence and information giver and information recipient. How they look at the sentence? . So, this are the very very hard problem know in natural language processing. We look at the transparency here. And, see an example of pragmatics, being important. Pragmatics is concerned with modeling using intention. So, see here I have a piece of conversation. There is tourist who is in a hurry, the tourist is checking out of the hotel and he is motioning to the service boy. The service boy, boy go upstairs and see if my sandals are under the divan. Do not be late, I just have 15 minutes to catch the train. The boy running upstairs and coming back panting. Yes sir, they are there. So, the boy is answering the tourist question appropriately, there is no problem about that. So, he is saying that the sandal is under the divan but, the tourist intention was to get that sandal and he was already late for the train and therefore, this sandal had to be brought to him. But, the sentence, his sentence only specified to the boy that he should go and see if the sandal is under the divan. There was no specific instruction with respect to the boy, getting the sandal and giving to him. So, that was the crux of the problem, human beings are no problem with this kind of situation. They are extremely good at dealing with it. The pragmatics of the sentence, so when a sentence is uttered, we understand the intention behind that sentence. .We, also understand who is the recipient of the sentence? Now, in this tourist boy conversation, it was actually an instruction for the boy to bring the sandal. Though, the sentence did not said in explicit terms, the intention was that. And therefore, the stage of pragmatics, for the natural language processing is concern with modeling the user intention which is very hard problem to illustrate. What I mean by this? Let me give you another example, many times we sit on the dining tables and we point to the neighbor, is that water? You ask the neighbors is that water point to jug and say is that water? The intention actually is, for you to obtain the jug of water. You like to drink some water. So, when you ask your neighbor, is that water? This is not actually the question, it is actually a request in the form of a question. The request is, please past me the jug of water and if the neighbors just says yes or no, is that water? Yes, it is water and then does nothing about it. Then there is the pragmatics failure. There is no: syntax, semantics or lexical processing in failure. There is pragmatic failure, we the neighbor the dining table has not understood the intention behind the question. Notice that, the same sentence is alright in a case chemistry lab situation. So, it is possible that an examiner comes to a student, performing a practical examination and points to water and says, is that water? The examiner preassembly does not have any intention of drinking the water but, he is examination the student with respect to what that particular compound is. So, in a chemistry lab situation pragmatics again is ensuring that this question is actually question. In the dining tables situation, this question was not question, it was an actually a request. So, pragmatics is extremely situation specific. There is some kind of pragmatics playing a role in this sentence. Why India needs a 2nd October? Times of India 2nd October 2007. This particular sentence will not be understand very well not be understood very easily about by a non-Indian. That a person reading this sentence, we will have to understand the significance of 2nd October, which is the birth anniversary of Mahatma Gandhi. 2nd October has a special significant for many Indian. This is the birth anniversary of Mahatma Gandhi. We celebrate 2nd October with different kinds of a: poojas, bhajan and songs and so on. So, why India needs a 2nd October will be wrongly interrupted or completely not understood by a person who does not understand the meaning of 2nd October, the special significant of 2nd October. So, this again is a pragmatics consideration, it shows the importance of pragmatics where a special word knowledge or situation knowledge is .helping the user, speaker, listener to understand a sentence. So, this is the scope of pragmatics. Pragmatics is a very hard problem mainly because, it has to do user model it has to know user preference, likes, dislikes. Pragmatics also to know situation specific constructs and their significance. . Now, we move on to the last stage of processing presumably. The very very difficult stages once again, like pragmatics. This is the stage of discourse processing, discourse processing is concerned with processing of sequence of sentences. So, far we have been discussing only one sentence. A sentence which is demarcated by 2 full stops on 2 sides. In this case now, in this course we are concerned with sequence of sentences, I take here a piece of conversation. Mother to john, john go to school. It is open today. Should you bunk? Father will be very angry. So, this 4 pieces of text are uttered by a mother and the listener is a boy called john. Now, when we look at these 4 sentences, one of which is interrogative. We cannot but, we astonished is at the ease with which we process this sentences. Because there are many, many complex tasks involved here. The 1st challenge to process this sentence is, is the ambiguity of open. Open is very, very policy able verbs. A verb with many many different meanings and in this case we are concerned with that particular meaning of open, which says the school is working, school is open today. It is not at the school doors .and windows are open. The school is working. It is the open to means, the school is working today. So, there is ambiguity of open and we have resolve this ambiguity by taking the particular meaning of open, which is working. The next challenging problem here is ellipses, we mentioned before that in garden path sentences are. The difficulty of processing comes, one kind of difficulty processing comes because of elision. The relative pronoun and the auxiliary verb has dropped. And therefore, there is a difficulty in parsing. Now, when we consider this sentences here, the school is open today and should you bunk? Is the next sentence, which the mother utters or john should you bunk. The question is, how does john know what is the object of the bunking. Bunk is a verb, should you bunk what so, should you bunk the school naturally. The school as a piece of text is coming from one of the previous sentences, which sentence? The sentence is the first sentence. John go to school, it is open today. It is a pronoun which refer to the nouns here, this kind of pronoun the noun referencing is called an of area and big branch of natural language processing is concern with analysis referencing. How do you correctly buying, a pronoun with a particular noun. The next problem that we are try to resolve here, is the problem of ellipses, should you bunk? Should you bunk the school and the piece of text. The school came from the previous sentence, not the immediately preceding sentence. But, the sentence before that you can presumably see that this kind of ellipse handling may require obtaining textual material. Textual material from a vary distance sentence may be 5 or 6 sentence away. You have to pick up the textual material matter from that. Therefore, ellipse is handling is a difficult problem. This is a challenge. Now, we come to the last sentence, father will be very angry. Question is, why will the father be angry and it is imagine how or mind processes this sentence. There is complex chain of reasoning an application of word knowledge here. The father is angry because the son is disobedient, john is disobedient or he is angry because he is apprehensive about, john not going to the school and forming the bad habit and there by entering the possibility of a league future. .All this complex chain of reasoning comes to the father minds and he becomes angry. Again, we can see that we have applied world knowledge, namely the fact that discipline is important in our life. We have to attend the school regularly, we should have good habits. This is world knowledge and we are also resolving the ambiguity of father. This ambiguity is very interesting ambiguity. One ambiguity point is that the father is, john’s father. When we say father will be angry, it could be somebody else father also, jacks father. But, form the context it is clear that the father that is being refer to actual john’s father. The other ambiguity consideration is that, father itself is ambiguous, it can make in either the principle of the school or parent. So, john’s father would be john’s parent and the school’s father is the principle of the school and we also notice that somebody else father will not be angry, which is why we can sort of sorting that the father being refer to here is john father. It could also be, without any problem it could also be the principle of the school. Father will be very angry that possibilities also remains. So, the mind will operate with two hypothesis, one is john’s father and the other is school principle, the school’s father. And since, the mother is saying to this john there is some kind of proximity consideration, mother preassembly is referring to john’s father. He is the person, he is closet that ends and therefore, it possible means johns father. But, we cannot rule out the possibility of the principle of the school, being angry. So, in somebody what have I illustrate through this text? You can listen to me and not look at the slide. This means that when we process connected sentences, this course sentences we keep the knowledge of previous sentence in mind. We also try to predict of what sentence is coming in the future and the complex interaction of all this. Finally, produces the meaning in our mind and on the way, we solve many problems. The problem of ambiguity of words, multiple means of words. We solve the problem of ellipses dropping of text or text which is not mentioned. We solve the problem of all ambiguity of word, lexical ambiguity, worlds have been multiple meanings. Then complex is an emphasis to finally arrive it the meaning. .So, all this goes in our mind and it is indeed and a remarkable fact that, we can process discourse at all. We can process in a number of sentences together by solving all this little difficulties on the way. . Moving further, here is the very interesting example, look at this slide, the complicity of connected text. This was pointed to me by student of mine from an actual web example. Look at this sentence here, the john was returning from school dejected, today was the math test. Anybody, looking at the sentence when asked, what do you think about john? Who is john? So, the reader or the hearer of the sentence would, in all probability say that john is student in the school, john was returning from school dejected. Today was the math test. He probably could not do well in the math test. Next sentence, he could not control the class. So, after seeing the first sentence our hypothesis about john was, john is a student of the school. When we encounter this sentence now, he could not control the class and therefore, he was dejected, our hypothesis. The previous hypothesis, actually does not we are up to this new evidence. Who control the class? The teacher control the class and seems johns is returning dejected from the school and he could not control the class or hypothesis about john is slightly to be teacher. John is a teacher. So, the previous sentence showed so, previous sentence sort up let to the surmise the john is student. The next, sentence is saying john is possibly a teacher. .Next sentence in the slide, teacher should not have made him responsible. See here, we have come back to the student hypothesis about john, teacher should not have made him responsible. Whom does a teacher made responsible? It is a special student class who called the monitor, the head boy of the class. Now, we are back to john being a student, special kind of student namely monitor on the head boy. Finally, we encounter this sentence: after all he is just a janitor. So, this says that john was returning school, from the school dejected. Today was the math test, make john student. He could not control the class, makes johns teacher. Teacher should not made him responsible, makes john a monitor. And then, he finally when we encounter the sentence, after all he is just a janitor, that over throw all hypotheses about john neither teacher nor student nor monitor. He is a janitor who cleans the class rooms, swipes the floors and so on. So, this are very, very instructive example which shows that, in natural language processing for every new piece of data. We will the hypothesis form so far in our mind against the sentences which are arriving. So, the first sentence made john student, second sentence made john a teacher, third sentence made john monitor, special student and the forth sentence made john a janitor, the person who cleans the class. So, this shows that when we process a set of connected sentences it becomes a very complex problem, we not only solve world ambiguity. We not only solve anaphoras by finding a pronoun to noun, we not only solve ellipses where there are unmentioned text. We also form, we also solve the problem of forming hypothesis and discarding them on the phase of new evidence or data. .. Just look at the last transparency and with that we will close the class. This will be our next topic of discussion where we say that natural language processing has been attempted from two different directions. One is the classical approach to natural language processing, which make the huge of knowledge and rules. And, second approach is statistical machine learning approach to natural language processing, which is the current approached to natural language processing. With that we will close and we will discuss this topic in a next class.\n",
          "document_id": 1144860
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What is generative model?",
              "id": 544728,
              "answers": [
                {
                  "answer_id": 633986,
                  "document_id": 1144864,
                  "question_id": 544728,
                  "text": " Now, this is giving rise to what is called a generative model, if we have this sentence people jump high preceded by sentences begin a hat and the sentence end there dot. Then we have here, the tag hat for the first symbol which is hat and the dot tag for the last symbol dot, in between we have noun verb adverb for people noun verb adverb for jump, high verb adverb for high. So, you can see that only one tag is the correct tag in the context of the sentence, people is a noun, this noun will be chosen, jump is verb we chose this verb, high is an adverb we chose this adverb which qualifies the verb. So, people jump high would get the tags N V R preceded by hat followed by dot. Now, this model is called generative. Because, you can see that from the automaton, we find the words are generated by the tags it is as if the tags generate the words that‘s why it called a generative model,",
                  "answer_start": 23113,
                  "answer_end": 24006,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What tag do we use when the text of a language contains string return?",
              "id": 544712,
              "answers": [
                {
                  "answer_id": 633920,
                  "document_id": 1144864,
                  "question_id": 544712,
                  "text": "So, whenever the text of a language contains a string return in the alphabet of the foreign language, then we always place the tag FW",
                  "answer_start": 2774,
                  "answer_end": 2907,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are the tags for singular nouns and plural nouns?",
              "id": 544715,
              "answers": [
                {
                  "answer_id": 633923,
                  "document_id": 1144864,
                  "question_id": 544715,
                  "text": " Singular noun is NN, plural noun is NNS",
                  "answer_start": 5548,
                  "answer_end": 5588,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is tag set and penn treebank?",
              "id": 544764,
              "answers": [
                {
                  "answer_id": 634104,
                  "document_id": 1144864,
                  "question_id": 544764,
                  "text": "The set of tags is called the tag set and one of the very standard tags sets is the penn Treebank",
                  "answer_start": 725,
                  "answer_end": 822,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What did India come up with in terms of speech tags?",
              "id": 544718,
              "answers": [
                {
                  "answer_id": 633926,
                  "document_id": 1144864,
                  "question_id": 544718,
                  "text": "We in India, have come up with a part of speech tags set for pan Indian languages, languages of not the India in though area are family languages of southern India dravidian family, languages of the north last the Tibetan family and Austro-Asiatic languages namely munda and khasi. So, we have tried our best to come up with a tag set for India languages, which should be used for annotating data and subsequently doing national language processing. ",
                  "answer_start": 6979,
                  "answer_end": 7429,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is the short form of Coordinating Conjunction?\n",
              "id": 544765,
              "answers": [
                {
                  "answer_id": 634105,
                  "document_id": 1144864,
                  "question_id": 544765,
                  "text": "here is CC, which is the short form for Coordinating Conjunction",
                  "answer_start": 1509,
                  "answer_end": 1573,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Describe an example of Coordinating Conjunction?",
              "id": 544766,
              "answers": [
                {
                  "answer_id": 634106,
                  "document_id": 1144864,
                  "question_id": 544766,
                  "text": "the example of that is the jack and Jill. So, this is a phrase, jack and Jill may be they go up the hill and this CC is attached to the word and, which is a conjunction, joining jack and Jill. So, an underscore CC shows the part of speech tag of an.",
                  "answer_start": 1575,
                  "answer_end": 1824,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is auxilary verb?",
              "id": 544720,
              "answers": [
                {
                  "answer_id": 633937,
                  "document_id": 1144864,
                  "question_id": 544720,
                  "text": " So, auxiliary verbs place in important role it carries, information about gender number person this auxiliary verb.",
                  "answer_start": 10442,
                  "answer_end": 10558,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is the short form of Cardinal number?",
              "id": 544767,
              "answers": [
                {
                  "answer_id": 634107,
                  "document_id": 1144864,
                  "question_id": 544767,
                  "text": " CD or Cardinal number.",
                  "answer_start": 1840,
                  "answer_end": 1863,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Describe the example of cardinal number?",
              "id": 544768,
              "answers": [
                {
                  "answer_id": 634108,
                  "document_id": 1144864,
                  "question_id": 544768,
                  "text": "if we look at this phrase four children, four is a numerical adjective qualifying the noun children and this is a cardinal number CD is attached here, if the word was fourth, the fourth child t h is other then the part of speech tag would be the tag for ordinal number. So, that indicates an order, so cardinal number tag would be place,",
                  "answer_start": 1868,
                  "answer_end": 2205,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is bigram markovian assumption?",
              "id": 544723,
              "answers": [
                {
                  "answer_id": 633963,
                  "document_id": 1144864,
                  "question_id": 544723,
                  "text": " this actually is a bigram markovian assumption, what does it say, it says that fine apply the chain rule get the expressions sub expression the constituent triviality values. However, this terms very complicated to compute. ",
                  "answer_start": 17700,
                  "answer_end": 17925,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is speech tagging?",
              "id": 544704,
              "answers": [
                {
                  "answer_id": 633912,
                  "document_id": 1144864,
                  "question_id": 544704,
                  "text": "So, as is shown in the slide now, part of speech tagging is a process that attaches each word in a sentence with a suitable tag from a given set of tags. ",
                  "answer_start": 571,
                  "answer_end": 725,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "Mod-01 Lec-11 Part of Speech Tagging counted...\n\nIn this lecture, we continue with our discussion on Part of Speech Tagging of words in a sentence. We have remarked many times that part of speech tagging is the first fundamental operation on raw text, and subsequence stages of natural language processing, like phrase detections, parsing, semantic low leveling and so on follow after part of speech style. This is also a very nice problem to illustrate, statistical natural language processing, the application of machine learning on natural language problem alright. . So, as is shown in the slide now, part of speech tagging is a process that attaches each word in a sentence with a suitable tag from a given set of tags. The set of tags is called the tag set and one of the very standard tags sets is the penn Treebank, which we show in the next slide. But before that just some small remarks, we are saying that part of speech tagging is the process of attaching tags on the words of a sentence. So, that thing to note here is this entity call tag, which is like a level on each word, what these labels are we .are going to see in a minute alright. So, the words are given this levels and this are very informative, for subsequence stages of processing. . Progressing with our discussion, this is an important slide which shows the Penn Treebank tag set, it is a sample there are about above 30 tags and we show here, a few of them may be above 10 and what is shown here these level. So, the first level here is CC, which is the short form for Coordinating Conjunction, the example of that is the jack and Jill. So, this is a phrase, jack and Jill may be they go up the hill and this CC is attached to the word and, which is a conjunction, joining jack and Jill. So, an underscore CC shows the part of speech tag of an. The next one is CD or Cardinal number. So, if we look at this phrase four children, four is a numerical adjective qualifying the noun children and this is a cardinal number CD is attached here, if the word was fourth, the fourth child t h is other then the part of speech tag would be the tag for ordinal number. So, that indicates an order, so cardinal number tag would be place, DT is a determiner example the underscore DT sky, EX is Existential there as oppose to, an adverbial there here the example is, there was a king. So, there underscore EX was a king, this there note is a pleonastic it is a pleonastic, it is a backward subject English sentence demand a subject to be compulsorily present. So, this there is given the tag example, EX existential as appose to the adverbial there. FW is the foreign word, here is a sentence . underscore FW indicating it is a foreign word . .means word. So, we are explaining the meaning of the string .. So, whenever the text of a language contains a string return in the alphabet of the foreign language, then we always place the tag FW; however, if . was return as shabd. So, in this case these would be an absorption of a foreign word transliterated into the language of the text. In that the case, . would be a noun and the noun tag would be placed on this. So, note the difference between . written in . and . written in English, when written in . embedded in English text it is, in the foreign word underscore FW otherwise it is the part of speech that it has in the sentence. IN is preposition or subordinating conjunction. So, for example, play with ball, with underscore IN is the entity here and IN is the tag for with, this can also be used for subordinating conjunction and example, we can see later. JJ stands for Adjective, many times people have wondered where this JJ is coming from adjectives, it could be abbreviated as Ad or Adj, but why JJ. So, the example that is first underscore JJ car, fast car it is an adjective, one conjunction is that adjective is open pronounced as adjective and it has two j sounds, adjacent to each other and most likely that give rise to this two letter tag JJ. JJR is adjective comparative, so fast car was the previous example, now it is faster car, fast car compare to another car and this is underscore JJR. JJS adjective superlative. So, fastest car JJS fastest underscore JJS, LS is List item marker for example, somebody is proposing to buy this grocery items, bread butter and jam the listing is given here, 1 bread, 2 butter, 3 jam. So, 1 underscore LS, 2 underscore LS, 3 underscore LS, they are the tags for this list items markers. MD is the Model, this is a sentence here, you may go as appose to you go and may here is the model auxiliary and is given the tag MD with an underscore. NN is probably the most important tag, which is the noun tag, which is used for singular or mass. So, water underscore NN, NNS is plural noun, boys underscore NNS. If you are wondering, why there is a separate tag for NNS note that, in English most nouns can be used as verbs and the third person singular form of a noun and the of a verb and the plural form of a noun are open identical. So, if I say place it is not clear is it multiple place, mini place in the sense of drama let us say or is it the third person singular form of the verb play. .NNP is proper noun singular, so john underscore NNP is the proper noun. So, these illustrates some important points in this tag set, if you are pay attention to the tags then you would see that, lot of care has gone into deciding how to designate tags properly. For example, there is a very certain discussion on why, plural nouns should have a separate tag compare to singular noun. Singular noun is NN, plural noun is NNS and the reason for that as I said is that, almost all English nouns can be used as verb play can be a noun meaning a drama dramatic performance or a play could be the act of playing which is a verb. Now, if we see an isolated word in the text, in the form of place than we would not know whether this is a plural noun or is a at third person singular form of play, the task of part of speech tag is to place the correct tag on the word. So, the part of speech tagger uses limited context to window and it places the tag on the target word. Now, if this distinction is not meet, between singular noun and plural noun and in the part of speech tag corpus, which is used for training if we have many typically have many singular third person singular number verb forms and we also have many, many plural nouns. If noun and plural noun is not cleanly separated, then the part of speech tagger will get vary of an confused between the third person singular number form of the verb and the plural form of the noun, will analyze these certain issue with examples later. So, the point I am making is that when, a part of speech tag set is design, normally very experience people with lot of inside into how language operates. As well as how a computational system inspired of it is many limitations, is required to do leveling with this kind of experience people discuss part of speech tag design. We in India, have come up with a part of speech tags set for pan Indian languages, languages of not the India in though area are family languages of southern India dravidian family, languages of the north last the Tibetan family and Austro-Asiatic languages namely munda and khasi. So, we have tried our best to come up with a tag set for India languages, which should be used for annotating data and subsequently doing national language processing. So, I hope you understand the importance of designing a tag set with lot of insight and correctness. .. Let us proceed, so we have already looked at a number of examples, with words and the part of speech tags. . Now, part of speech tag task is a essentially disambiguation task, look at this sentence here. In English, we have this sentence I bank, on the bank on the river bank for my transactions I concede that this is not a very natural sentence, which is a rather artificial sentence. But, it illustrates the points I would like to make, the first bank is a verb this .means depend, I depend on the bank this is a noun, on the river bank this is also a noun, the third bank is also a noun for my transactions. So, the first level disambiguation task which is execute it through part of speech tagging is the disambiguation of categories, this first bank is verb other two banks bank 2 and bank 3 or nouns. Now, this disambiguation is simple, but crucial for subsequence stages, another disambiguation which will have to may affected, is the disambiguation of second bank, bank 2, bank 3, the first bank is the place where financial transactions take place, the second bank is the embankment the land escaped by the side of the river. So, these disambiguation is known as what sense disambiguation, it is possible to have same part of speech for a word, but the sentence can be different. So, the first bank is a verb, other bank is noun these ambiguity is not on the characteristic of English, we seat in Hindi and many other languages for example, the word . it can be a noun, which means a food or a verb which means to eat. . the first . is noun and the second . is verb. . We, can also look at this nice example ram . ram sings well and ram . ram is a good boy. So, here you can see that the only word, which is different between the two sentence is . and . is a verb. So, . is an adverb qualifying this verb . is a noun, so . here is a adjective for the noun, so ram . and ram . first . .adverb second . adjective. So, the part of speech tagger has to disambiguation with this. If you say that this disambiguation is not difficult because you see the adverb is followed by a verb, the adjective is followed by a noun. Then you might be miss late into what is call the false positive and false negative, which we have discuss last time in the lecture. I would just like remind you that between . you can have some amount of text ram. . So, this rule that and adverb should be follow by a verb, will not hold true here, there will rule will have to be made more robust. Similarly, ram . here are also, we can introduce a particle ram . ram .. So, you can have text in between adjective or noun and therefore, the rule will have to be more robust, we have more problem in this sentence, . look at the word . and ram . the first . is a helping verb, for . it carries the tense information, gender number information also. So, ram . if it was seta, . so . for would change if the tense was past tense ram .. So, auxiliary verbs place in important role it carries, information about gender number person this auxiliary verb. Ram . here, this verb is this . is not a auxiliary verb it is not helping another verb, it is called copular verb, copular verb also carries the information of gender number person tenses, so on. So, it is very difficult to distinguish between VCOP and we VAUX unless the word morphologically changes in this two situations, from the context it can become very difficult many times, will see examples later disambiguation examples. .. Now, we discuss the process of parts of speech tagging this is a computational process. So, you have understood what the problem is and now, where entering to the computational discussion, we would like to understand how one could make an algorithm to produce these labels automatically that is a task. So, that process is that, list all possible tag for each word in the sentence and choose the best possible tag sequence. . We have an illustration here, people jump high is a sentence, people can be noun or verb jump can be also noun or verb, high can be noun verb adjective and we actually start .with probabilities. So, people jump high will finally, get this level if the program is working correctly, it should get the level noun verb and adverb, actually high can be an adverb also noun verb and adverb. However, each word is multiple part of speech text and we will choose that tags sequence which is the highest probabilities, this is where the probabilistic approach. So, noun verb adverb tag will be the highest probability tag here. . This is illustrated here, people jump high. So, this hat symbol is a important special symbol, which is at the beginning of a sentence dot is again a special symbol, which is at the end of a sentence also called pull stop and for each word we place all possible tags as columns of tags on the words. So, people can be noun verb, adjective adverb jump can be noun verb adjective adverb, I can be noun verb adjective adverb. So, off course you will object saying that people can never been an adverb, jump how can it be adjective and, so on. But, this is only for the purpose of keeping the discussion simple and also illustrating, how a simple algorithm would work now, how a first cut algorithm would work. The first cut algorithm will not try to be intelligent right from the beginning, it will try to take all possible options or all possible tags for each word and then do a disambiguation or selections. So, if you look at this picture here, then for hat symbol conventionally the tag is hat itself. So, for the hat symbol hat, people it can have all this four possible tags, which is from the whole tag deprecatory of course, people can .would be a adverb, so this will come out to be probability is 0, jump can have all this tags I can have all this tags. Now, when we connect all this tags together. So, this hat is connected to 4 and is connected to the 4 tags after it v is to connected to all the 4 tags after it a similarly, to all the 4 tags or again to all the 4 tags. So, from here you can see 16 arcs go to this 4 tags for the next what. Similarly, from here there would be 4 into 4, 16 times going into the next words tags. So, this way we will define a graph and on part of speech tagging problem or part of speech tagging determination problem, becomes finding a path, through this whole graph. And this graph is the set of levels, which should be placed on the words. Now, this graph traversal before we being discussing the mathematical aspects, this graph traversal would finally, find out the best possible tags sequence the best possible levels for the words, what does this best possible mean, the best possible means the highest probability path from the hat symbol to the dot symbol. So, these highest probability path taking only one level per word, is found out by the odd math’s computation. So, the best possible path here means the higher probabilities path. . So, this mathematics is based on an argmax computation, on which we have already spend quite in amount of tag. And you will see that, this fundamental ideas or broad to be a here. So, the best tag sequence we call as T star, T star is the best possible tag sequence, T star is found out from argmax of P T given W where, W is the word .sequence and T is the tag sequence. So, if we please the tags on the set of words and we have the sequence T and the word sequence is W. Here, we apply baye’s theorem and we convert this expression into P T into P W given T. Now, this is also an old point discuss many times in previous lectures that it is the problem, which determines whether we should apply baye’s theorem or not and there by, adopt a generative approach or a discriminative approach. Now, in this case the part of speech tag is determine through a generative approach, P T given W is converted to P T the prior probability of the tag sequence into P W the likely would probability of the word sequence given the tag sequence. So, this particular part may sink counter intuitive or one intuitive, one would think what is this P W given T because our very natural thinking about this problem is that given the word sequence, we would like to find out the tags sequence. However, has we remark before, we convert this probabilities in to this two parts, prior probabilities and the likely would and the probability, acts a nice filter, to eliminate bad possibilities. So, these tags sequence P T is a representation for highly likely tags sequences as learnt from the corpora. So, this point I suppose is clear to you, we have the prior probability which many times acts as a model an ideal model, for the label sequence that we reproduce. So, the P T part in the formula is a filter, which helps isolate bad tag sequences and which gives weight ages to good tag sequences, we understand this in a minute the only counter intuitive part there is the P W given T. And that came because we wanted to apply baye’s theorem and we will have to make some engineering judgments, take some engineering steps to make use of this expression P W given T. So, let us go ahead with a mathematical formulations P T is written as P t 0 equal to hat followed by t 1, followed by t 2, followed by t 3 and, so on. Until we have t n plus 1 which is equal to dot. So, we have here this tag sequence t is t 0, t 1 up to t n plus 1, these now can be broken down into a number of expressions, number of probability values by applying what is call the chain rule, which is a fundamental operation in a probability. So, what you have done is that we have apply baye’s theorem, first fundamental operation and second fundamental operation is this chain rule, which is P t 0 into P t 1 given t 0 P t 2 given t 1 t 0 P t 3 given t 2 t 1 t 0 and, so on. Until we meet our last .expression which is P t n plus 1 given t n t n minus 1 up to t 0. So, this whole probability of the sequence is converted into probabilities of single levels, given the presiding tag levels alright. So, baye’s theorem applied, chain rule applied now we apply what is called the markovian assumption. And the expression that we have written here, in the last line P t i given t i minus 1 i going from 1 2 n plus 1, this actually is a bigram markovian assumption, what does it say, it says that fine apply the chain rule get the expressions sub expression the constituent triviality values. However, this terms very complicated to compute. So, P t n given t n minus 1 t n minus up to t 0, we have to deal n terms here, in the conditioning point what the markovian assumption is saying is that, this regard anything which is very distant from the current tag, if the current tag is extremely faraway it does not have influences on the tag at the current position. So, P t 2 given t 1 t 0 is we are saying that at the second position, the tag is t 2 depending on the two tags, just before it and anything beyond that is not useful to compute to consider. So, if I take P t 5 for example, the tag at the fifth sequence, the only influencing factor on this is t 4 and t 3 the only the first two previous tags. Here, we have given a very simple expression, we have made what is call the bigram assumption, we are saying that each tag depends only on the previous tag, on the tag coming before it which is the condition a part. So, I would present you with a small exercises and request you to do this to be convinced of the bi gram assumption or the markovian assumption. .. So, the exercise is this take a tagged corpora for example, john laughs loudly, so here the tags are john NNP laughs is a verb, which is a main verb VM, loudly is adverb RB. So, take it at corpses you will have this kind of tags along with the words. . After this from this tag corpses, compute n grams or compute P t n given t n minus 1 t n minus 2 t n minus 3 up to t 0, this we are saying is almost equivalent to P t n given t n minus 1 t n minus 2 this is trigram mark of assumption. .. So, what I request you to do is take P t let say 5 and t 4, t 3, t 2, t 1, t 0 which you know, is equal to count of the pattern t 0 t 1 t 2 t 3 t 4 t 5 divided by count of t 0 t 1 t 2 t 3 and t 4. . If our assumption is correct if the mark of assumption is correct, we will see count of t 0 t 1 t 2 t 3 t 4 t 5 divided by count of t 0 t 1 t 2 t 3 t 4 will be approximately equal to we take it on the next page. .. T 5 that count divided by count of t 3 t 4 alright. So, this whole sequence t 0 to t 5 divided by t 0 to t 4 is approximated as t 3 to t 5 when t 3 to t 4. So, that is the bigram assumption and if are markovian assumption is correct, this to count should come out to be approximately equal telling us that mean for a particular tag at a position or for a tag at a particular position, we did not consider any word which is beyond a certain distances that is the meaning. So, this you should verify from a training corpuses, we will mention important corpora tag corpora towards the end of the lecture and it should be possible for you to verify this quite easily, but you should do this to be convinced of the operation of the markovian assumption alright. .. Proceeding further we see that P t is equal to this expression and after making bigram assumption it comes out to be equal to P t i given t i minus 1 i going from 1 to n plus 1. So, this first part of the expression the prior probability comes out to be product of bigram entities P t i, t i minus 1 is nothing but count of the number of times t i is followed by the t i minus 1 divided by number of times t i minus 1 appears. . Alright we move on to the next probability, which is the lexical probability. So, P W given T is shown here, which is equal to P W 0 given t 0 to t n plus 1, t 0 to t n plus 1 is .nothing but capital T, P W 1 given W 0 and capital T. This the chain P W 2 is nothing but P W 1 W 0 and the whole tags sequence finally, we have the two expressions here, P W n given W 0 W n minus 1 and the whole tags sequence t 0 t n plus 1, the last expression is P W n plus 1 which is condition by W 0 to W n and the whole tags sequence t 0 to t n plus 1. Now, we make an assumption which does not have much of linguistic support, it is more like an engineering decision for the purpose of computation. However, the results of part of speech tagging shows that this is a not a bad assumption after all, the assumption here is that a word is determine completely by it is tag, this is inspired by speech recognition. So, I have attired a set of words now, I know what the part of speech tag of the next word most likely to be and given that is the part of speech tag which will appear after the sequence of words, what is the probability of a particular word coming there. So, if I have sentence I see a black and now, it is clear that the most likely after black is a noun, so now, what is the probability of attiring I see a black cow or I see a black dog or I see a black umbrella. So, dog, umbrella, cow all this are nouns which are lexical items, what is the probability they can appear at that position the last word position, given that the tag there is a noun. So, this kind of word prediction problems are quit common in daily of speech recognition and the lexical probability assumption is inspired by. So, if you look at the expression here, t w given t has been converted in to a chain rule expression, after that by making this assumption that a word is dependent only on the tag at the position, we obtain P W 0 given t 0 into P W 1 given t 1 up to P W n plus 1 given t n plus 1. So, this comes out to be equal to i equal to i going from 0 n plus 1 P W i given t i. .. Now, this is giving rise to what is called a generative model, if we have this sentence people jump high preceded by sentences begin a hat and the sentence end there dot. Then we have here, the tag hat for the first symbol which is hat and the dot tag for the last symbol dot, in between we have noun verb adverb for people noun verb adverb for jump, high verb adverb for high. So, you can see that only one tag is the correct tag in the context of the sentence, people is a noun, this noun will be chosen, jump is verb we chose this verb, high is an adverb we chose this adverb which qualifies the verb. So, people jump high would get the tags N V R preceded by hat followed by dot. Now, this model is called generative. Because, you can see that from the automaton, we find the words are generated by the tags it is as if the tags generate the words that‘s why it called a generative model, the second part of the probability expression the likely would probability P W given t, which is converted in to product of P W i given t i is the generative model part of the computation, as if the words are generated from the tag. So, we go through this automaton and we have the probabilities of the arcs from tag to tag, this is known as the bigram probability P t i given t i minus 1 and we have the lexical probabilities, probability of people given n, probability of people given verb, probability of people given adverb, this are the lexical probabilities and the R probabilities between two tags is call the bigram probability are the transition probability alright. So, when we .make a traversal from hat to dot, we find out for very word a tag and the tag sequence we get is the best possible tag sequence, in the sense of being the highest probability path. . So, this here shows how the bigram probabilities are represented is an important data structure, which it is very useful to remember you see on the column we have the tags N V A noun verb, adjective let say in the row also we have N V A. Every cell in this matrix denotes the transition triviality, since it is a bigram probability situation, where we say that every tag depends only on the previous tag; we have a matrix where the column or tags and rows are also single tags. .. If it was a trigram probability situation consider a trigram probability situation. Suppose we have the trigram probability situation and we have P of a noun given that the previous two tags were noun and verb. So, the situation is N V N, so when you have this kind of trigram situation, we again have a matrix of transition probabilities noun verb adjective; however, on the row we have the conditioning part, which is a pair of tags. So, would have N comma V and then we have V comma A let say we can have A comma A. So, what is the meaning of this the meaning of this suppose, I take up this cell supposes this cell is our cell of attention, here will the place probability of a verb being preceded by a verb and adjective that is this sequence V A V. So, the row will have tupelos instead of single tags, if is a bigram then you have single tags on the rows. So, is it clear the columns will always have tags, single tags, rows will have pairs triples quadruples, entaple, depending on the markovian assumption we make. If the assumption is a quadric gram assumption a tag depends on the previous three tags. So, the whole thing is a four tap let, three previous t tags than on the row we will have three symbols triples, so this is about the transition probability, the lexical probability table also we look similar it will be a matrix. So, in the situation we have let say noun verb and adjectives, which are on the rows on the column we will have actual words. So, how many columns will this matrix have this matrix will have as many words as there are in the language, are if we want to be more conservative we can say that the .number of columns will be equal to the number of distinct words the corpus. So, now, if you look at the cell n and people, this is 10 to the power of minus 5, this means what is the probability of the word people given that the tag is went. That means, at a particular position, what is the probability that the word is people given that the tag at the position is noun. Now, this how will you compute you will clearly compute this, by finding out how many times the noun tag appears, have it in the denominator and let it divided how many times does people appear in those noun positions. So, probability of people of given n, so how many nouns are there in the corpora and out of them how many are people that ratio is the is the probability value. So, this shows the 10 to the power of minus 5, which means there are many, many nouns in the corpus. And people appears one once out of 10 to the power 5 nouns, for every 10 to the power 5 nouns one is a people. So, this the meaning of this probability, we can see some zeros here what is the probability of people given adjective, so are what is the probability of jump given adjective. So, this kind of probabilities are very low almost nil jump has never possible been used in that purpose as an adjective. . So, I suppose this is clear, so let me just repeat this two data structures once again, they are very impotent for our understanding lexical probability is given by the lexical probability matrix. .. And in the previous slide, bigram probability is given by this transition probability matrix. . Now, how do we calculate this probability values is from the actual data, what have we done, so for just recapitulation what we done, so for is that we have set the part of speech time problem as a sequences leveling task used or max computation. Apply baye’s theorem divided in to two parts probability of probability of the tag sequence, multiplied .by the likely would probability of likely would of the word given the words sequence given the tag sequence, we applied markovian assumption. And then we obtain P t i given t i minus 1 which is the bigram assumption, then we obtain probability of w i given t i which is the lexical probability assumption. So, markovian assumption preceded by baye’s theorem application chain rule, know this probability gave rise to the transition probability table, also the lexical probability table. And how do we do the calculation from the actual data, this will discuss in the next class, but you can see, this is a raw piece of text and the whole thing is pos tag. . From the pos tag we record the numbers and then compute the probabilities, we will do the calculation in the next lecture.\n\n",
          "document_id": 1144864
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What is the main concern of language processing?",
              "id": 543850,
              "answers": [
                {
                  "answer_id": 628232,
                  "document_id": 1144866,
                  "question_id": 543850,
                  "text": " resolving ambiguity is the main concern of language processing. ",
                  "answer_start": 1735,
                  "answer_end": 1800,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What does Homophones mean?",
              "id": 543855,
              "answers": [
                {
                  "answer_id": 628237,
                  "document_id": 1144866,
                  "question_id": 543855,
                  "text": "homophones, which are words which are .nearly identical in the pronunciation",
                  "answer_start": 2357,
                  "answer_end": 2433,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is word boundary processing?",
              "id": 543858,
              "answers": [
                {
                  "answer_id": 628240,
                  "document_id": 1144866,
                  "question_id": 543858,
                  "text": "word boundary processing is very important problem, the example which was given was . tomorrow, or the sentence I got a plate which can broken in two different ways, either to mean I got up late, which means I woke up late or I got a plate, I have a plate with me.",
                  "answer_start": 2456,
                  "answer_end": 2720,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is Phase boundary detection?",
              "id": 543859,
              "answers": [
                {
                  "answer_id": 628241,
                  "document_id": 1144866,
                  "question_id": 543859,
                  "text": "phase boundary detection is a problem and disfluency is concerned with how a speaker inters fares as sentences, with meaningless sound just to be able to organize is thought. ",
                  "answer_start": 2732,
                  "answer_end": 2907,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Describe about Dictionary in NLP?\n",
              "id": 543870,
              "answers": [
                {
                  "answer_id": 628252,
                  "document_id": 1144866,
                  "question_id": 543870,
                  "text": "Dictionary indeed forms a part of the natural language processing, just like morphology processing is concern with breaking up a word and the obtaining a suffix, obtaining the features which are contained on the world. Dictionary on the other hand is concerned with how to store the root words after morphological processing one obtains a root words and how this words are stored in the dictionary, what kind of the information do we have t imbed in the dictionary.",
                  "answer_start": 4306,
                  "answer_end": 4771,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Explain the importance of Question Answering conpect in the field research?",
              "id": 543872,
              "answers": [
                {
                  "answer_id": 628254,
                  "document_id": 1144866,
                  "question_id": 543872,
                  "text": "There is the field of research called question answering, which is a very upcoming field in today is world of internet and in question answering a machine is made to answer uses question. So, this is a field of information extraction, information retrieval it is a branch of those field and it gets it support from information. When the documents are obtained from the internet the document are proceed to manufacture in answer so to say.",
                  "answer_start": 5348,
                  "answer_end": 5786,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Describe an example regarding Question Answering concept?",
              "id": 543876,
              "answers": [
                {
                  "answer_id": 628258,
                  "document_id": 1144866,
                  "question_id": 543876,
                  "text": " if we ask a question, how many years does a dog live? This question please supposes that, dog is the animate entity it has a stage of being bound then, there is the period of being alive, which finally, terminates in the dog being dead. So, how many years does a dog live? That this pre support all these intricate and small were curtail pieces of knowledge, it is many times requiring internecine. So, this kind of processing is assisted by a rich dictionary without a rich lexical knowledge, this kind of processing is not possible.",
                  "answer_start": 5790,
                  "answer_end": 6325,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is 1st step in disambiguating process explain with an example?",
              "id": 543879,
              "answers": [
                {
                  "answer_id": 628261,
                  "document_id": 1144866,
                  "question_id": 543879,
                  "text": "in the disambiguating process. The 1st step is part of speech disambiguation, look at the example here, the dog as a noun is a animal and dog as a verb means to pursue, to run after, to go after so, one could for example, say an sentence wherever, ram went miss fortune dog came, that means wherever, ram went means fortune went after him. So, this is the part of speech of dog as a verb and the 1st part of speech in 1st line dog is a noun here dog is an animal. The words and disambiguation problem comes in, after parts of speech is ambulation is over.",
                  "answer_start": 6719,
                  "answer_end": 7274,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is the forcing function of Computer Science and NLP?",
              "id": 543847,
              "answers": [
                {
                  "answer_id": 628229,
                  "document_id": 1144866,
                  "question_id": 543847,
                  "text": "forcing function for the computer science and natural language processing happens to be the forcing function for A I ",
                  "answer_start": 895,
                  "answer_end": 1012,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is Science goal and Engineering goal is all about?",
              "id": 543848,
              "answers": [
                {
                  "answer_id": 628230,
                  "document_id": 1144866,
                  "question_id": 543848,
                  "text": "The science goal is to understand the way the language operates and engineering goal is to build systems that analyze and generate language; and reduce the man machine gap. ",
                  "answer_start": 1464,
                  "answer_end": 1637,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are the important linguistic particles in NLP?",
              "id": 544617,
              "answers": [
                {
                  "answer_id": 632763,
                  "document_id": 1144866,
                  "question_id": 544617,
                  "text": "quantifier are very important linguistic particles in natural language processing.",
                  "answer_start": 22543,
                  "answer_end": 22625,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is Existential Quantifier and mention it's symbol?",
              "id": 544596,
              "answers": [
                {
                  "answer_id": 632321,
                  "document_id": 1144866,
                  "question_id": 544596,
                  "text": "And some as a quantifier is called existential quantifier ok and the symbol for that, is a reverse E a E is written this way instead of that, you turn it other way a mirror image and this becomes the existential quantifier.",
                  "answer_start": 22315,
                  "answer_end": 22538,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is one sense per discourse in NLP?",
              "id": 544088,
              "answers": [
                {
                  "answer_id": 628264,
                  "document_id": 1144866,
                  "question_id": 544088,
                  "text": " the statement one sense per .discourse so, this is very important assumption it says that when a word appears in the document, it does not have the multiple senses, it has typically one sense ok. ",
                  "answer_start": 8181,
                  "answer_end": 8378,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is scope of qualification of no in NLP?",
              "id": 544618,
              "answers": [
                {
                  "answer_id": 632779,
                  "document_id": 1144866,
                  "question_id": 544618,
                  "text": "We say the depending on the scope of no the sentences has one or the other meaning. one meaning of the sentence is that you cannot find any smoking area which will allow Hookas inside so, this is the sense of not any. Not that does not exist a smoking area, which will allow hook as inside. So, here no smoking areas the scope of no is, smoking areas this qualified smoking areas qualifying the whole sentences, the smoking areas will allow Hookas inside, this whole .sentence is being negative by the presence of no. The scope of the no is complete sentence therefore; no smoking areas will allow Hookas inside. The other meaning of the sentence is there are certain area special areas called smoking areas ok, the special areas called the no smoking areas and these no smoking areas is such that, they allow Hookas inside, they may not allow other think they may not other thinks, they may not allow segregates and signers but, they will allow Hookas inside. So, you can possibly see that depending on what is the scope of no? Whether it is the complete sentence after these or just this compound ward smoking area depending on that, the meaning takes completely reversal ok. The one meaning of the sentence is that, there are certain designated areas called smoking areas, none of them allow Hookas and there are also some areas called no smoking areas they are however, allows Hookas so, this the meaning.",
                  "answer_start": 22990,
                  "answer_end": 24399,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Describe the example of Disambiguation in NLP?",
              "id": 544479,
              "answers": [
                {
                  "answer_id": 631037,
                  "document_id": 1144866,
                  "question_id": 544479,
                  "text": "for example, look at this sentence the chair emphasis the need for adult education, the chair emphases the need for the adult education. The word which is being disambiguated here is chair. Now, chair can be either piece of furniture or the person holding the chair right so, when we look at this sentence what is the meaning of the chair? From the context it is clear that, we mean a person here the, chair emphasized the need for adult education presumably the furniture cannot talk emphasizing is a kind of talking and therefore, emphasizing is the clues to disambiguation.",
                  "answer_start": 9159,
                  "answer_end": 9735,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is preposition phrase ambiguity?",
              "id": 544619,
              "answers": [
                {
                  "answer_id": 632782,
                  "document_id": 1144866,
                  "question_id": 544619,
                  "text": "preposition phrase ambiguity and this comes from the multiple possibilities of attachment of the preposition phrase in the sentence. ",
                  "answer_start": 24665,
                  "answer_end": 24798,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Describe various examples of Disambiguation after technological develpoments?\n",
              "id": 544482,
              "answers": [
                {
                  "answer_id": 631040,
                  "document_id": 1144866,
                  "question_id": 544482,
                  "text": "For example, let us look at the 1st line the word justify, the words justify as the its own original meaning justifying something, that means validating something, where as in this particular sentence justify the right margin, this means aligning the words of sentences with the right margined this meaning of justify is align and this meaning came because of what processing, when what processing came ok. So, software assisted word processing at the time the word justify also came into our parleys and this means aligning the sentence with the right margin. So, justify came because a word processing. The word xerox is a new word which came because, the xerox machine where brought into play copy our machines. So, the word xerox we came new verb digital trace, these are new expression and a very interesting expression. Digital trace acutely describes, the trace of the individual as he or she navigate the words or the internet all the your else that we visit, all the pages that is we browse they form what is called our digital trace. So, in this sense you can imagine that, Google as such engine is the extreme powerful entity, influencing all rights. Every click of hours every u r l that, we have visited every page that we have browsed everything has a record with ok. So, Google as a complete digital trace of our activities on the internet so, this particular expression digital trace it .came, because of search engine and also because, of the internet. A clear indication the technology brings new phrases a new words, into our day to day life. The next word is also an interesting word this is the expression, which came as the combination of two words communication and faking, communicating and faking.",
                  "answer_start": 13433,
                  "answer_end": 15155,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is Typo, Texto and Speko?",
              "id": 544504,
              "answers": [
                {
                  "answer_id": 631062,
                  "document_id": 1144866,
                  "question_id": 544504,
                  "text": "The typo means a typing mistake so, texto is a texting mistake that means you are trying to send on S M S so, trying to send the S M S over the mobile and if you make a mistake then, this is known as texto. And from that, change the expression speko you are trying to speak something and make a mistake while speaking this is called as speko ok. So the word typo instead of two more words texto this came in the context of mobile technology, speko came in the context of speaking. So, again we can see that new technology name the technology of the mobile, had to be when you came it introduce this new term called texto",
                  "answer_start": 17859,
                  "answer_end": 18479,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Describe an example of preposition phrase ambiguity?",
              "id": 544626,
              "answers": [
                {
                  "answer_id": 632800,
                  "document_id": 1144866,
                  "question_id": 544626,
                  "text": "We have in front of us a very classical sentence I saw the boy with the telescope I saw the boy with the telescope, this sentence is ambiguous because, with the telescope is attach to what why or saw. One meaning of the sentence is I saw a boy and the boy had a telescope that means I saw the boy with the telescope. The other meaning is I saw the boy and I saw the boy with the telescope using a teleshop. So, you can see that, if we was substituted by using, then there is no ambiguity apparently I saw the boy using a telescope now, even then there is an ambiguity because, again the word using does not clarify who is that in the telescope I saw the boy using the telescope, the boy might be using the telescope or I might be using the telescope.",
                  "answer_start": 24798,
                  "answer_end": 25548,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What would be the use of communifaking? ",
              "id": 544487,
              "answers": [
                {
                  "answer_id": 631045,
                  "document_id": 1144866,
                  "question_id": 544487,
                  "text": "The use of communifaking could be for example, humorously speaking a giving a way of disappear for a boring meeting, suppose you are sitting in the meeting and you do not like the way things are presiding it is very boring discussion and you would like to excuse yourself from the meeting, then you can communicate into a mobile, while acutely you are not communicating you are faking communication and this is called a situation of communifaking",
                  "answer_start": 15532,
                  "answer_end": 15978,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Explain about Structure detection and Problem parsing.",
              "id": 544506,
              "answers": [
                {
                  "answer_id": 631064,
                  "document_id": 1144866,
                  "question_id": 544506,
                  "text": "here S is the sentence and this is a tree structure which computer scientist a very familiar with the sentence has two phrases, noun phrase and the verb phrases under the noun phrases you have the noun in this particular case it is the word I which pronoun, under the word phrases you have a word and noun phrase, the particular verb in this case is like and the noun phrases goes to noun, namely a mangoes. .This whole sentence is I like mangoes . so, I like mangoes these as this structure, it is a noun phrases and the verb phrase, the word phrases is again broken into two entities for an noun phrases ok. This is known as structure detection and the whole problem of converting a sentence in a tree like structure like this, is called the problem parsing",
                  "answer_start": 18933,
                  "answer_end": 19692,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is Communifaking?",
              "id": 544488,
              "answers": [
                {
                  "answer_id": 631046,
                  "document_id": 1144866,
                  "question_id": 544488,
                  "text": "The word is communifaking this means pretending to talk on a mobile, when you are actually not talking ok so, that is a very interesting situation somebody he has taken up the mobile and he is talking in to the mobile but, actually this person is not talking with anybody. So, he is faking communication that, is why it is called communifaking",
                  "answer_start": 15156,
                  "answer_end": 15499,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Explain Scope ambiguity with respect to NLP?\n",
              "id": 544507,
              "answers": [
                {
                  "answer_id": 631065,
                  "document_id": 1144866,
                  "question_id": 544507,
                  "text": "scope challenge it is called the scope ambiguity. If you see the sentence the old men and women we are taken into safe locations, the old men and women were take into safe locations. The question in this sentence is who is old? Are both men and women old or only the men that are old ok. Because, there is a adjective here, old how much of the text does the adjective qualify? There is the question. Both men and women are old or only men are old. This is known as the scope ambiguity",
                  "answer_start": 20063,
                  "answer_end": 20547,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is The state of Arizona is famous for?",
              "id": 544628,
              "answers": [
                {
                  "answer_id": 632818,
                  "document_id": 1144866,
                  "question_id": 544628,
                  "text": "The state of Arizona is famous for its space research program and the program is an extremely thrilling program in the state so, much so that, most of the mountains in Arizona are fitted with a telescope, which are used for the absorbing the planet and the star.",
                  "answer_start": 26429,
                  "answer_end": 26691,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Explain about Discomgooglation?",
              "id": 544489,
              "answers": [
                {
                  "answer_id": 631047,
                  "document_id": 1144866,
                  "question_id": 544489,
                  "text": "discomgooglation this is anxiety or discomfort at not being able to access internet, this is a very modern phenomena a very resent phenomenon in our life more many of our young people are glue to the computer searching the web, searching for the information, looking at different web pages, looking at pictures, browsing pages and so on. So, all this is the goggling activity, you are very active on the internet searching for information and browsing. If this individual is not able to use the search engine, not able to axis the internet, then he or she suffers from anxiety syndrome, this particular syndrome is called discomgooglation, this is discomfort at not being able to do goggling not be able to do google. So, this is the discomgooglation it is a new word",
                  "answer_start": 16136,
                  "answer_end": 16903,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Explain Quantifier and Universal Quantifier in NLP?",
              "id": 544550,
              "answers": [
                {
                  "answer_id": 631792,
                  "document_id": 1144866,
                  "question_id": 544550,
                  "text": "write down the term for no and this star is called quantifier, just look at the word here No, the meaning of the no is not any ok. So, this is a quantifier I write here the term for such entities linguistic units quantifier ok. There are other quantifiers also no is not only quantifier, all is a very important quantifier all, all men are mortal so, this is the quantifier application over men, all men this is all, another quantifier is some. So, some men are rich these also quantifier so, no, all, some these things are known as quantifiers. Let me also mention, that all and some have a special place in logic and artificial intelligent. .. Let me write it down for you, all is called a universal quantifier",
                  "answer_start": 21173,
                  "answer_end": 21885,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Describe structural ambiguity examples.\n",
              "id": 544631,
              "answers": [
                {
                  "answer_id": 632848,
                  "document_id": 1144866,
                  "question_id": 544631,
                  "text": "structural ambiguity examples here all of them are actual examples, which occurred, when I was in a confidence or I was in the discussion .with somebody for example, this I heard this particular sentence I heard in a particular conference. I did not know my P D A, P D A is a hand held device, had a phone for 3 months, I did not know my P D A had phone for 3 months. The question is this for 3 months which is the duration; it is a diuretic phase for 3 months it refers to which event. So, one of the possibilities that, here is it reference to this knowing event, I did not know for 3 months that my P D A had phone. So, this is one reading I did not know my P D A had phone for 3 months and other reading is for 3 months is attached to the noun phone so it is the qualified for phone so, the since of the sentence will be I did not know my P D A had a phone and this phone was therefore, 3 months this is one meaning. There is another attachment point for 3 months, may be you can guess which is the certain point, for 3 months can also be attach to P D A a very interesting rule of thumb is to see that, preposition phrases in a sentence can be attached potentially to any noun that comes before it ok. So, it can be attached to I it can be attached to P D A it can be attached to phone and it can also attached to the main part of the sentence. So, all this attachments all the 3 different, 4 different attachment, they will give you rights to 4 meaning. So, one meaning was I did not know for 3 months that my instrument had a phone, another meaning is I did not know that my P D A for 3 months that means this P D A was which me for 3 month, maybe it was loaned for 3 month had a phone and finally, I did not my P D A had a phone for 3 months, that means the phone itself was called 3 months",
                  "answer_start": 30138,
                  "answer_end": 31936,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is helicopter parenting?",
              "id": 544492,
              "answers": [
                {
                  "answer_id": 631050,
                  "document_id": 1144866,
                  "question_id": 544492,
                  "text": "helicopter parenting, this is phrase and it means over parenting just like a helicopter goes over a terrine, it keeps on moving over a terrine seeing",
                  "answer_start": 16941,
                  "answer_end": 17090,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Describe structural ambiguity real time example?",
              "id": 544632,
              "answers": [
                {
                  "answer_id": 632852,
                  "document_id": 1144866,
                  "question_id": 544632,
                  "text": "depending on the naturalness of the situation depending on our life experience we can exclude some meanings for example, phone for 3 months is a strain construction in this particular sentence so, most likely the actual reading of this sentence is I did not know from 3 months in my, this was over heart by me in a conference, there is an actual sentences in the newspaper which do my attention, these are also very famous sentence in the sense that, similar kind of construction abounds in news paper, story newspaper writing, the camera man short the man with the gun, when he was near Tendulkar. I will read this sentence once again the camera man short the man with the gun when he was near Tendulkar. The different meanings of the sentence arise from a complex interaction or many different factors ok, one of the factor is in fact that, the camera man short the man with .the gun when he was Tendulkar the 1st fact is that short has 2 meanings ok. This is the act of shooting the shooting can be by a camera which camera man does, or a shooting can be done by the gun which can be by a terrorist for example, or by a murderer so, the camera man short the man with the gun when he was near Tendulkar. If somebody comes back and says that, no the word camera man makes the meaning very clear for the works out, makes it very clear the camera man short the man because, of this phrases the phrases of the word camera the meaning of shoots becomes very clear, this is not the case. There is nothing which prevents the camera man from carrying an actual gun I will doing the shooting activity. Therefore, it is possible that the camera man is shooting with the gun. Now, the camera man shot the man with the gun, when he was near Tendulkar again there is this complex interaction of the preposition phrase with an house the camera man shot the man with the gun that means, he shot he took a picture of the man who had a man with the gun is a complete noun phrase, in this case with the gun is attached to man ok, or the camera man actually fired a shot with the man with his own gun. In this case the gun is with camera man. So, this is the 1st develop ambiguity for actual 2nd level of ambiguity, 1st level of ambiguity was two meanings of shots, the 2nd level of ambiguity is with the gun being attach to the man, or being attach to shoot ok. So, this gun was used as an instrument for suiting or it is qualified for men. The next level of ambiguity comes from close attachment here, when he was near Tendulkar the ambiguity here is who is who was near Tendulkar, The camera man or the man ok. So, there are these 2 possibility camera man or the man and depending on that ok depending on that, there are more meanings of the sentences ok. So, this sentence really can have really can have a very large number of meanings depending on combinations of multiple possibilities of attachment, multiple meanings of the words sort and multiple attachments coming from the clause ok. .. So, let me just write down where this ambiguity comes from this is an interesting point and it clarifies our notion of how ambiguity arises. So, the sentence is the camera man sort the man with the gun when he was Tendulkar so, ambiguity because, of shot 2 meanings ok, with the gun this is the preposition phase, 2 attachment points, means shot or man 2 meanings of shot camera or gun. So, 2 meanings here 2 attachment points, another possibility is the clause, when he was near Tendulkar ok. So, this is the clause when you was near Tendulkar is a clause. The question is he is reference, what is he refer to? This he refers to the man or the cameraman so, again 2 possibilities ok. So, 2 meanings of sort 2 attachment points for with the gun and 2 references point for he, camera man or man ok. So, when we multiply all this possibilities 2 into 2 into 2 we find that it there are 8 different meanings of this sentence ok. So, this particular sentence the cameraman shot the man with the gun when he was Tendulkar has 8 meanings on the 1st level of analysis. Where it is differently to that this particular sentence, which is very complex sentence and it has many more meanings apparently there are 14 meanings of this, many of quite of them are actually nonsense ok. But, this 8 meanings that, we discussed about they are extremely real, they are very much real and this meanings are all possible and they are competing meanings. Now, this meanings becomes apparent I definitely heartily to do this exercise, this meanings become apparent, when you translate the sentence, according to this meanings .in to your own mother tongue. ",
                  "answer_start": 31943,
                  "answer_end": 36560,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Define Helicopter parenting?",
              "id": 544493,
              "answers": [
                {
                  "answer_id": 631051,
                  "document_id": 1144866,
                  "question_id": 544493,
                  "text": "there is some over bearing parents who are extra careful what the children are doing and in their extra care they are doing what is called helicopter parenting.",
                  "answer_start": 17121,
                  "answer_end": 17281,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "Mod-01 Lec-02 Stages of NLP\n\nWe begin lecture 2 natural language processing, in lecture 1 we gave an introduction to the course and also define the subject. We proceed with stages of natural language processing, which would form the content of lecture two. . Let us continue on the slide as I had mentioned before the faculty instructor is myself and my area of research is natural language processing, machine learning and course home page will be soon created. Proceeding further I would like to remind the once again the areas of artificial intelligence and their inter dependents, we find here that natural language processing comes on the left bottom corner, which is dependent on machine learning, knowledge representation logic and such. There are many other areas of artificial intelligence and they have this inter dependents, these us explain last time and we also say that A I is the forcing function for the computer science and natural language processing happens to be the forcing function for A I itself. .. We once again mention the course content, will cover sound that means speech processing, word and word forms morphological processing. . Structures which means sync acting processing passing, meaning representation means semantics and we have to conserve applications. This is a plan for the whole course and these are the topics to be covered. .. Natural language processing was defined as a branch of artificial intelligence with 2 goals. The science goal is to understand the way the language operates and engineering goal is to build systems that analyze and generate language; and reduce the man machine gap. . We also mention that, ambiguity is the cracks of the problem in natural language processing. And resolving ambiguity is the main concern of language processing. .. We then, introduce the stages of language processing and the phonetic and phonology, which is concerned with the sound morphology concerned with words, lexical analyses, how make the dictionaries? And how to store words in them? Syntactic analysis parsing of sentences, Symmetric analyses is concerned with meaning representation, pragmatics means how a sentence is used? And discourse is a processing of connected of sentences. . We proceed it further and understood that, there are something called homophones, which are words which sound similar near homophones, which are words which are .nearly identical in the pronunciation. In speech processing word boundary processing is very important problem, the example which was given was . tomorrow, or the sentence I got a plate which can broken in two different ways, either to mean I got up late, which means I woke up late or I got a plate, I have a plate with me. Similarly, phase boundary detection is a problem and disfluency is concerned with how a speaker inters fares as sentences, with meaningless sound just to be able to organize is thought. . can we broken up into . will come or . will come The last topic we discussed, in the last lecture was morphology or the word formation rules, how plurals influence a noun forms? Of all forms influence aspect modality and so on. We also mention that, by using finites machine, one can produce morphology analyses and this is a very important problem in computer science. Language defer in the regions of morphology for example, Dravidian, Hungarian, and Turkish, language are rich in morphology Chinese an English or poor in morphology. So, this is where we stopped in the last class. Now, we proceed with the further discussion name with the stage of natural language processing. .. Now, comes lexical analysis, which is the dictionary making, if you look at the example given in the slide it refers to dictionary axis and obtaining the properties of the word. For example, the word dog, this is noun, which correspond to the lexical property, it takes s in plural, which is the morphological property, it is animate which is the semantic property, it is the 4 legged animal, which is again the semantic property, its carnivore that means it is the meat again a semantic property. So, one might wonder why we need to store all this information on to the dictionary so, when we produce the dictionary entries in a lexicon, one of our main concern is how to research in this whole detail structure? Dictionary indeed forms a part of the natural language processing, just like morphology processing is concern with breaking up a word and the obtaining a suffix, obtaining the features which are contained on the world. Dictionary on the other hand is concerned with how to store the root words after morphological processing one obtains a root words and how this words are stored in the dictionary, what kind of the information do we have t imbed in the dictionary. For example, the example which was given was the dog in the dictionary. Dog takes s inverse so, many dogs are barking, here dog has become down after morphological analyses s is the plop and the root words is dog, at the point of time when the processing has to go further, it needs to know, what are the properties of the word .dog? So, at that point of the time, the dictionary comes handy and it tells us that, dog is a noun, it takes s in the plural its semantic property at that it is animal, it is animate it has 4 legs and so on. So, who uses this kind of information? There is the field of research called question answering, which is a very upcoming field in today is world of internet and in question answering a machine is made to answer uses question. So, this is a field of information extraction, information retrieval it is a branch of those field and it gets it support from information. When the documents are obtained from the internet the document are proceed to manufacture in answer so to say. So, if we ask a question, how many years does a dog live? This question please supposes that, dog is the animate entity it has a stage of being bound then, there is the period of being alive, which finally, terminates in the dog being dead. So, how many years does a dog live? That this pre support all these intricate and small were curtail pieces of knowledge, it is many times requiring internecine. So, this kind of processing is assisted by a rich dictionary without a rich lexical knowledge, this kind of processing is not possible. So, here is the important of lexical analysis. If you look at the bottom of the slide the main challenge in lexical analysis is lexical or word sense disambiguation, which indeed is one of the most challenging problem of natural language processing. We would like to dwell on disambiguation through a set of examples. . .So, these transference lexical disambiguation, shows the steps involved in the disambiguating process. The 1st step is part of speech disambiguation, look at the example here, the dog as a noun is a animal and dog as a verb means to pursue, to run after, to go after so, one could for example, say an sentence wherever, ram went miss fortune dog came, that means wherever, ram went means fortune went after him. So, this is the part of speech of dog as a verb and the 1st part of speech in 1st line dog is a noun here dog is an animal. The words and disambiguation problem comes in, after parts of speech is ambulation is over. So, for example, when you decide the dog is a noun the next question we ask, is dog and animal or is the particular sense of dog a very detachable person, one of the sense of the dog is this very detachable person. So, from the context one you have to make out whether dog is to being used as an animal or dog is used as a detestable person. So, we must mention here that, when a word is used many meanings of the word come into play depending on the context. Typically in a document what operates is called one sense per discourse assumption, typically a word used in only a single sense. . Let me write down these particular hypothesis, we are discussing, the branch of natural language processing, as a branch of artificial intelligence and we are also discussing, word sense disambiguation, digestion in this context. And we are saying that a word typically follows one sense per discourse. So, this is the statement one sense per .discourse so, this is very important assumption it says that when a word appears in the document, it does not have the multiple senses, it has typically one sense ok. So, let us proceed lets proceed with the discussion, look at the transference once again, dog has this to senses as an even and as a detestable person. Now, when we see dog in the text, what do we make out from the context? Do you mean animal? Or do you mean a detestable person? Now it is so happens that, dog the predominate sense of dog is animal, the sense of detestable person is very low and these are typical phenomenon in most of the languages, for most of the words, each word has a very predominant meaning, other meanings are more or other meanings are less frequency compared to this particular meaning. So, the animal sense of dog is more frequent detestable person sense of dog is less frequent. Now, it to disambiguate a word, we need word relationship in a context for example, look at this sentence the chair emphasis the need for adult education, the chair emphases the need for the adult education. The word which is being disambiguated here is chair. Now, chair can be either piece of furniture or the person holding the chair right so, when we look at this sentence what is the meaning of the chair? From the context it is clear that, we mean a person here the, chair emphasized the need for adult education presumably the furniture cannot talk emphasizing is a kind of talking and therefore, emphasizing is the clues to disambiguation. So, let us remember this very important point mean words in disambiguation, namely: when we find out the sense of a word from its context, the context provides clues critical clues with respect to the since. And when we design a computer algorithm for version disambiguation we have to see how to obtain that, clue from the sentence so, for example, in this sentence the chair embassies the need for adult education the clue word is emphasize. Now, when we create the automatic system for disambiguation it has to identify that emphasis is an activity which can be done by animate being and therefore, chair is not furniture, this is the way the alga rhythm is proceed, there are lots of interceding case involving words and disambiguation in the course will cover words and disambiguation algorithms in lot of detail quite a few lecture, we divided towards a disambiguation. .So, at this point we just mark this particular fact that, from the context a clue will come in and disambiguate the word. Now, this is an this particular sentence which I showed as on elastration is constructed by me but, watson disambiguation is not really an artificial problem it appears day to day at all the time, it is very common in day to day communication, look at these particular advertisement in satellite channel one of the satellite channel, which I have seen on t v. Look at this sentence watch what you want, when you want, this particular sentence if you think carefully has two meanings, watch what you want when you want. The word watch as two meanings one meaning is look intimately look carefully and the other meaning of watch is be careful. Now, one meaning of this sentence will be careful what you want, when you want so, just be watchful what is that you desire? And what is the time when you desiring? There is always a right time for desiring anything and also that, things should appropriate, this is the meaning of that sentence one meaning 1st meaning. The 2nd meaning of watch is look carefully so, watch what you want, when you want here watch means the act of watching something, act of looking at something. So, watch you what you want, when you want so, this is the satellite channel add a add advertisement for a satellite channel. So, this advertisement is sort of giving propaganda for the satellite channel, it is saying watch what you want, when you want you have this kind of the freedom on this satellite channel it is scaring there are two meanings of this sentence coming from two different senses of this word, not only words but, phases also have a multiple meaning for example, the phase here ground breaking ceremony versus ground breaking research, ground making ceremony means the starting reach well some kind of worship, some kind of pooja done for starting and activity, or starting an organization or even you know starting a building, starting the activity of constructing a building, that is ground breaking ceremony. And ground breaking research is something which is a par nearing kind of work is starts a line of research. So, here the phrase ground breaking has two meaning ok. So, may be through this particular slide, we have made this very important part that words have multiple meanings whenever, we have to phrase a sentences, we have to 1st solve this difficulty that words a multiple meanings and in this particular context which meaning of the word is being talked about ok. So, that is the meaning which with you proceeds further for the next stage phrasing of the sentence. .. Next proceed to the next slide, it is also a very common observation that, technological developments bring a new terms additional meanings and nuance for existing terms. For example, let us look at the 1st line the word justify, the words justify as the its own original meaning justifying something, that means validating something, where as in this particular sentence justify the right margin, this means aligning the words of sentences with the right margined this meaning of justify is align and this meaning came because of what processing, when what processing came ok. So, software assisted word processing at the time the word justify also came into our parleys and this means aligning the sentence with the right margin. So, justify came because a word processing. The word xerox is a new word which came because, the xerox machine where brought into play copy our machines. So, the word xerox we came new verb digital trace, these are new expression and a very interesting expression. Digital trace acutely describes, the trace of the individual as he or she navigate the words or the internet all the your else that we visit, all the pages that is we browse they form what is called our digital trace. So, in this sense you can imagine that, Google as such engine is the extreme powerful entity, influencing all rights. Every click of hours every u r l that, we have visited every page that we have browsed everything has a record with ok. So, Google as a complete digital trace of our activities on the internet so, this particular expression digital trace it .came, because of search engine and also because, of the internet. A clear indication the technology brings new phrases a new words, into our day to day life. The next word is also an interesting word this is the expression, which came as the combination of two words communication and faking, communicating and faking. The word is communifaking this means pretending to talk on a mobile, when you are actually not talking ok so, that is a very interesting situation somebody he has taken up the mobile and he is talking in to the mobile but, actually this person is not talking with anybody. So, he is faking communication that, is why it is called communifaking, what would be the use of this? The use of communifaking could be for example, humorously speaking a giving a way of disappear for a boring meeting, suppose you are sitting in the meeting and you do not like the way things are presiding it is very boring discussion and you would like to excuse yourself from the meeting, then you can communicate into a mobile, while acutely you are not communicating you are faking communication and this is called a situation of communifaking ok. So, communifaking could be useful in disappearing from a boring meeting. The next word is also a very new expression it is called this discomgooglation, discomgooglation this is anxiety or discomfort at not being able to access internet, this is a very modern phenomena a very resent phenomenon in our life more many of our young people are glue to the computer searching the web, searching for the information, looking at different web pages, looking at pictures, browsing pages and so on. So, all this is the goggling activity, you are very active on the internet searching for information and browsing. If this individual is not able to use the search engine, not able to axis the internet, then he or she suffers from anxiety syndrome, this particular syndrome is called discomgooglation, this is discomfort at not being able to do goggling not be able to do google. So, this is the discomgooglation it is a new word. The next phrase which is the phrase helicopter parenting, this is phrase and it means over parenting just like a helicopter goes over a terrine, it keeps on moving over a terrine seeing what is below it?. Similarly, there is some over bearing parents who are extra careful what the children are doing and in their extra care they are doing what is called helicopter parenting. .So, all this words you can see came from technological advancements, justify because of what processing xerox because, of the xerox machine digital phrase, because of the internet, communicating because of mobile, technology, discomgooglation because of goggling, helicopter parenting it has a metaphorical association with helicopter. . Let me give you one more word which is also very interesting I came to know about this yesterday from the newspaper this word is called texto and there is aligned word speako. So, they came from the word typo, what is the word typo mean? The typo means a typing mistake so, texto is a texting mistake that means you are trying to send on S M S so, trying to send the S M S over the mobile and if you make a mistake then, this is known as texto. And from that, change the expression speko you are trying to speak something and make a mistake while speaking this is called as speko ok. So the word typo instead of two more words texto this came in the context of mobile technology, speko came in the context of speaking. So, again we can see that new technology name the technology of the mobile, had to be when you came it introduce this new term called texto ok. So, let us proceed and this particular transparency showed that we create new words in our language or an existing word gets a new meaning let say just justify, new word come because of the technology and we have to deal with the meaning of these words. .. Next we come to a very important stage, where we have graduated from the processing of words ok. So, we have processed the words now we come to the structure of the sentence, the phrases. So, here S is the sentence and this is a tree structure which computer scientist a very familiar with the sentence has two phrases, noun phrase and the verb phrases under the noun phrases you have the noun in this particular case it is the word I which pronoun, under the word phrases you have a word and noun phrase, the particular verb in this case is like and the noun phrases goes to noun, namely a mangoes. .This whole sentence is I like mangoes . so, I like mangoes these as this structure, it is a noun phrases and the verb phrase, the word phrases is again broken into two entities for an noun phrases ok. This is known as structure detection and the whole problem of converting a sentence in a tree like structure like this, is called the problem parsing the parsing technical analyses. And we will look many algorithm for parsing as a the course process. We again mention here, the problems which in natural language processing system encounters while parsing. . Look at the next transferring the challengers which come in syntactic processing, are known as structural ambiguities. The 1st challenge which I show here, is a scope challenge it is called the scope ambiguity. If you see the sentence the old men and women we are taken into safe locations, the old men and women were take into safe locations. The question in this sentence is who is old? Are both men and women old or only the men that are old ok. Because, there is a adjective here, old how much of the text does the adjective qualify? There is the question. Both men and women are old or only men are old. This is known as the scope ambiguity that means, what is the reason of influence or scope of the adjective here in this sentence the word old, how much text does it qualify? Look at the next sentence here, this ambiguity is an extremely on interesting ambiguity because, it completely reverses the meaning of the sentence, here what we have is an .adjective like entity no smoking areas will allow hook as inside So, when you look at the sentence what meaning does it convey to you, the word no is the quantifier not any the meaning of no is not any. Now, what is the scope of no? Because, it is it acts like an attitude quantifier acts like an entity. . Let me write down the term for no and this star is called quantifier, just look at the word here No, the meaning of the no is not any ok. So, this is a quantifier I write here the term for such entities linguistic units quantifier ok. There are other quantifiers also no is not only quantifier, all is a very important quantifier all, all men are mortal so, this is the quantifier application over men, all men this is all, another quantifier is some. So, some men are rich these also quantifier so, no, all, some these things are known as quantifiers. Let me also mention, that all and some have a special place in logic and artificial intelligent. .. Let me write it down for you, all is called a universal quantifier, universal quantifier and in logic when you go to predicate calculus, the quantifier all is expressed by a special symbol this is the symbol, this is known as the power all quantification symbol. This is a V ups and down, with a bar passing through the center of the V. So, it is almost like upside down a except that both its end are extended in both directions. So, this is called a universal quantifier standing for, for all. And some as a quantifier is called existential quantifier ok and the symbol for that, is a reverse E a E is written this way instead of that, you turn it other way a mirror image and this becomes the existential quantifier. So, quantifier are very important linguistic particles in natural language processing. And they their processing is also a very important job should be carefully done, otherwise we can have ambiguity. So, let us look at the sentence which we are discussing at some time back, before the discussion on universal and existential quantifier. These sentence no smoking areas will hook as inside the question was, what is the scope of qualification of no? We say the depending on the scope of no the sentences has one or the other meaning. one meaning of the sentence is that you cannot find any smoking area which will allow Hookas inside so, this is the sense of not any. Not that does not exist a smoking area, which will allow hook as inside. So, here no smoking areas the scope of no is, smoking areas this qualified smoking areas qualifying the whole sentences, the smoking areas will allow Hookas inside, this whole .sentence is being negative by the presence of no. The scope of the no is complete sentence therefore; no smoking areas will allow Hookas inside. The other meaning of the sentence is there are certain area special areas called smoking areas ok, the special areas called the no smoking areas and these no smoking areas is such that, they allow Hookas inside, they may not allow other think they may not other thinks, they may not allow segregates and signers but, they will allow Hookas inside. So, you can possibly see that depending on what is the scope of no? Whether it is the complete sentence after these or just this compound ward smoking area depending on that, the meaning takes completely reversal ok. The one meaning of the sentence is that, there are certain designated areas called smoking areas, none of them allow Hookas and there are also some areas called no smoking areas they are however, allows Hookas so, this the meaning. Now, these two examples will be sufficient to tell us that, adjectives and quantifier unless there scope is completely precise the determine, they can lip the ambiguity confusion of weakling. Next kind of synthetic ambiguity which we move on two now, is called the preposition phrase ambiguity and this comes from the multiple possibilities of attachment of the preposition phrase in the sentence. We have in front of us a very classical sentence I saw the boy with the telescope I saw the boy with the telescope, this sentence is ambiguous because, with the telescope is attach to what why or saw. One meaning of the sentence is I saw a boy and the boy had a telescope that means I saw the boy with the telescope. The other meaning is I saw the boy and I saw the boy with the telescope using a teleshop. So, you can see that, if we was substituted by using, then there is no ambiguity apparently I saw the boy using a telescope now, even then there is an ambiguity because, again the word using does not clarify who is that in the telescope I saw the boy using the telescope, the boy might be using the telescope or I might be using the telescope. So, you can see the difficulty of the sentence whether with remains or does not and if it is substituted by a financial verb using, even then the ambiguity does not go so, the question is who has the telescope a boy or I? And this is arising because, with the telescope is a qualified for boy or not. Next sentence I saw the mountain with a telescope in this case there is no ambiguity apparently ok, I saw the mountain with the telescope why should they have an ambiguity in this because, with the telescope is definitely the instrument of seeing I am performing the same action with the telescope and therefore, .the meaning, that the mountain has the telescope does not arise here that possibility does not arise so, it is an ambiguity in the sense. But, it is not a such a simple case it is country specific, domine specific, there is a state in united states called Arizona. The state of Arizona is famous for its space research program and the program is an extremely thrilling program in the state so, much so that, most of the mountains in Arizona are fitted with a telescope, which are used for the absorbing the planet and the star. So, if these sentence are attired in Arizona it continuous to be on ambiguity sentence because, in Arizona you have mountains with telescope, you have mountains which have telescope in there. So, again the question that will arise, where is the telescope is the telescope with me or is it with a mountain? So, we are invoking the word knowledge here something called the word noise, the mountain connect their instrument of telescope instrument of seeing which is fine the mountain is not instrument of seeing and therefore, the mountain cannot has the telescope but, we are did not take in to account the possibility, that a mountain will be fitted with the telescope for making observation of the celestial figures, in which case this whole sentence is ambiguous fine. So, I think this point is well understood, that ambiguity is a settled and certain feature it is situation dependent time dependent, country dependent, region dependent, Next sentence I saw the boy with the pony tail here at last we can heap a sigh of relief, this sentence is definitely not ambiguous the pony tail is with the boy, I cannot see anybody with the pony tail, pony tail is not an instrument of seeing, this is the crucial piece of world knowledge which is being used and that ambiguity is reserved now. However, the word knowledge is a situation dependent, region dependent, the in the previous case the world knowledge did not come handy when the sentenced was been uttered in Arizona. Now, this kind of sentence is once sees in text book and one wonders whether a structural ambiguity is indeed a real life problem, does it indeed arise in day to day communication. Here I say that structural ambiguity like word sense ambiguity is a very ubiquitous problem, it is all for wearing I saw a news paper headline in times of India, 20 years later B M C pays further 2000000 for causing sons death. 20 years later Bombay municipality cooperation pays further 2000000 rupees for causing sons death. Now, in this case who is a causing the son’s death? Who is responsible for sons death? .It is something to do with the Bombay municipality corporation, may be some vehicle which the municipality cooperation was using was responsible for sons death but, if the phrase for causing sons death is not correctly attached, it can lead to a completely different meaning and completely unacceptable meaning may be comical meaning. So, read it this way 20 years later B M C pays father 2000000 for causing sons death, these might be to the B M C is paying father 2000000 for causing sons death. It is might be contrive to read B M C is paying further 2000000 rupees as a reward because, the father has caused the son’s death. So, by causing the son’s death the father is able to get rupees 2000000 rupees so, these are completely unacceptable meaning we know it from our real day to day experience and it is very carpenter that, unless the attachment problem is properly solved, the there is meaning discussion complete discussion meaning in the sentence. So, let me just summarize what we say in this slide? We discussed, the scope ambiguity which is the region of influence of quantifiers an adjectives how much of text the qualify? And we discuss the very classical problem natural language processing, preposition phrase ambiguity were we are concerned with how the preposition is attaching to the particular word in the sentence. . Let us specify other, there are other structural ambiguity examples here all of them are actual examples, which occurred, when I was in a confidence or I was in the discussion .with somebody for example, this I heard this particular sentence I heard in a particular conference. I did not know my P D A, P D A is a hand held device, had a phone for 3 months, I did not know my P D A had phone for 3 months. The question is this for 3 months which is the duration; it is a diuretic phase for 3 months it refers to which event. So, one of the possibilities that, here is it reference to this knowing event, I did not know for 3 months that my P D A had phone. So, this is one reading I did not know my P D A had phone for 3 months and other reading is for 3 months is attached to the noun phone so it is the qualified for phone so, the since of the sentence will be I did not know my P D A had a phone and this phone was therefore, 3 months this is one meaning. There is another attachment point for 3 months, may be you can guess which is the certain point, for 3 months can also be attach to P D A a very interesting rule of thumb is to see that, preposition phrases in a sentence can be attached potentially to any noun that comes before it ok. So, it can be attached to I it can be attached to P D A it can be attached to phone and it can also attached to the main part of the sentence. So, all this attachments all the 3 different, 4 different attachment, they will give you rights to 4 meaning. So, one meaning was I did not know for 3 months that my instrument had a phone, another meaning is I did not know that my P D A for 3 months that means this P D A was which me for 3 month, maybe it was loaned for 3 month had a phone and finally, I did not my P D A had a phone for 3 months, that means the phone itself was called 3 months. Now, depending on the naturalness of the situation depending on our life experience we can exclude some meanings for example, phone for 3 months is a strain construction in this particular sentence so, most likely the actual reading of this sentence is I did not know from 3 months in my, this was over heart by me in a conference, there is an actual sentences in the newspaper which do my attention, these are also very famous sentence in the sense that, similar kind of construction abounds in news paper, story newspaper writing, the camera man short the man with the gun, when he was near Tendulkar. I will read this sentence once again the camera man short the man with the gun when he was near Tendulkar. The different meanings of the sentence arise from a complex interaction or many different factors ok, one of the factor is in fact that, the camera man short the man with .the gun when he was Tendulkar the 1st fact is that short has 2 meanings ok. This is the act of shooting the shooting can be by a camera which camera man does, or a shooting can be done by the gun which can be by a terrorist for example, or by a murderer so, the camera man short the man with the gun when he was near Tendulkar. If somebody comes back and says that, no the word camera man makes the meaning very clear for the works out, makes it very clear the camera man short the man because, of this phrases the phrases of the word camera the meaning of shoots becomes very clear, this is not the case. There is nothing which prevents the camera man from carrying an actual gun I will doing the shooting activity. Therefore, it is possible that the camera man is shooting with the gun. Now, the camera man shot the man with the gun, when he was near Tendulkar again there is this complex interaction of the preposition phrase with an house the camera man shot the man with the gun that means, he shot he took a picture of the man who had a man with the gun is a complete noun phrase, in this case with the gun is attached to man ok, or the camera man actually fired a shot with the man with his own gun. In this case the gun is with camera man. So, this is the 1st develop ambiguity for actual 2nd level of ambiguity, 1st level of ambiguity was two meanings of shots, the 2nd level of ambiguity is with the gun being attach to the man, or being attach to shoot ok. So, this gun was used as an instrument for suiting or it is qualified for men. The next level of ambiguity comes from close attachment here, when he was near Tendulkar the ambiguity here is who is who was near Tendulkar, The camera man or the man ok. So, there are these 2 possibility camera man or the man and depending on that ok depending on that, there are more meanings of the sentences ok. So, this sentence really can have really can have a very large number of meanings depending on combinations of multiple possibilities of attachment, multiple meanings of the words sort and multiple attachments coming from the clause ok. .. So, let me just write down where this ambiguity comes from this is an interesting point and it clarifies our notion of how ambiguity arises. So, the sentence is the camera man sort the man with the gun when he was Tendulkar so, ambiguity because, of shot 2 meanings ok, with the gun this is the preposition phase, 2 attachment points, means shot or man 2 meanings of shot camera or gun. So, 2 meanings here 2 attachment points, another possibility is the clause, when he was near Tendulkar ok. So, this is the clause when you was near Tendulkar is a clause. The question is he is reference, what is he refer to? This he refers to the man or the cameraman so, again 2 possibilities ok. So, 2 meanings of sort 2 attachment points for with the gun and 2 references point for he, camera man or man ok. So, when we multiply all this possibilities 2 into 2 into 2 we find that it there are 8 different meanings of this sentence ok. So, this particular sentence the cameraman shot the man with the gun when he was Tendulkar has 8 meanings on the 1st level of analysis. Where it is differently to that this particular sentence, which is very complex sentence and it has many more meanings apparently there are 14 meanings of this, many of quite of them are actually nonsense ok. But, this 8 meanings that, we discussed about they are extremely real, they are very much real and this meanings are all possible and they are competing meanings. Now, this meanings becomes apparent I definitely heartily to do this exercise, this meanings become apparent, when you translate the sentence, according to this meanings .in to your own mother tongue. Translate this for example, into Tamil or Hindi or Marathi so, this will show you that there are different meanings of the sentence ok. Now, we have understood that, ambiguity can come from the reference of a pronoun to a particular noun that there are different possibility, 2 different meaning of the word lexical ambiguity and 2 different attachment points of preposition phase. I have given more examples; one example is from P G woodhouse ring in Jeeves a very famous novel. Here this sentence is very instructive in terms of the ambiguity produces, when we analyze its phrases and clauses, Jill had rubbed ointment on mike. The Irish Terrier taken a look at gold fish belonging to the cook, which had caused anxiety in the kitchen while refusing its ants eggs. Your exercise would be to find out what this which refers to and depending on that how the meaning changes. And the final sentence here is the a times of India click 26-th February 2008 aid for kins of cops, killed in terrorist attacks. So, here killed in terrorist attacks is clause the question is it modifies, what the cops or kins ok, from that ambiguity arises. So, let me summaries the structural ambiguity point, let us first go back to the previous slide, where we have seen the scope ambiguity namely the region of influence of adjectives and quantifier, preposition phrase attachment ambiguity, where does the preposition phase attach. And then we proceeded at to show that, the combination of this ambiguities, words senses different senses of the word, the preposition phase attachment points and the clause attachments. The interaction of all this different point kinds of ambiguity can give rise to a very large number of meanings of a sentence. So, with this we finish lecture number 2. We will proceed to other kinds of other stages of natural language processing, in a next lecture. . \n",
          "document_id": 1144866
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What is VP?",
              "id": 544751,
              "answers": [
                {
                  "answer_id": 634091,
                  "document_id": 1144855,
                  "question_id": 544751,
                  "text": "VP is the verb phrase, the next important structure after the noun phrase ",
                  "answer_start": 4528,
                  "answer_end": 4602,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "what is the expression for T star?",
              "id": 544705,
              "answers": [
                {
                  "answer_id": 633913,
                  "document_id": 1144855,
                  "question_id": 544705,
                  "text": "T star becomes a very simple expression now, it is argmax over all possible T’s of P T, ",
                  "answer_start": 1038,
                  "answer_end": 1126,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "what is the probability of the parse tree T? ",
              "id": 544707,
              "answers": [
                {
                  "answer_id": 633915,
                  "document_id": 1144855,
                  "question_id": 544707,
                  "text": "the probability of the parse tree T. .Now, this is a very intuitive when seemingly obvious expression where the best possible parse tree of a sentence is nothing but the tree which has the highest probability. ",
                  "answer_start": 1126,
                  "answer_end": 1336,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "what are the different kinds of verb phrase?",
              "id": 544754,
              "answers": [
                {
                  "answer_id": 634094,
                  "document_id": 1144855,
                  "question_id": 544754,
                  "text": "verb phrase can be again of different kinds. These captures two different situations for forming a verb phrase, a verb phrase can be a verb phrase followed by PP, a preposition phrase, this is a left recursive production once again. And this is a basic rule, verb phrase is VBD, D indicates the past tense e d, reminiscent of the e d suffix and VBD indicating past tense is again from the Penn tree bank",
                  "answer_start": 4606,
                  "answer_end": 5009,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "what is Probabilistic context free grammar ?",
              "id": 544710,
              "answers": [
                {
                  "answer_id": 633918,
                  "document_id": 1144855,
                  "question_id": 544710,
                  "text": " Probabilistic context free grammar is just like context free grammar where, only the additional thing is that, with every rule or every rewrite rule or every production, we have a probability value. So, these symbols try to capture a small grammar of English,",
                  "answer_start": 1735,
                  "answer_end": 1995,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "what are the examples of verb phrase?",
              "id": 544757,
              "answers": [
                {
                  "answer_id": 634097,
                  "document_id": 1144855,
                  "question_id": 544757,
                  "text": "which is called the morphology analyzer ",
                  "answer_start": 7739,
                  "answer_end": 7779,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "what are the rules of Probabilistic context free grammar?",
              "id": 544713,
              "answers": [
                {
                  "answer_id": 633921,
                  "document_id": 1144855,
                  "question_id": 544713,
                  "text": " S goes to NP VP. That means, a sentence is composed of a noun phrase and a verb phrase,",
                  "answer_start": 2037,
                  "answer_end": 2125,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "how does the target parse tree is produced?",
              "id": 544692,
              "answers": [
                {
                  "answer_id": 633900,
                  "document_id": 1144855,
                  "question_id": 544692,
                  "text": "source sentence parse is through a noisy channel does an argmax spaced computation or phases in argmax parse computation and a target parse tree is produced. ",
                  "answer_start": 306,
                  "answer_end": 464,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "what are the examples for Probabilistic context free grammar?",
              "id": 544716,
              "answers": [
                {
                  "answer_id": 633924,
                  "document_id": 1144855,
                  "question_id": 544716,
                  "text": "a simple example of that would be children play where, children is noun phrase, play is the verb phrase and every sentence has noun phrase and verb phrase. All sentences are composed of these two consequence, there is no other possibility for a sentence and therefore, the probability value is 1.0",
                  "answer_start": 2126,
                  "answer_end": 2423,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "what is the expression for theory and the computation?",
              "id": 544697,
              "answers": [
                {
                  "answer_id": 633905,
                  "document_id": 1144855,
                  "question_id": 544697,
                  "text": "The leaf nodes traversed in that order produces the sentence and P T is a prior probability, which is the probability of the tree. ",
                  "answer_start": 903,
                  "answer_end": 1034,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "which is the best possible tree in the sense of probability value of the condition probability?",
              "id": 544699,
              "answers": [
                {
                  "answer_id": 633907,
                  "document_id": 1144855,
                  "question_id": 544699,
                  "text": "T star is the best possible tree in the sense of probability value of the condition probability",
                  "answer_start": 526,
                  "answer_end": 621,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is a noun phrase?",
              "id": 544719,
              "answers": [
                {
                  "answer_id": 633930,
                  "document_id": 1144855,
                  "question_id": 544719,
                  "text": "So, a noun phrase is a plural noun then the final NP production is, noun phrase is, a noun phrase followed by a preposition phrase. So, this is a recursive definition with left recursion, NP is at NP followed by a preposition phrase.",
                  "answer_start": 2992,
                  "answer_end": 3225,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "what is the probability of the tree.?\n",
              "id": 544701,
              "answers": [
                {
                  "answer_id": 633909,
                  "document_id": 1144855,
                  "question_id": 544701,
                  "text": "The leaf nodes traversed in that order produces the sentence and P T is a prior probability, which is the probability of the tree. ",
                  "answer_start": 903,
                  "answer_end": 1034,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How to find out if the noun phrase starts with a plural noun and has a preposition phrase?",
              "id": 544724,
              "answers": [
                {
                  "answer_id": 633966,
                  "document_id": 1144855,
                  "question_id": 544724,
                  "text": " So, that is easy to find out, because preposition phrase P phrase what is the definition, the definition is that, it starts with a preposition and is then followed by a noun phrase. So, suppose here also for noun phrase, we use plural noun and therefore, these now becomes noun phrase is a plural noun followed by a preposition followed by another plural noun",
                  "answer_start": 3449,
                  "answer_end": 3809,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "what are the different kinds of noun phrase? ",
              "id": 544750,
              "answers": [
                {
                  "answer_id": 634090,
                  "document_id": 1144855,
                  "question_id": 544750,
                  "text": "verb phrase can be again of different kinds. These captures two different situations for forming a verb phrase, a verb phrase can be a verb phrase followed by PP, a preposition phrase, this is a left recursive production once again. And this is a basic rule, verb phrase is VBD, D indicates the past tense e d, reminiscent of the e d suffix and VBD indicating past tense is again from the Penn tree bank.",
                  "answer_start": 4606,
                  "answer_end": 5010,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "parsing typically is presided by?",
              "id": 547056,
              "answers": [
                {
                  "answer_id": 638340,
                  "document_id": 1144855,
                  "question_id": 547056,
                  "text": "parsing typically is presided by a phase of morphology, presided by a phase of parsing for part of speech tagging, ",
                  "answer_start": 7899,
                  "answer_end": 8014,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "which is called the morphology analyze?",
              "id": 547052,
              "answers": [
                {
                  "answer_id": 638336,
                  "document_id": 1144855,
                  "question_id": 547052,
                  "text": "one could always do morphology analysis or run a tool, which is called the morphology analyze",
                  "answer_start": 7684,
                  "answer_end": 7777,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "Mod-01 Lec-09 Brief on Probabilistic Parsing & Start of Part of Speech Tagging\n\nWe will start the very important topic of Part of Speech Tagging. Before that, we finish what we left in the last lecture namely, the argmax spaced noisy channel computation of parse tree from a sentence. So, we said that the source sentence parse is through a noisy channel does an argmax spaced computation or phases in argmax parse computation and a target parse tree is produced. So, the expressions show here the theory and the computation, T star is the best possible tree in the sense of probability value of the condition probability P T given S and the conditioning or the argmax based computation is, who were all possible T’s. Now, we apply base theorem and convert this probability into P T into P S given T, P S given T is 1, because given the T, the sentence is completely determined without any uncertainty. The leaf nodes traversed in that order produces the sentence and P T is a prior probability, which is the probability of the tree. So, T star becomes a very simple expression now, it is argmax over all possible T’s of P T, the probability of the parse tree T. .Now, this is a very intuitive when seemingly obvious expression where the best possible parse tree of a sentence is nothing but the tree which has the highest probability. So, that naturally leads to the question as to, how to compute the probability value of the parse tree, what is the meaning of the probability of the parse tree. So, this is a discussion reserved for the topic of parsing and probabilistic parsing, which we do later. . But, I just want to give you the main idea behind, now probabilistic context free grammar forms the foundation of this discussion. Probabilistic context free grammar is just like context free grammar where, only the additional thing is that, with every rule or every rewrite rule or every production, we have a probability value. So, these symbols try to capture a small grammar of English, let us go through these rules one by one, S goes to NP VP. That means, a sentence is composed of a noun phrase and a verb phrase, a simple example of that would be children play where, children is noun phrase, play is the verb phrase and every sentence has noun phrase and verb phrase. All sentences are composed of these two consequence, there is no other possibility for a sentence and therefore, the probability value is 1.0. This kind of certainty with respect to probability is not the case for other kinds of phrases, because NP which is a noun phrase can be constructed in many different ways. .Three ways I have shown here, NP goes to DT NN that means, a determiner and NN, this is a very common situation for a noun phrase, the why DT is the NN is why. NP goes to NNS, what is NNS, NNS is a plural noun and the convention comes from what is called the Penn tree bank, which is an important project for annotated co-procreation and they adapted this convention and it is shown here also. So, a noun phrase is a plural noun then the final NP production is, noun phrase is, a noun phrase followed by a preposition phrase. So, this is a recursive definition with left recursion, NP is at NP followed by a preposition phrase. So, let us say, we invoke the NNS rewrite for this recursive NP, so suppose NP is now, NNS PP. So, we have to have, we are looking for an example where the noun phrase starts with a plural noun and has a preposition phrase. So, that is easy to find out, because preposition phrase P phrase what is the definition, the definition is that, it starts with a preposition and is then followed by a noun phrase. So, suppose here also for noun phrase, we use plural noun and therefore, these now becomes noun phrase is a plural noun followed by a preposition followed by another plural noun. So, can you think of a construct of this kind, not very difficult, so this would be boys with footballs for example, this will follow the structure, boys is NNS plural noun, with is a preposition and with footballs is similarly a plural noun, boys with footballs were spotted on the ground, that is the sentence here. So, noun phrase can be of different kinds, in this case there are three possibilities namely, determine a noun, plural noun and noun phrase followed by a preposition phrase, the boy, boys, boys with footballs. Preposition phrase is a preposition followed by a noun phrase, so things like with a binocular in the train by the people, for the people, of the people, all these are preposition phrases. VP is the verb phrase, the next important structure after the noun phrase and verb phrase can be again of different kinds. These captures two different situations for forming a verb phrase, a verb phrase can be a verb phrase followed by PP, a preposition phrase, this is a left recursive production once again. And this is a basic rule, verb phrase is VBD, D indicates the past tense e d, reminiscent of the e d suffix and VBD indicating past tense is again from the Penn tree bank. So, here it is an example of a verb phrase, which is past tense verb followed by a .noun phrase and these actually captures the transitive verb situation that is, verbs which take objects. So, for example, VBD could be played, NP could be football or saw the boy, NP is DT NN, VBD is saw, saw the boy and VP with PP, VP is VP and PP, a recursive definition, what could be an example for that. An example for that could be, saw with telescopes, people saw Everest with telescopes. So, saw Everest or saw mountains with telescopes, saw mountains with telescopes will become parse by this grammar. But, saw Everest with telescopes will not be parse, because we have not made prohibition for noun phrase going to a single noun. But, it could parse things like saw the Everest, if you introduce the before Everest, that could be parse anyway. So, this shows how some segment of English, a few constructs of English are captured by production rules, which are context free grammar rules. So, there is nothing new in this, what is new are this probability values, we come in minute to the understanding of this probability values. Notice the probabilities here in the right hand side DT goes to the, with 1.0. So, this is not a completely correct situation, because a determiner can be the, a, and an, so this is a limited view of DT, what DT is, DT is the we are ignoring here a and an. And NN is noun, which goes to gunman this means that, our machine has seen only the word gunman and another word of course, it is same this is building. And VBD, the past tense verb is sprayed, NNS is bullets, so this is an extremely artificial situation. We know that, English languages many, many plural nouns, lakhs of nouns and there are many, many verbs, 30, 40000 verbs and if you also consider the past tense form, they would be equal in number. So therefore, this is a very, very artificial situation where, the machine has been exposed to only one sentence, can you imagine what the sentence is, the sentence is, the gunman sprayed the building with bullets. So, since the appears twice, it has to be taken into account only once in the production rule. And we divide the probability equally amongst gunman and building, because the computation is probability of NN going to gunman is the number of times gunman appears divided by total number of nouns. The total number of nouns here singular noun of course, is 2, so this is 1 by 2, 1 by 2, 0.5 and there is only one pronoun, which is .bullets and NNS goes to bullets with 1.0 probability. Now, one question that might arise in your mind at this stage is that, what is the point of keeping the plural nouns as bullets. Let us say, one could always do morphology analysis or run a tool, which is called the morphology analyzer and that isolates the suffix S and says that, bullet is a singular noun, we will talk about all these things later. So, parsing typically is presided by a phase of morphology, presided by a phase of parsing for part of speech tagging, which is our next topic of our discussion. So, you just accept the following at this stage that, a probabilistic context free grammar is a set of production rules just like in context free grammar, but associated with probability values. Now, let us quickly understand what this probability values mean, the probability values mean that, noun phrase being expressed as determiner and noun occurs 50 percent of the time in the corpus. How is the corpus created, corpus is created by lexicographers, linguists, language experts, who produce these kind of structure on the sentences. So, the number of times the structure is found in the corpus divided by total number of noun phrases in the corpus, it gives me the probability value. So, this shows that, in the corpus 50 percent of the time noun phrases appear, of the 50 percent time the noun phrase appear, it was DT NN. So, NP was DT NN 50 percent of the time, NP appeared as plural noun 30 percent of the time, NP appeared as noun phrase followed by a preposition phrase 20 percent of the time. Similarly, verb phrase had 60 percent, 40 percent distribution, so this is quite clear. Just let me give an example of, how the machine actually looks at the corpora and gets these structures, so let me take a very very simple example of how the corpora looks like. .. So, if we have a sentence like boy saw mountains with telescopes, this is a sentence, so we begin with S goes to NP VP. So, in this case, the whole structure is S of course, boys saw mountains with telescopes, the whole thing is S. Now, we identify noun phrases and verb phrases in this and gives similar kind of bracketing. So, we are doing what is called the top down processing, now boys is the noun phrase and the whole sentence part, saw mountains, etcetera is the verb phrase. So, is it clear to you, how the bracketing is being done, boys saw mountains with telescopes is S and then boys is NP, saw mountains with telescopes is VP, what we are doing is essentially top down parsing. In the next step, we have to give finer structures to these. .. Boys cannot be broken up further, because NP goes to NNS is a rule which cannot be elaborated further however, NP goes to NNS, we have to give the closest tag to this, NNS boys. So, this finishes the story on boys, which is boys is a plural noun indicated by NNS as a bracket and this is also the noun phrase as indicated by NP. The processing of verb phrase is little more complex, because we have VP here, saw is also a verb phrase and it is not very obvious how we should group them or break them apart. So, we have saw mountains with telescopes, with telescopes has to be a preposition phrase, so we put it down here, with telescopes and this is a PP, the whole thing is under a VP. And here, we have to invoke the rule, VP goes to VP PP, it is a left recursive rule, so saw mountains is another VP. So, you see how the structure is emerging, S is nothing but NP and VP at the top most level. NP in this case is NNS, NNS is boys and VP the verb phrase, saw mountains with telescopes is broken up into VP and PP, PP is with telescopes saw mountains. I will not expand the NP part, because that is same, it will continue to remain same and I will just say, this is the NP without showing the details below it. However, the VP has saw and saw, we know is a VBD, mountains is NNS. So, the whole thing is the VP and with telescopes remains the PP, we would like to break the PP now. .. Proceeding further, we get S, NP is as before within VP, we have a VP with saw as VBD, mountains as NNS and with telescopes is a PP, with being a P and telescopes being NNS, which is also the NP. So, this whole thing finishes the PP, whole thing finishes the VP and whole thing finishes S. This large number of brackets makes the expression slightly complicated towards the N, but I guess you get the main idea. Now, what we can do is that, we can go whatever, we can go from the words and see how the final structure emerges. So, telescopes is NNS plural noun, which again is a noun phrase, so NP goes to NNS is invoked, P with is a P, so P with NP, P and NP gives rise to PP, which is the higher level structure. So, the work of PP is over, now we come to mountains which is NNS, which again requires an NP to be placed, this is NP, VBD and NP together forms a VP, this is the rule. VP goes to VBD NP this is invoke now, the whole thing of the VP and the PP forms the VP, so VP goes to VP PP this left recursive rule is invoked, we have the NP here, NP and VP together forms S. So, this illustrates how the bracket at corpus is created for training a machine to learn parsing and you must have seen, how complicated the process is. A process like this is invoked on the sentences and many times of course, a rule base parser can create this kind of structure and many times not, because the rule basis have their own limitations. .But, once the structure is created, it is now suitable for a machine to process and the machine can be trained to learn parsing. I draw your attention to the bracketing, now bracketings essentially capture the internal structure of the sentence and how smaller structures group together to form a higher level structure and the highest level structure is S. So, what should be noted here is, how the annotator is required to invoke the correct rule at specific points of processing of the sentence. So, the person has to be knowledgeable with respect to the syntax of the language, must have a very good idea of the properties of the words. So, telescopes for example, could be a third person singular verb also. Telescopes as a verb and saw is a verb in past tense, but saw could also be a noun, an instrument for cutting wood, let us say. So, the lexicographer who is producing these kind of brackets has to know the structure of the sentences, the structure of the grammar and the properties of the words. So, this is by no means, a non trivial task, it requires lot of money and time to create this kind of resource, bracketing structure of sentences, but once created, it becomes useful for training a machine to learn. So, we now of course, we again come back to the bracketed structure we created on the paper and now, I can explain to you how the probability values are calculated. So now, you see here, VP going to VBD NP, this structure appears once and VP not VP, but NP going to NNS was invoke twice for telescopes and boys, and trice actually, NP goes to NNS was invoke for boys, mountains and telescopes. So, what the machinery do is that, it will find that, NP goes to NNS was applied three times whereas NP, no in this case NP going to NNS is the only production which is used. However, VP going to VBD and P, and VP going to VP and PP, these are the two instances of the verb phrase expansion. And since they appear with equal number, if this was the on the corpus available on the evidence available then you have no other choice than distributing the probability equally to VP goes to VP PP and VP goes to VBD NP. So, this kind of bracketed structure is looked at by the machine to compute the probability by counting, simply counting. .. So now, let us understand what is the meaning of the probability of a tree? And how one has to choose the best possible tree in terms of it is probability value. This sentence, the gunman sprayed the building with bullets is an ambiguous sentence, do not think of, do not look at the sentence from the word knowledge point of view, but simply from the point of view of structure. So, the gunman sprayed the building with bullets, in this case what is the status of this preposition phrase with bullets. So, the immediate answer I suppose, that even make is, with bullets is the entity with which the gunman sprayed the building. So, with bullets goes with sprayed and therefore, this is logical structure. So, the sentence goes to noun phrase and verb phrase, a noun phrase is again determiner and noun, which is the gunman. Verb phrase goes to verb phrase and preposition phrase with left recursion, notice that preposition phrase being here makes it attached to the main verb, the main verb is sprayed, so spray with bullets is the reading. VP going to VBD and NP which is sprayed, NP here is the building through DT and NN, PP is preposition at noun phrase and in this case, the noun phrase is a plural noun bullets, so with bullets. So, the point to be noted here is that, the PP is at the same level as this VP, which contains the main verb, this structure contains the main verb sprayed. So, this way of forming the tree is telling me that, with bullets is attached to sprayed, the gunman .used bullets to spray the building. Let us look at the other parse tree, the other parse tree let me draw on the paper. . The gunman sprayed the building with bullets, S again goes to NP and VP, NP goes to DT and NN which is the gunman. VP goes to VBD, NP this is the other invocation of the rule VP, so VP can be expanded as VP PP or VBD NP. Now, VBD becomes sprayed, NP on expansion becomes NP and PP, this NP becomes DT and NN and produces the building and PP is P NP, this P becomes with, NP is bullets. So, NP goes to NNS and bullets, so notice the difference between the two structures. I will draw your attention once to the slide where, this PP is at the same level as VP or PP is at the same level as a structure, which contains the main verb. Whereas, if you look at the tree that I drew on the paper, here you find that the PP is not at the same level as the main verb sprayed. It is at a level below, at one level below, in a sense that, there is an NP and that NP contains the another NP and PP. So, this means that, the preposition phrase is attached to the noun phrase here that means, it is attached with the building. So, as if the building has bullets in it, which building, that building which has bullets in it, the building with bullets. So, the gunman sprayed the building which has bullets, which contains bullets, so this is another possible reading of the sentence. The sentence is ambiguous, this is very similar to a very famous sentence in natural language processing. The sentence is, I saw the boys with telescopes and the ambiguity here is, .who has the telescopes. I saw the boys using my telescope or I saw a boy who had telescope, that is the meaning. So, similar is the situation in this case, in one case with bullets is attached to building. In the other case, with bullets is attached to sprayed, that is the ambiguity, now the question is, which parse tree is more probable. This is founded by computing a probability values and the theory for this will be discussed later when we do probabilistic parsing in detail. But in this case, for the moment surprise it to say that, the probability of the parse tree is nothing but the probabilities of the rule applications. So, this first 1.0 comes from S going to NP VP and that is a definite rule with no uncertainty and therefore 1.0, into 0.5 where does this come from, this comes from the fact that, NP has been expanded as DT NN. And that occurs 50 percent of the times in corpora with probability 0.5 therefore, this is the 0.5. Then again I have 1.0, this is the expansion of DT with probability 1.0, there is only one determiner which is the then we have a probability value of 0.5, which is noun going to gunman. Assume, this is the probability value and then we come to this part of the tree, the multiplication factor is 0.6 here, which comes from this value 0.6 which means, VP is expanded into VP PP with probability 0.6, that is the 0.6 here. Then we had 0.4 which is the probability of this PP expansion, which is VBD and NP, that has a probability of 0.4, so this is 0.4. Then 1.0 comes from PP being expanded as P NP, PP is expanded only this way as given in the grammar, there are no other possibilities, so 1.0, so this is the 1.0. Now, we have another 0.5 which comes from the NP getting expanded as DT and NN and then we have 1.0 with DT being the another 0.5, which is NN going as building. And then there is another 1.0 which is the preposition with, this is the only preposition in the grammar then NP expanded into NNS with 0.3 probability, which is 0.3 and NNS becoming bullet with 1.0 probability. So, this is the way, the probability of a parse tree is computed namely, the probability of rule application or the probabilities associated with the production rules, simply the product of probabilities. Now, the question of why this is done, what is the rationale behind this, what is the theory behind this, that will be explained later when we do probabilistic parsing in detail. So, this is the probability, the probability comes out to be 0.00225, I am not showing the probability of the tree which is drawn in the paper. I am not showing that probability, .again one can record the probability values on the nodes for the rule application, this is given in the grammar. Take the probability values take the product and you will find that, the probability value here will come out to be less than the probability value on the slide. So, this means that, this tree is much more probable than the tree I drew on the paper and this is because you might be tempted to say that, the gunman sprayed the building with bullets is a much more feasible situation. Then sprayed the building which contains bullets, which is fine as far as the word knowledge is concerned. But, the machine does not have that kind of common sense knowledge, it goes purely by counts. And it so happens that, the production rules here are occurring more in the corpus, giving thereby the evidence that, the verb phrase indeed is expanded as verb phrase and preposition phrase many many more times. And preposition phrase at gets attach to the verb, also the verb phrase becoming VBD and NP is more frequent at deeper levels of parsing rather than other top level. So, this kind of phenomena exists in the corpora and the machine simply computes the frequency and obtains the probability value. One should not be tempted to be leave that the machine has intelligence and word knowledge, but the point is that, one knowledge on intelligence can be almost simulated. I am tempted to say, if there is a very, very large amount of corpus and people’s actual language behavior, written sentences, spoken utterances can be captured and there we will find the evidence for preposition phrase getting attached to verb more frequently than to the noun, so that is the point. So, from this the main conclusion we draw is that, it is possible to obtain the parse tree of a sentence through argmax based computation. And in the argmax based computation, the tree which is chosen finally as the output, is the tree with the highest probability. The probability is found simply by taking the product of production rules, the theory will be done later. .. We now move on to a very important topic, a very, very fundamental basic topic of natural language processing called POS tagging, part of speech tagging. The part of speech is something, which you have done before in your high school, the very famous part of speeches are top level categories noun, verb, adjective, adverb, adjectives qualify nouns, adverbs qualify verbs. So, there are verbals and nominals, so these are basic grammatical categories, which come from our high school grammar. So, one might be wondering, what has POS tagging got to do with natural language processing, this is a very important point to discuss, so let us go ahead and make those issues. . .Part of speech tagging is a process that attaches each word in a sentence with a suitable tag from a given set of tags. What are these tags, we will see in a minute through examples, the set of tags is called the tag set, there are many standard tag sets. So, Penn tree bank is the most famous one for English and some of examples of this, we will see very soon. So, POS tagging is a process that attaches each word in a sentence with a suitable tag from a given set of tags, that is the main point. Now, the point is that, who creates these tags, how is the set of tags defined, lot of intricate linguistic and computational concerns go behind the design of a tag set. We will see as we discussed POS tagging that, certain things are not possible when we are at the level of POS tagging without invoking syntax and semantics of the sentence. The higher level structure of the sentence or the meaning of the sentence, but the point is that, if we do that then we are putting the cot before the horse. The horse has to pull the cart and therefore, it has to be behind the horse which means that, we are doing an activity which is supposed to be done later. So, syntax analysis, semantic analysis require as a fundamental step, the part of speeches of the words constituting the sentence. So, how could we assume in a syntactic or semantic knowledge for POS tagging when those activities actually follow POS tagging, this is the point. So, at the level of part of speech tagging, we will not be able to produce certain tags. And therefore, those tags will not be useful in the tag set, because those tags cannot be produced. And therefore, these kind of considerations go for designing the set of tags, the tag set. .. Let us look at some example of POS tags, NN is the most important and most frequent POS tag, this stands for common noun. For example, dog NN, so look at the convention here, this is a . accepted convention where, the word is followed by an underscore and followed by the tag. So, this means that, dog underscore NN, here dog is a noun. Now, what is an example of this, I saw a dog here, dog is a noun, so dog will be tagged as underscore NN. VM or the main verb is possible in the next most important entity and here the example, I have chosen is run. So, if we have dogs run, dogs run or a dog runs and so on, so let us not worry about the morphological changes here dogs, runs, etcetera. So, run is the main verb, run underscore VM is the main verb. VAUX is the auxiliary verb for example, is, am, are these are auxiliary verbs, in this case, is is the example, so is underscore VAUX is the auxiliary form. JJ stands for adjective, so one might wonder where does JJ come from, this is from the penn tag set, it is most likely adjective is pronounced that way, the d has a palatal sound ja, so that is why, this gives an impression of double J and that is why, JJ is kept here. So, for example, a red ball, here red is an adjective, so red will be tagged as underscore JJ. PRP is a proper noun, so I, you, we, she these are proper nouns, in this case I have taken the example of you, which is you underscore PRP. .So, if the sentence is, you laugh then you underscore PRP, laugh underscore VM finishes the tagging of the sentence. NNP is proper noun for example John, John underscore NNP is the proper noun. So, one could tag a complete sentence by means of these kind of tags, this is not the full tag set by any means, that is why there is an extra here. You could go to the site of Penn tree bank, go to Google, type as a query Penn tree bank and you would be lead to the home page of Penn tree bank project. And then you will see all these tags there, so I suppose the meaning of these tags and their purpose is quite clear. . Now, why is parse tag a difficult problem, the problem is difficult because of these very basic or common situation prevailing in natural language pressing, namely that of ambiguity. So, POS tag ambiguity is rampant in language, in English we know that, almost all nouns can be used as verbs. So, I take this very interesting sentence though improbable, I bank on the bank on the river bank for my transactions. So, for my financial transactions, I bank on the bank on the river bank, so the word bank appears three times here. And therefore, this linguistic convention is followed which is the lower suffix, so bank one is the first appearance of the word bank, bank 2 is the second appearance, bank 3 is the third appearance. So, for financial transactions, I bank on the bank on the river bank, the first bank is the verb meaning depend, so I depend on the bank on the river bank for .my transactions. The other two banks are noun, but you can see that, here is a situation for word sense this ambiguation. The second bank is the actual bank, from where money is withdrawn or into which money is put in, so this is where financial transactions are carried out. Whereas, this bank is a place, river bank is a place, so words in this ambiguation will be called for, to get the correct sense of the two banks, the first bank of course, is a verb. Now, the question is, when the POS tagger is called to put levels on the words of this sentence, I will be leveled as PRP and bank will be noun on will get the tag for preposition, there will get the tag for determiner. This bank now will have to get the tag for noun, the first bank has to get the tag for verb, VM this is the main verb, so this is noun NN. On the tag for proposition the, tag for determiner river, tag for noun and bank again the tag for noun, for the tag for preposition my, the tag for pronoun and transactions the tag for noun. So, I and my are pronouns here and this bank is the only verb, prepositions there are three of them on, on, for and the nouns are bank, bank, transactions, river. So, this shows that, POS tag can be facing the challenge of ambiguity, so this is not the situation only in English, in other all languages the POS tag ambiguity exists. From the context, one can make out the actual part of speech, but sometimes it may not be possible. Now, here is an example in Hindi where, we deal with the POS tag ambiguity, . can be noun in the sense of food or it can be a verb to eat, which is the infinity will form. So, . or ., this is like the previous sentence in English, I bank on the bank on the river bank, here we are saying .. So, the first . is noun, I need to eat food and second . is verb in the inimitable form. .. There is another example here which is interesting, Ram ., . is auxiliary verb and the sentence means, Ram sings well. Ram ., here . has a different grammatical role, what is called copula verb, VCOP copula verb. So, the symbols also are different VAUX and VCOP and the meaning of the sentence is Ram is a good boy, so Ram sings well and Ram is a good boy. So, I draw your attention here to two problems, one is ., so this . has the auxiliary role, ., . has the copula role. How will the POS tag in system find out, one is auxiliary the other is copula, think about this. The other problem is . appears at both places, Ram ., this . is an adverb, it is qualifying the action of singing. And [FLl], here it is qualifying the noun ., a particular quality of the ., so this is an adjective. So, . in the first sentence is adverb, the second sentence . is adjective, . in the first sentence is auxiliary verb, . in the second sentence is copula verb. So, when the POS tag works, it has to correctly produce the tags, in the first case adverb, in the second case adjective and this is a disambiguation task, it has to do it correctly. One might be advancing a simple rule saying that, if a word which can be both adverb and adjective, is followed by a noun then it is actually an adjective, if it is followed by a verb it has to be an adverb. But, though this rule is simple, this rule is not all encompassing, it can fail for situations which we will explain in the next class.\n\n",
          "document_id": 1144855
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "What is a V AUX ?",
              "id": 544726,
              "answers": [
                {
                  "answer_id": 633981,
                  "document_id": 1144861,
                  "question_id": 544726,
                  "text": " V AUX is the auxiliary verb, so is am or these are auxiliary verbs, they also a tag in the text. So, is underscore V AUX is the tag shown here,",
                  "answer_start": 2632,
                  "answer_end": 2776,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is tag for proper noun?",
              "id": 544730,
              "answers": [
                {
                  "answer_id": 633989,
                  "document_id": 1144861,
                  "question_id": 544730,
                  "text": "N N P is the tag for proper noun ",
                  "answer_start": 3095,
                  "answer_end": 3128,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is a J J?",
              "id": 544727,
              "answers": [
                {
                  "answer_id": 633984,
                  "document_id": 1144861,
                  "question_id": 544727,
                  "text": "J J is the adjective tag ",
                  "answer_start": 2777,
                  "answer_end": 2802,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is part of speech tagging? ",
              "id": 544706,
              "answers": [
                {
                  "answer_id": 633914,
                  "document_id": 1144861,
                  "question_id": 544706,
                  "text": "part of speech tagging is a process that attaches each word in a sentence with a suitable tag from a given set of tags",
                  "answer_start": 1489,
                  "answer_end": 1607,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is bank 1 in I bank on the river bank for my transactions?",
              "id": 544753,
              "answers": [
                {
                  "answer_id": 634093,
                  "document_id": 1144861,
                  "question_id": 544753,
                  "text": "Bank 1 is verb, because I bank on the river bank for my transactions, yet this bank means depend, so I depend on the bank on the river bank for my transactions. So, bank 1 is verb",
                  "answer_start": 3794,
                  "answer_end": 3973,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Which is an extremely important topic, in statistical natural language processing?  ",
              "id": 544684,
              "answers": [
                {
                  "answer_id": 633896,
                  "document_id": 1144861,
                  "question_id": 544684,
                  "text": " Part of Speech Tagging, which is an extremely important topic, in statistical natural language processing or let us say a whole of natural language processing",
                  "answer_start": 71,
                  "answer_end": 230,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Which tag is very common in text?",
              "id": 544733,
              "answers": [
                {
                  "answer_id": 634014,
                  "document_id": 1144861,
                  "question_id": 544733,
                  "text": " pos tag ambiguity is very common in text",
                  "answer_start": 3347,
                  "answer_end": 3388,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is a set of tags is called?",
              "id": 544708,
              "answers": [
                {
                  "answer_id": 633916,
                  "document_id": 1144861,
                  "question_id": 544708,
                  "text": "The set of tags is called the tag set",
                  "answer_start": 1609,
                  "answer_end": 1646,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Which is the most visible and famous set of tags for categorizing the words of English language?",
              "id": 544709,
              "answers": [
                {
                  "answer_id": 633917,
                  "document_id": 1144861,
                  "question_id": 544709,
                  "text": "there are many standard tag sets Penn tree bank for English is probably the most visible and famous set of tags for categorizing the words of English language.",
                  "answer_start": 1648,
                  "answer_end": 1807,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is the sentence?",
              "id": 544735,
              "answers": [
                {
                  "answer_id": 634046,
                  "document_id": 1144861,
                  "question_id": 544735,
                  "text": " sentence, I bank on the bank, on the river bank for my transactions. So, I bank on the bank on the river bank for my transactions,",
                  "answer_start": 3480,
                  "answer_end": 3611,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What does an auxiliary verb requires?",
              "id": 544756,
              "answers": [
                {
                  "answer_id": 634096,
                  "document_id": 1144861,
                  "question_id": 544756,
                  "text": "an auxiliary verb requires a main verb, which it is helping",
                  "answer_start": 4919,
                  "answer_end": 4978,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What does the lower suffixes indicate in sentence?  ",
              "id": 544737,
              "answers": [
                {
                  "answer_id": 634050,
                  "document_id": 1144861,
                  "question_id": 544737,
                  "text": "the lower suffixes indicate the occurrence of the word bank,",
                  "answer_start": 3612,
                  "answer_end": 3672,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is the symbol for the copula verb? ",
              "id": 544760,
              "answers": [
                {
                  "answer_id": 634100,
                  "document_id": 1144861,
                  "question_id": 544760,
                  "text": "the symbol for this in parts of speech tagging is V COP.",
                  "answer_start": 5498,
                  "answer_end": 5554,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is copula verb?",
              "id": 544759,
              "answers": [
                {
                  "answer_id": 634099,
                  "document_id": 1144861,
                  "question_id": 544759,
                  "text": "[FL] is not preceded by a main verb, we do not call it an auxiliary verb, it is called a copula verb ",
                  "answer_start": 5393,
                  "answer_end": 5494,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "When did the computational task or part of speech tagging gained visibility and respectability? ",
              "id": 544695,
              "answers": [
                {
                  "answer_id": 633903,
                  "document_id": 1144861,
                  "question_id": 544695,
                  "text": "computational task or part of speech tagging gained visibility and respectability, let us say in a recent times, in last 10 to 15 years",
                  "answer_start": 358,
                  "answer_end": 493,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is a crucial component of natural language processing task?\n ",
              "id": 544696,
              "answers": [
                {
                  "answer_id": 633904,
                  "document_id": 1144861,
                  "question_id": 544696,
                  "text": "a good part of speech tagger is a crucial component of any natural language processing task. ",
                  "answer_start": 538,
                  "answer_end": 631,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Which mark is placed in each word ?",
              "id": 544717,
              "answers": [
                {
                  "answer_id": 633925,
                  "document_id": 1144861,
                  "question_id": 544717,
                  "text": "but you could also conceive of this being and x m l file, where each word is place within x m l mark",
                  "answer_start": 2162,
                  "answer_end": 2262,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Which is important categories that form text ?",
              "id": 544700,
              "answers": [
                {
                  "answer_id": 633908,
                  "document_id": 1144861,
                  "question_id": 544700,
                  "text": "it is important to know the categories of the words that form the text",
                  "answer_start": 702,
                  "answer_end": 772,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is a V M?",
              "id": 544721,
              "answers": [
                {
                  "answer_id": 633945,
                  "document_id": 1144861,
                  "question_id": 544721,
                  "text": "V M, which is a very important tag, namely the main verb of the sentence ",
                  "answer_start": 2456,
                  "answer_end": 2529,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are the examples of parts of speech tag? ",
              "id": 544722,
              "answers": [
                {
                  "answer_id": 633960,
                  "document_id": 1144861,
                  "question_id": 544722,
                  "text": "here is some examples of part of speech tags, N N is noun for example, Dog is N N,",
                  "answer_start": 1815,
                  "answer_end": 1897,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What level of task is part of speech tagging?",
              "id": 544769,
              "answers": [
                {
                  "answer_id": 634109,
                  "document_id": 1144861,
                  "question_id": 544769,
                  "text": "part of speech tagging of course, is the first level task",
                  "answer_start": 6925,
                  "answer_end": 6982,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Who created rules of parts of speech ?",
              "id": 544703,
              "answers": [
                {
                  "answer_id": 633911,
                  "document_id": 1144861,
                  "question_id": 544703,
                  "text": "Human created rules for part of speech tagging do a good job no doubt, but they are little subject to human error and may miss out phenomena",
                  "answer_start": 1049,
                  "answer_end": 1189,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Where does the powerful clue comes from the suffixes the morphological features on the word?",
              "id": 544770,
              "answers": [
                {
                  "answer_id": 634110,
                  "document_id": 1144861,
                  "question_id": 544770,
                  "text": "The most powerful clue comes from the suffixes the morphological features on the word itself",
                  "answer_start": 7419,
                  "answer_end": 7511,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "Mod-01 Lec-10 Part of Speech Tagging\n\nToday, we are going to talk about Part of Speech Tagging, which is an extremely important topic, in statistical natural language processing or let us say a whole of natural language processing. And the fact that part of speech tagging is an important component of natural language processing is well recognized. But the computational task or part of speech tagging gained visibility and respectability, let us say in a recent times, in last 10 to 15 years, but it is very, very well understood that, a good part of speech tagger is a crucial component of any natural language processing task. Before beginning any processing, any sophisticated processing on text, it is important to know the categories of the words that form the text. So, this is the discussion of today, we are going to describe the part of the speech tagging problem, the statistical approach to doing this, because it is well recognized again that part of speech tagging is vest done by machine learning methods from the annotated corpora. Human created rules for part of speech tagging do a good job no doubt, but they are little subject to human error and may miss out phenomena. But on the other hand, if you have data or text, which is already marked with part of speech tags. And we run a machine running algorithm on this, then it is possible to create a statistical system which does a very good job of part of speech tagging. .. So, here is the definition of the problem, part of speech tagging is a process that attaches each word in a sentence with a suitable tag from a given set of tags. The set of tags is called the tag set, there are many standard tag sets Penn tree bank for English is probably the most visible and famous set of tags for categorizing the words of English language. . Now, here is some examples of part of speech tags, N N is noun for example, Dog is N N, we had discuss this in the last class, but let me repeat, this point once again just to clarify the notion of tags and how they are placed with the words. So, one of the options .to place the category information is by placing an under score and then placing N N, but you could also conceive of this being and x m l file, where each word is place within x m l mark, which also specifies what the tag of the word is anyway those are representations. However, we find that, each word needs a categorization in the text, we do not leave out any word. Similarly V M, which is a very important tag, namely the main verb of the sentence for example, john runs here run is the word and it has the category V M main verb, which an underscore, V AUX is the auxiliary verb, so is am or these are auxiliary verbs, they also a tag in the text. So, is underscore V AUX is the tag shown here, J J is the adjective tag and I remark that, adjective is sometimes pronounced to it d very similar to the J sound. So, Red is an adjective as in Red ball, so Red underscore J J would be the tag for the word Red P R P is also an important tag pronoun. So, you is a pronoun, so you underscore, P R P is the tagged word, N N P is the tag for proper noun john underscore N N P, shows the tagging for john, as in the sentence john runs, so N N P is the tag for john and so on. So, this way a piece of text is completely tagged, for every word in it. . Proceeding further, now pos tag ambiguity is very common in text, I take her a sentence, which was mentioned in the last class to, in English I could have a sentence, I bank on the bank, on the river bank for my transactions. So, I bank on the bank on the river bank for my transactions, the lower suffixes indicate the occurrence of the word bank, so bank .1 here is a first occurrence of bank, bank 2 here is a second occurrence and bank 3 here is a third occurrence. Bank 1 is verb, because I bank on the river bank for my transactions, yet this bank means depend, so I depend on the bank on the river bank for my transactions. So, bank 1 is verb, the other 2 banks or noun, I bank on the bank. So, this is the actual bank where financial transaction, take is taking place and this third bank is nothing but the river bank in Hindi, the word [FL] can be a noun or a verb. So, when it is a noun it means food when it is verb it means to eat, so [FL] again has pos tag ambiguity. . Now, I take 2 examples here, which were mention towards end of the last class, but let us describe this in little more detail, just to bring out the ambiguity issue in POS tagging ram [FL]. So, [FL] is auxiliary verb, it is an auxiliary verb, so it has the tag V AUX. The meaning of the sentence is ram sings well, now ram [FL] here this [FL] is a qualified for the verb and therefore, this is an adverb. So, ram [FL] is an adverb ram [FL], so see that both the sentences look very similar except for this 2 words [FL] and [FL]. Here, we say that [FL] is not an auxiliary verb, because it is not a helping verb, an auxiliary verb requires a main verb, which it is helping, in the previous sentence [FL] was the main verb and [FL] is the auxiliary verb, it is the helping verb for [FL]. The auxiliary verb, carries the tense number and person information ram [FL] here indicates that, the person .is third person single or number and the tense is present tense ram [fl] ram sings well present tense singular number third person all this information is carried on hai. Now ram [FL] here, [FL] is not preceded by a main verb, we do not call it an auxiliary verb, it is called a copula verb and the symbol for this in parts of speech tagging is V COP. So, ram [FL] indicates the goodness of ram, ram is a good boy, now here [FL] qualifies [FL], which is a noun therefore, [FL] is an adjective, in the previous sentence [FL] was an adverb, because [FL] was qualifying the verb. So, the whole point of this discussion is that, this sentence are very similar, except for this towards [FL] and [FL]. But, the word [FL] has different POS tags depending on what it qualifies in the first case, it is adverb, second case it is an adjective, similarly [FL] preceded by verb, which is helping the main verb is the auxiliary verb and [FL] here is the copula verb. Now, we can understand that, words can a multiple pos tags and it is important to dis ambiguity them, it is important to place the correct tag depending on the sentential context, in which it appears. Now, if you look at this 2 sentences, you may be tempted to come up with this kind of rule that, when a word, which can be both adverb and adjective for example, [FL] here, if it followed by a verb [FL]. This then is an adverb, if it followed by a noun then it is an adjective. So, this is because the principle that is operating in your mind is that, [FL] is qualifying a verb therefore, it is adverb here [FL] is qualifying a noun therefore, it is an adjective here, but the problem comes when we insist that, the following word is the clue for disambiguation. So, part of speech tagging of course, is the first level task, syntax semantics all this have not been done, we have just started processing the text. So, we cannot assume any syntactical clue or semantic clue, we cannot assume parsing is done or the semantic role has been obtained. So, we necessarily have to depend on the clues from nearby area, so nobody refuse that, nobody argues with that, it is defiantly the case that, we have to disambiguate vast on clues available in the near vicinity. The most powerful clue comes from the suffixes the morphological features on the word itself, so in this case, we find [FL] is a word and the both cases the word forms the same, therefore there is no morphological clue, actually there should be an a here [FL]. So, ram [FL], there should be an a here and if we say that it is followed by a verb it is adverb .followed by a noun, it is adjective. Now, the problem is that, it is possible to have some amount of text between [FL] and [FL] and [FL], so ram [FL] for example, ram [FL]. So, you have the particle he between [FL] and [FL] ram [FL], this is again possible and therefore, you can have some amount of text between [FL] and [FL] sometimes, what can happen is that, because of movement, because of topicalization focus etcetera, words can move ram [FL], you can say ram [FL] ram [FL] to [FL]. So, now, you can see here [FL] has gone after [FL] here to has gone after [FL], so let me write this to clarify. . What I am saying ram [FL], because of topicalization, which means emphasis, one could have the situation ram [FL] to [FL] per and you can have some other piece of text coming after it. So, here also you can see that, [FL] is an adverb, it is still qualifying [FL], but if you if we say that, the rule is adverb should be followed by a verb, that rule will fail in this case ok. So, the rule will work in most cases from [FL] is adverb, this is fine, but in this case, because of the movement of the word, even though [FL] is adverb, this rule is not applicable, because [FL] is coming before [Fl], ram [FL] to [FL], we could also have ram [FL] to [fl] making it little more complex. Now can the same thing happen for adjective. .. So, we had the sentence ram [FL] again, because of word we meant, this rule of noun following an adjective will not work here, ram you can say ram [FL] par an another piece of text identical situation. So, [FL] has moved and because of this movement, the fact that, [FL] is qualifying a noun and therefore, it is an adjective that rule, we did not work. So, I suppose you have understood that this is the point. . .We have to use simple rules for part of speech tagging, namely the word clues from the immediate vicinity of the word, but they are fallible rules, there vital rules, because there can be many natural language phenomena, which work against this rules. . Proceeding further the process of part of speech tagging, is list all possible tag for each word in the sentence, choose the best suitable tag sequence. So, this is the process for each word will list all possible tags, for each word in the sentence and we choose the best suitable tag sequence. . .Here is an example to illustrate, this point people jump high, it is a fictitious sentence, let us not worry about the meaning of this sentence as to what it could possibly indicate may be it is a sentence from a this course in a context. So, people jump high people can be both noun and verb, jump can be noun and verb high can be noun verb adjective. So, if you are not convinced, we can take examples to see, how people jump in high can have this multiple tags, this I believe needs a bit of explanation. . So, we take people can be noun or verb how can it be noun, that is quiet simple people are the assets of a country. So, here it is noun people can be verb the place was peopled with the members of the tribes from the hills, I hope you can read the sentence the place was peopled with the member with the members of the tribes from the hills. So, let us say a place has been built and we populate, the place with members of the tribes from the hills, so here people means populate it, so thus people can be both noun and verb let us see the other words in this sentence jump. .. Can be both noun and verb, this is relatively easier, the fact that jump is verb is well known, I jumped over the fence, so here this is a verb, this was a good jump here, it is a noun, so such sentence are quiet common. We can take the word high finally, high can be noun verb and adjective, I believe the verb parts of speech tag is very rare, we live out verb, but high can be noun and adjective, which is quiet common, so for example, high hills. So, here this is an adjective and after the win, he was on a high here this is noun, so after the win, he was on a high this is noun. So, thus we find that, what is a multiple parts of speech and it is quiet common to have words in a sentence with multiple part of speech and it is necessary to disambiguate them. So, we proceed further. .. And now suppose, we have the task of part of speech tagging in front of us, we would like to pos tag, this words in the sentence people jump high. Now, a very useful convention is to have the sentence beginner, which is typically the hat symbol and the sentence finisher, the sentence ended, which is the dot symbol, this is the full stop. So, these 2 d limiters are the sentence for the sentence, the part of speech tagging begins from the hat ends on dot, for a particular sentence. So, this shows here a very simple picture, we place the tags along site or on top of every word in the sentence. So, the people, we saw could be noun and verb just for a simple a scheme, just for this discussing a simple scheme. We place all the tags or all the words, so this is a simple minded scheme, but it will work, because the tags, which are completely improbable will not be taken up. How one could place tags, which are applicable is a separate discussion, which we can go in to later. So, we have this 3 words people jump high or people, we have N V A and R, which are noun verb adjective and adverb tags, so all the words have this 4 tags, so assume in our discussion, we are concerned only with 4 tags noun verb adjective and adverb. So, we start with the hat symbol, which is the beginner of the sentence, from here, we can transit to N or V or A or R from here, we can transit to any of this 4 tags and this transition is from each state. So, each tag is a state here, so from this state 4 transitions are possible from, we state 4 again A again 4, R again 4. .So, there would be 16 arcs going from the this set of states, this first column of states to the second column of states, similarly from the second column to the third column, we can have 16 transitions, because from each state, we can make 4 transitions. And finally, we have this 4 transitions going into the finishing state, which is dot. So, the an important point here to notice that, the sentence beginner has this prevail tag of hat and the sentence ended or the full stop has this prevail tag of dot. So, this whole graph, which is nothing but a graph is to be traversed for best possible path from hat to dot. So, now, let us discuss a an important point, what we have done, so for is that, we have taken the words of a sentence and we have erected columns of fast tags on them. It is a separate matter of discussion as to how, we can selectively place, only those tags, which are applicable, this is not very important right now. For understanding, what is going on as a process, it is sufficient for us to see that on top of words, we have tag sequences columns of tags, at each tag should be looked up on as a state. The first starting state is the hat state, which begins the pos tagging processes and the last finishing state is the dot state, which is the full stop. And this finishes the tagging process on the way starting from hat to the dot symbol, we are interested in finding the best possible path from hat to dot traversing the states, from each column, we choose only one state. So, if there are n words in a sentence, there are 2 delivators hat n dot, so if there are n words then there are states of the tags and finally, when we find the best possible tag sequence, we would have described a path of length n plus 2 in the sense that, there are n plus 2 nodes in this whole path. And this path gives me the best possible tag sequence we choose one state, one single state from each column of states. So, we can see now that, the whole pos tagging process has been reduce to a graph traversal task, starting from the hat state to the goal state, we find the best possible path and this path chooses only one state, from the column of states on each word. So, this makes a formulation quiet clear, we are now ready to look at the techniques of fast tagging. .. Before that, we would like to understand why pos tagging could be channeling and we will be discussing mainly with the English examples, but in this part let us take some examples from Indian languages and this would show, why part of speech tagging is a real challenge, it is not a trivial task. At this part let me just remind you once again this fact, we spend just 2 minutes to repeat a point, part of speech tagging is crucial for any L L P task, you have to begin natural language processing of text with part of speech tagging. So, emphasis is on the word begin, we start natural language processing with part of speech tagging ok. So, before part of speech tagging, what is available possibly is morphological analyses information, so if a language has morphology analyzer, it would take the words of the language and stripe of the suffix get the morphological features of the words for example, the word [FL] here, the suffix is a the root what is [FL] the number is plural form. So, this is the plural form of [FL], it could also with the oblique form, so let us not go into those details, a point is that, the words have been presets for separating the suffix from the root word and the word features are available. So, when you begin part of speech tagging the only information that is available is the information at the word level morphological features and the suffixes. So, we cannot assume any syntactic information is available, we also cannot assume that semantic roles are available. .Though the semantic properties of the words may be available, but that may require since this ambiguition, it may require words in this ambiguition, but words into this ambiguition is later task, which has to be done after part of speech tagging. Therefore, it is necessary the case, that part of speech tagging has to be done with tremendous amount of constraint, you can place part of speech tag on a word only from limited amount of context in the vicinity of the word. So, the word itself and may be some 2 or 3 words, before and after it that is all, this is the only information available and using that, your force to do that is ambiguition. So, this produces challenges and let us looks at some of these challenges, which are very interesting. . We take up the phenomenon of [FL] and their inflected forms in Hindi and their equivalents in multiple languages, we will mainly discuss Hindi at some example from Bengali and Sanskrit. So, the problem is to place tags on [FL] and [FL] on the text and their forms. .. Now typically, the level that is given are DEM and PRON, please understand, what we mean by this DEM means demonstrative and PRON means pronoun, so PRON is pronoun DEM is demonstrative. Let us look at this sentence [FL] cricket [FL], this is the sentence [FL] cricket [FL], the boy who came yesterday plays cricket well, this is the meaning of the sentence in English. Look at the word Jo here, which is in capital and it has been given the tag of DEM Jo underscore DEM, DEM is the tag on Jo, which indicates demonstrative. So, here the word Jo has a demonstrative function Jo [FL] cricket [FL], we a specify particular boy [FL], so that is why, it is demonstrative. Take the next sentence [FL] cricket [FL], so almost same sentence expect that [FL] is dropped [FL] is dropped. So, Jo has to find, it is what is called referent, what does Jo refer to, it refers to something, which is not present in the sentence, however, this Jo can be matched with [FL] Jo [FL]. So, Jo [FL] who the person, who came yesterday plays cricket well, this is the meaning. Now, this Jo not a demonstrative, its pronoun because it is reference is somewhere else and this Jo ending visiting has what is called demonstrative role, it indicates a particular boy Jo [FL] and this Jo has an unspecified noun another and it is a pronoun, so this Jo is a pronoun. Now it is clear that here, we are faced with a disambiguation situation, because Jo can have both done and from and we need to find out, which level will be applicable in the particular context. .. So, we formulated this disambiguation rule, which is pretty of S, if Jo is followed by noun, then it is a demonstrative. . So, you can see the previous transparency that, Jo was followed by noun here. And therefore, it is a demonstrative. .. You are possibly already saying some problems here and we will discuss those problems, so Jo is followed by noun, it is a demonstrative else, we have to take more complicated steps to find out what Jo is. . Now, we have the problem of what is called false negative and what is called false positive for any rule, which is suppose to produce a level or for that matter for any rule, it is possible to get into false negative and false positive situations. Let me illustrate from this example itself when, there is arbitrary amount of text between Jo and the noun, than .the rule that, we have formulated, we will fail. So, take the sentence here for a movement forget about this or ignore, this piece of text in capital for a movement, if you ignore this then we have the sentence Jo [FL] cricket [FL]. So, this Jo and [FL] Jo is clearly demonstrative, the problem is that, Jo will continue to be demonstrative, even when it is not followed by a noun, because you have a an arbitrary amount of text between Jo and [FL], this text is seen here, [FL] Chennai academy may coaching [FL], this should be may Chennai academy may coaching [FL] cricket [FL] ok. So, sentence is a slightly artificial one, what an interesting sentence still Jo [FL] a Chennai academy may coaching [FL] cricket [FL] that means, the boy who came running and who was panting [FL] and who was crying [FL] and who was taking coaching in Chennai academy, he goes to a cricket coaching class this boy, who came yesterday he plays cricket well. So, all this are modified, so are the qualifiers for this word [FL], so Jo [FL] Chennai academy a coaching [FL] cricket [FL]. So, again Jo is a demonstrative, but see Jo is not followed by noun [FL], this is a verb and therefore, this rule will fail and this is a case of false negative, we are not able to place demonstrative on this Jo, using that rule. So, this is a case of false negative, it is saying most probably the tag is not DEM and is failing and therefore, this is failure is not desirable ok. . .So, this is a case of false negative and there can be case of false positive for example, take this sentence here, Jo [FL] say this is the sentence, one who understands the ways of the world achieve success. So, in this case, if we place the demonstrative tag will go wrong, because the rule says that, if Jo is followed by a noun [FL] is noun here. So, it follows JO and therefore, it has placed simple mindedly a DEM the demonstrative and it is gone wrong. So, this is what we mean by false positive, this is wrongly given the demonstrative tag, this is an interesting sentence where, demonstrative of pronoun tag cannot be decided, because of ambiguity. So, the sentence is Jo [FL] and then there is a piece of text, so Jo [FL] the it has 2 meanings, one meaning is [FL] here is person, the person who understands the relationship between human beings [FL]. So, the person who understands the relationship between human beings can be called a compassionate person for example, this is a sentence. So, in this case [FL] is demonstrated by Jo and therefore, this can be the this can be given the level DEM, but see another reading for this sentence Jo [FL] here [FL] means man and men relationship between man and man. So, they go together and this Jo has an un specified noun, which it refers to, so this JO therefore, will be pronoun for that reading, now this sees a very difficult problem at the level of past again, you can out resolve this issue, because it requires grouping together [FL] or living out that grouping, this [FL] is separate from [FL]. So, this shows a case of false positive where, Jo can be wrongly given the tagged them and in this case, it is difficult to decide, it can go either way. So, therefore, a simple rule like this where, Jo followed by noun should be given the DEM tag is very brital, it can have both false negative and false positive. .. We take the case of Bengali where, morphology markings are quiet weak on the words and we find here interesting cases, the sentence here is Je [FL], so that means, ones who gets love can give love. So, in this case again, the rule that, if Jo Je equivalent in bengali Je is followed by noun then it should be given the DEM tag, this goes wrong here [FL] is a noun it is after Je, but it will go wrong, because this Je is not referring to [FL] here. This Je is referring to an unspecified noun not in the sentence, so this wrong and in this case however, the rule is working right. And here, we have the sentence as [FL] the love that, you imagine exits, this needs a bit of correction the love that, you imagine exits is impossible in this world Je [FL] here, this Je is the demonstrative for [FL] and therefore, if you give the tag them it is right. So, we have a very interesting situation where, the word J is followed by identical noun, but the further sentential context shows where, them would be wrong and where it will be right. So, this shows it is a difficult problem, let us have a bit discussion on this now. So, what is happening is that, this was like Jo Je, they have both demonstrative role and pronoun role and this clue for whether, it is a demonstrative or pronoun can come from far apart in the sentence. So, the clue can be far away or the clue can be, because of some kind of syntactic structure, the sentence that we had in Bengali [FL] pi. So, in this case the fact, that Je is not demonstrative for [FL], comes from the word pi Je pi 1 who gets. So, this is .little far away from Je and it can be quiet far away depending on arbitrary amount of text being inserted and therefore, this disambiguation would be difficult. . So, we proceed further, we see that other forms of Jo like Jis Jin [FL] us un, they can fail in similar situation and all this forms are very very frequent, in the corpus. Therefore, all this put together can lead to a large amount of error of pos tagging all this errors can accumulate and you could have a situation where, the accuracy is pretty low, because simple rules cannot disambiguate the situation. . .We take the another disambiguation rule, rule number 2, which says that, if Jo is oblique it is attached with ne Ko se etcetera. If Jo is oblique then it is pronoun. So, this also looks like and accurate rule, if we do not examine this closely, we may get in a impression that, this is all there is in giving the pronoun tag to Jo. So, let us repeat this rule once again, if Jo is oblique that means, it is associated with some case mark and ne Ko se etcetera, then it is pronoun else, there are other tests. . So, this will fail, this will have false positive in case of languages that, demand agreement between Jo form and the noun, it qualifies for example, in [FL]. So, this is the meaning of this sentence Sanskrit insists that, the demonstrative and the noun it is demonstrative for must have forms that agree. So, here it is sasti vibakthi on baalakasya of the y, so [FL] has to be on the Jo for mace also [FL]. But, in this case, this rule that, if the Jo form is in case marked form, than it is necessarily pronoun that rule will fail, now the example is with Sanskrit, however it can very well hold for languages, which insist on this kind of agreement, we have another case here [FL]. So, here come on [FL], which means beautiful, which is qualifier for [FL], indicates that between [FL] and [FL] there can be arbitrary amount of text leading to the rule application going wrong. So, this indicates the complexity of formulating a rule. Now, may be a clarification is required here as to what, we mean by this oblique form and why is the case that, it will definitely get the pronoun tag, let us take an example. .. This is the example I will take, so we take the sentence [FL] this [FL], so one who has eaten should repair for bed, so one who is eaten should go to sleep [FL]. So, this is what, we mean by oblique form Jisneh is the oblique form of Jo, this is Jo [FL], now in Hindi the oblique form of Jo will always be a pronoun form. So, that is why that rule is quiet safe in Hindi, it is hundred percent accurate [FL] here, this will be a pronoun, but we are saying that, when there are languages, which insist on the [FL] coming on the Jo form well, it is demonstrative for a noun, which insist on agreement between the Jo form and the noun it is demonstrative for. In such cases, this rule will go wrong and we have seen an example in Sanskrit where, this kind of situation holds and other languages also may have this kind of agreement demand. .. Now elaborating further on this rules that depend on whether the noun following [FL] or it is form is oblique or not can also fail, because the case marker can be far from the noun. So, we can have constraints like [FL] or its form [FL], so the girl who was afflicted with jaundice the girl, who have jaundice is the meaning of this part of this sentence [FL] and this kind of construction is common in Hindi these days. So, the case marker is quiet far from [FL] and that is why, we need to be a careful here. So, we need to discuss phenomena across languages to see what kind of fails safe rules can be used for the demonstrative pronoun disambiguation and it is not a simple problem honesty many language evidences. .. So, the conclusion from this discussion on DEM and pronoun is that, DEM verses pronoun cannot be disambiguated, in general at the level of the POS tagger. That is we cannot assume parsing, we cannot assume semantics and if such clues are not present such information is not present then the demonstrative verses pronoun cannot be disambiguated in general, so that is the conclusion from this discussion on DEM and pronoun. Now, one should at assume that, this is the only difficult case for part of speech tagging, there are many other such levels, which frequently get confused with each other one of them is main verb and auxiliary verb for India languages. It is also possible to confuse between noun and adjective, so if we have a an expression like golf clap or cricket bat here both cricket and bat are noun, but the first cricket is having an adjective function, it is an adject I will, which bat or what kind of bat cricket bat. So, here that is confusion between noun and adjective in the next class, we will discuss the mathematics of part of speech tagging and the algorithm. . \n\n",
          "document_id": 1144861
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "Which is the first non Trivial task of statistical NLP processing?\n",
              "id": 544557,
              "answers": [
                {
                  "answer_id": 631858,
                  "document_id": 1144865,
                  "question_id": 544557,
                  "text": "part of speech tagging happens to be the first non trivial task of statistical natural language processing, making use of machine learning techniques.",
                  "answer_start": 150,
                  "answer_end": 300,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are the other parameters for accuracy checking?",
              "id": 544598,
              "answers": [
                {
                  "answer_id": 632331,
                  "document_id": 1144865,
                  "question_id": 544598,
                  "text": "other parameters for accuracy checking, how to check the quality of tagging this is done through three parameters called, precision, recall and F score.",
                  "answer_start": 12820,
                  "answer_end": 12972,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are the different categories of noun in English?",
              "id": 544558,
              "answers": [
                {
                  "answer_id": 631880,
                  "document_id": 1144865,
                  "question_id": 544558,
                  "text": "in pronoun again we have many sub categories like, personal, reflexive, relative, reciprocal and W h word.",
                  "answer_start": 1216,
                  "answer_end": 1322,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are residual tags used for?",
              "id": 544579,
              "answers": [
                {
                  "answer_id": 632075,
                  "document_id": 1144865,
                  "question_id": 544579,
                  "text": "we have residual tags which are for foreign words, symbols, punctuation, un known words and equal words.",
                  "answer_start": 2657,
                  "answer_end": 2761,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Explain in brief about precision, recall and F score.",
              "id": 544600,
              "answers": [
                {
                  "answer_id": 632371,
                  "document_id": 1144865,
                  "question_id": 544600,
                  "text": "precision measures how many are correct from whatever has been obtain, recall measures of the correct ones how many have been obtained and these two things can be combine to compute what is called the F score, F score is two into precision into recall divided by precision plus recall. So, this is nothing but the harmonic mean",
                  "answer_start": 14613,
                  "answer_end": 14940,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What happens if we maximize the harmonic mean?",
              "id": 544601,
              "answers": [
                {
                  "answer_id": 632388,
                  "document_id": 1144865,
                  "question_id": 544601,
                  "text": "if we maximize the harmonic mean automatically the geometric mean and arithmetic mean also will go up, ensuring increase in harmonic mean, ensures increase in geometric mean and arithmetic mean also automatically.",
                  "answer_start": 15408,
                  "answer_end": 15621,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are the subcategories of Pronouns?\n",
              "id": 544562,
              "answers": [
                {
                  "answer_id": 631987,
                  "document_id": 1144865,
                  "question_id": 544562,
                  "text": "verb we have two large categories again, main and auxiliary under main there could be finite verbs, non finite verbs, infinity, gerams.",
                  "answer_start": 1553,
                  "answer_end": 1688,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What do you mean by Lexical category?",
              "id": 544603,
              "answers": [
                {
                  "answer_id": 632459,
                  "document_id": 1144865,
                  "question_id": 544603,
                  "text": "Lexical category means, the most frequent are most accepted category of a word which is a record in the dictionaries,",
                  "answer_start": 20124,
                  "answer_end": 20241,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How do you differentiate nouns and verbs in simple?",
              "id": 544605,
              "answers": [
                {
                  "answer_id": 632477,
                  "document_id": 1144865,
                  "question_id": 544605,
                  "text": "nouns can be preceded by definite or indefinite articles, but not verbs. So, for example, verbs cannot be preceded by an article typically unless in poetry let us say. So, A or the cat is fine, but an applauded, applauded is a verb in past tense verb and before that would be ungrammatical, additionally nouns combine with other words to found phrases and they can be complements of verbs and verbs cannot do, so.",
                  "answer_start": 21429,
                  "answer_end": 21842,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Which algorithm can be used to learn the tags produced by Lexicographers?",
              "id": 544585,
              "answers": [
                {
                  "answer_id": 632141,
                  "document_id": 1144865,
                  "question_id": 544585,
                  "text": "when lexicographers produce tags on the language document and then machine learning algorithms are used to learn this tags",
                  "answer_start": 3610,
                  "answer_end": 3732,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What does a sentence consists of?",
              "id": 544606,
              "answers": [
                {
                  "answer_id": 632485,
                  "document_id": 1144865,
                  "question_id": 544606,
                  "text": "in a sentence there are subjects and complements of a verb",
                  "answer_start": 22433,
                  "answer_end": 22491,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are the two large categories of Verbs in English?",
              "id": 544566,
              "answers": [
                {
                  "answer_id": 632027,
                  "document_id": 1144865,
                  "question_id": 544566,
                  "text": "Under verb we have two large categories again, main and auxiliary under main there could be finite verbs, non finite verbs, infinity, gerams.",
                  "answer_start": 1547,
                  "answer_end": 1688,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How are phrases formed?",
              "id": 544607,
              "answers": [
                {
                  "answer_id": 632494,
                  "document_id": 1144865,
                  "question_id": 544607,
                  "text": "verbs typically do not be arguments of other verbs, nouns are the arguments. And nouns are typically preceded by determiners, articles to form phrases.",
                  "answer_start": 23316,
                  "answer_end": 23467,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Which parts of speech cannot be distinguished in English?",
              "id": 544567,
              "answers": [
                {
                  "answer_id": 632029,
                  "document_id": 1144865,
                  "question_id": 544567,
                  "text": "we mention adjectives and adverbs cannot be many times distinguished in English",
                  "answer_start": 1966,
                  "answer_end": 2045,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "In English how can adverbs be formed?",
              "id": 544608,
              "answers": [
                {
                  "answer_id": 632503,
                  "document_id": 1144865,
                  "question_id": 544608,
                  "text": "In English adverbs can be formed from adjectives by adding ly",
                  "answer_start": 23832,
                  "answer_end": 23893,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Which suffix can be used to identify the Adjectives, Adverbs?",
              "id": 544568,
              "answers": [
                {
                  "answer_id": 632032,
                  "document_id": 1144865,
                  "question_id": 544568,
                  "text": "we have the le suffix which helps to identify the adjectives, identify the adverbs.",
                  "answer_start": 2047,
                  "answer_end": 2130,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are relaters?",
              "id": 544609,
              "answers": [
                {
                  "answer_id": 632504,
                  "document_id": 1144865,
                  "question_id": 544609,
                  "text": "there are relaters which join entities in a sentence.",
                  "answer_start": 24131,
                  "answer_end": 24184,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Which parts of Speech comes after the noun?",
              "id": 544569,
              "answers": [
                {
                  "answer_id": 632035,
                  "document_id": 1144865,
                  "question_id": 544569,
                  "text": "prepositions of English and they come after the noun",
                  "answer_start": 2161,
                  "answer_end": 2213,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What does semantic test, morphological test,  syntactical test realize?",
              "id": 544610,
              "answers": [
                {
                  "answer_id": 632505,
                  "document_id": 1144865,
                  "question_id": 544610,
                  "text": "semantic realize meaning, morphological realize on word forms, syntactic realize in where in many phrases",
                  "answer_start": 26350,
                  "answer_end": 26455,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "How long does it take to add a new pronoun?",
              "id": 544611,
              "answers": [
                {
                  "answer_id": 632553,
                  "document_id": 1144865,
                  "question_id": 544611,
                  "text": "we do not add new pronouns everyday, it is only after centuries or 200 years, 300 years that pronouns get added to a language repository. So, in old English for example, there was this pronoun call thou which got deleted later in modern English.",
                  "answer_start": 30590,
                  "answer_end": 30835,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What are Conjunctions?",
              "id": 544571,
              "answers": [
                {
                  "answer_id": 632045,
                  "document_id": 1144865,
                  "question_id": 544571,
                  "text": "conjunctions are coordinators and subordinators, they help join noun phrases, nouns and even complete sentences. ",
                  "answer_start": 2215,
                  "answer_end": 2328,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Which forms the largest chunk of language data?",
              "id": 544592,
              "answers": [
                {
                  "answer_id": 632182,
                  "document_id": 1144865,
                  "question_id": 544592,
                  "text": "common nouns form a the largest chunk of the language data ",
                  "answer_start": 5224,
                  "answer_end": 5283,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "What is confusion matrix and how can it be used?",
              "id": 544594,
              "answers": [
                {
                  "answer_id": 632260,
                  "document_id": 1144865,
                  "question_id": 544594,
                  "text": "a particular structure called the confusion matrix is of great help, now what is done is that the part of .speech tags are placed row wise, part of speech tags are also placed column wise the same part of speech tags.",
                  "answer_start": 8996,
                  "answer_end": 9213,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Which category does not hold for Hindi but holds for Bengali?",
              "id": 544573,
              "answers": [
                {
                  "answer_id": 632053,
                  "document_id": 1144865,
                  "question_id": 544573,
                  "text": "Classifier does not hold for Hindi, Hindi does not have this particular category, but in Bengali they are classifiers. ",
                  "answer_start": 2445,
                  "answer_end": 2564,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "Mod-01 Lec-15 PoS Tagging; Accuracy Measurement; Word categories\n\nIn the last lecture, we discussed why part of speech tagging is a challenging task, part of speech tagging happens to be the first non trivial task of statistical natural language processing, making use of machine learning techniques. Now, we will discuss today how to calculate accuracy of part of speech tagging, what is the way to report correctness of part of speech tags obtained, how to do error analyses. And then we will move on to discussing the categories that come from part of speech tagging, the linguistic foundation of part of speeches which are word categories. . So, just a recap of the tags that we had seen for Indian language processing, this is happening in the context of a large machine transition effort throughout the country involving many institutions. We saw that the words have higher level categories with the form of noun, adjective, verb, adverb, and so on. And within each large category there are sub categories, so under noun for example, we have common noun, proper noun, Nloc which are special categories, then verbal noun which is not there in Hindi, but is found to be important in Dravidian languages. .. Then in pronoun again we have many sub categories like, personal, reflexive, relative, reciprocal and W h word. Under demonstratives we have deictic relative and W h word, which again are quiet common with the pronoun words. So, we remarked that it is often a challenge to correctly distinguish pronoun, tags from demonstrative tags. . Under verb we have two large categories again, main and auxiliary under main there could be finite verbs, non finite verbs, infinity, gerams. For Hindi it is not possible to distinguish them an ambiguously from, the word itself are from a small window around .the word. And therefore, this sub categories are dropped, we work with main verb and auxiliary verb. . Then, we move on to adjective and for Indian languages, we mention adjectives and adverbs cannot be many times distinguished in English, we have the le suffix which helps to identify the adjectives, identify the adverbs. Post positions again are like prepositions of English and they come after the noun, conjunctions are coordinators and subordinators, they help join noun phrases, nouns and even complete sentences. . .Then we come to particles, where we have default, particles, classifiers, interjection, intensifier and negation. Classifier does not hold for Hindi, Hindi does not have this particular category, but in Bengali they are classifiers. Then a quantifiers are used which are general quantifiers cardinals and ordinals. . Finally, we have residual tags which are for foreign words, symbols, punctuation, un known words and equal words. So, all these form something like a miscellaneous bag whatever could not be put in large categories are placed here, in this miscellaneous bag. So, this was an account of part of speech tags, which has being used for Indian languages and this is looked up and as a pan Indian standard. Now, if you remarks are in order for this part of speech tags and their symbols. So, as you can see this part of speech tags have sub categories and this sub categories are denoted by the main category underscore the subcategory. Now, the question of is this grouping of tags, good enough is it correct complete, so that will eventually emerge when we begin to actually part of speech a lot of data, the ministry funded project from government of India, stipulates that language processing groups create about 25000 strong corpora, tag to it part of speech. And when lexicographers produce tags on the language document and then machine learning algorithms are used to learn this tags, then we would come to know the efficacy of this tag set. So, this means that we will be able to identify if the lexicographers are .comfortable with this tags, at this tags described well enough, clearly enough, precisely enough. So, that the lexicographer has no problem as an a tag to a particular word and after that, when we submit this tag copula to a machine learning algorithm does the algorithm easily learn this tags with high accuracy, this is the ultimate test. Let me, write down this two tests for the efficacy of a part of speech tag. . So, pos tag efficacy is a function of one lexicographer slash annotator is and amenability to high accuracy machine learning algorithm. So, we actually have for two entities here, human annotator and computer, so this will tell us how would our pos tag set is and when the pos tag set is, designed properly it serves both the sense let us annotator find it easy to annotate data with this tag sets. And high accuracy machine learning algorithms also can be designed. .. Let us move forward and we discuss now the accuracy measurement in part of speech tagging. . First we show a bar chart, which is typically shown for part of speech tags systems. So, you can seen here, there are two access the accuracy is plotted on the y axis and part of speech tags are mention on the x axis. So, NN we have seen is the common noun tag, so for this particular system which is reporting accuracy, the common noun accuracy is .close to 100 percent. And common nouns form a the largest chunk of the language data and therefore, high accuracy here is good news. NST we have seen is a special kind of tag required for Indian languages where, there are words which can act as pos positions and also can act as nouns things like . and so on there the accuracy is less than 90 percent. On PRP which is the pronoun the accuracy go crosses 90 percent, demonstrative accuracy is also around that close to that, main verb accuracy is high, main verb accuracy is close to common noun accuracy. And this should be Indian languages typically are strong on morphology and verb forms are quiet an ambiguously, shown by a markings on the verbs themselves. So, it is possible for a morphology analyzer to send the information of verb and therefore, a part of speech tagger can make use of this information to accurately predict that a word is a verb or not. Verb auxiliary also has similar kind of accuracy, close to the common noun accuracy may be about to 96 percent are shown, 95 percent. Adjective accuracy is not, so high that is slightly lower than 90 percent and the reason of course, is it is neighbor which is RB or adverb, adverb accuracy you can see is quiet low less than 70 percent. And the reason for this two categories low accuracy is because they can be quiet easily confused in Indian languages. So, ram . here . is adjective, ram . here . is adverb and it is possible that this adverb is far away from the verb and therefore, from the immediate vicinity of the word, it is not easy to disambiguate the category. PSP which are pos positions again have low accuracy, which is close to 70 percent and the reason should be that it is clashing with the NST’s the words which can act as locative nouns, temporal locative or special locative nouns. So, PSP and NST can easily confused and this reduces the accuracy of both RP’s are particles, particles also have low accuracy and there are many particles like, negative and so on. And this accuracy is low which needs to be analyze, particles need not have low accuracy in general, the conjuncts which are like and or, but etcetera, corresponding to Hindi which is are . than .. So, these words are an ambiguous and they should be deducted with complete accuracy, one needs to investigate why there are not exactly 100 percent. .Quantified accuracy is again below 90 percent, which is also a matter to be investigated because quantifiers also are quiet unique and distinct for example, all each every . this are quantifiers and they seem to have a low accuracy. This QW was, w h quantifier question quantifiers, than QF is again quantifier has similar accuracy has QW, QC is another kind of quantifier, QO is again another quantifier they have various kinds of accuracy. INJ is the interjection which has very low accuracy, very strangely and negative again has accuracy which is moderate close to 90 percent and so on UT is not used in the current tag set. So, this is for some language and some of this tags are understandable they are in the tag set, which was discussed for Hindi and some are specific to that language and the accuracies are in the form of bars. So, from this diagram one can make out which category has, what kind of accuracy and the low accuracy tags are to be investigated further that is were one has to invest resources, ideas to improve the accuracy. So, that the accuracy of the overall system goes up. So, this is an extremely useful graph and extremely useful way of understanding, how the part of speech tagger is working and it is absolutely indispensible, for design of good quality part of speech taggers, one needs to have this kind of bar category accuracy report. . Proceeding further, how did we come up with that kind of bar chart. So, here a particular structure called the confusion matrix is of great help, now what is done is that the part of .speech tags are placed row wise, part of speech tags are also placed column wise the same part of speech tags. So, if I take a particular part of speech let us part of speech tag let say NN which is the common noun, we see the row of NN in the row of NN I find that for the column under NN, we have about 50000 entries. NN has been confused with NST 18 times, with pronoun 92 times, then with demonstrative 2 times, main verb 167 times and auxiliary verb 4 times. One might wonder how can a noun and pronoun be confused, how can a noun and main verb be confused amongst to all, we have to remember that in Indian languages there is a phenomenon called conjunct verb formation let me write it down. . So, we are wondering why NN can be confused with VM we wonder it. Now, how can a common noun we confused with a main verb, the reason is Indian languages have this phenomenon called conjunct verb. So, this is nothing but a noun or adjective plus a verb in the form of . and so on. So, for example, [fl] for example, . which means to advice, so in Hindi for the action of advising, we have a double word group which has [fl] and [fl] two parts in it. So, . is the nominal part in this group this whole thing is a verb, though the first part is a noun. And the part of speech tagger should possibly tag the whole thing as a verb and this kind of problem can give rise to main verb noun confusion this is the explanation. .. So, coming to the matrix once again the confusion matrix is a very important structure, which shows which part of speech tag has been confused, how many times with another category. So, noun we have analyzed then we find that NST has been confused it noun 33 times, this need not be symmetric NN has been confused with NST 18 times, but NST is confused with noun 33 times. So, this means that for NN we have placed NST wrongly 18 times. And for NST we are placed NN 33 times wrongly. So, this need not be symmetric of course, as it is clear similarly if we take that them row them is a demonstrative, what does our expectation from the last few lectures, we understood that DEM and pronoun cannot be easily separated from each other. And that is bound out by the data here, we find that the DEM has been confused 231 times for pronoun and 231 times forms, a pretty significant percentage of the total number of demonstratives. So, we have placed PRP for DEM 231 times and out of about 3000 such tags 200 times this error has occurred to which is about 6 percent of error more than 6 percent of error I would say. Similarly, the main verb has been confused with noun 225 times, so this is a matrix this is also known as the confusion matrix, it is an extremely useful data structure which tells us, which category has been confused, which other category how many times. So, going back to the previous slide while this reports accuracy on each part of speech tag, this is the function of the bar chart, the confusion matrix gives more detail it shows .how many times a tag has been confused with other tags. Now, it is not very difficult to see that the noun accuracy which was shown on the y axis of the bar chart, can be computed by dividing this number by the some of the numbers in this row. And we can see that this is close to 50000 other numbers are pretty small and that is why the noun accuracy is close to 100 percent. Now, if we take the DEM row then them has been arrow nastily marked in here, 3 times then 231 times as PRP, VM 2 times, VAUX 1 time and this kind of errors give rise to the them accuracy as 3002 divided by some of all this numbers. Now, one can understand how this numbers have been obtained and plotted on the bar chart, so confusion matrix very useful. . We come to other parameters for accuracy checking, how to check the quality of tagging this is done through three parameters called, precision, recall and F score. Precision P recall or F score, which is a function of the precision and recall. Let us understand how this is computed, suppose we have this actual set of tags which should have happen. So, how do we visualize this, we visualize this these way that we have the goals standard data. That means, we have language data the text which has been tagged by their actual tags and this data is available to us. So, we have a set of words with their corresponding tags, so these tags will form the actual set we call it A, now on this textual data we have got some tags by the part of speech tagger, they may or may not be same as the actual tag .which is there in the goal standard data. However, we have this set of obtained tags which is O. So, set of actual tags is A, set of obtain tags is O and then precision can be measured as A intersection O divided by the number of O. So, the number of times A and O agree divided by the number of O’s, what is the meaning of this, the meaning of this is that precision measures, the accuracy as a percentage of what has been obtained. So, out of the things that have been obtained, cardinality of O how do the things which have been obtained, what percentage is correct that is A intersection O. Recall, on the other hand is of the actually correct tags how many have been obtained which are correct. So, we already know that A intersection O is the agreement set between A and O this is the number of times the part of speech tagger has been correct, this is the proportion of how many things are correct, how many correct tags have been obtained from the actual correct set of tags this is recall. So, precision measures how many are correct from whatever has been obtain, recall measures of the correct ones how many have been obtained and these two things can be combine to compute what is called the F score, F score is two into precision into recall divided by precision plus recall. So, this is nothing but the harmonic mean now the question that may arise is why F score is defined as a harmonic mean. So, this requires a bit of writing. . .So, we know that harmonic mean is less than or equal to geometric mean is less than or equal to arithmetic mean. So, this is harmonic mean, this is geometric mean and this is arithmetic mean right and this relationship holds, harmonic mean is the smallest of the three quantities, arithmetic mean, geometric mean, harmonic mean. So, it is clear that if we maximize the harmonic mean automatically the geometric mean and arithmetic mean also will go up, ensuring increase in harmonic mean, ensures increase in geometric mean and arithmetic mean also automatically. . So, if we look at the slide again when we improve the F score, we improve the arithmetic mean of both precision and recall the average of precision and recall, we also improve the geometric mean of precision and recall. So, this is a good idea, now let me just write down the intuitive meaning of precision and recall. .. Precision P this measures out of those obtained what proportion is correct, out of those obtained of what proportion is correct this is precision. And recall or measures out of those correct how many are actually we got. . So, this the measure look at slide again this intersection area is the agreement between A and O. So, this intersection divided by this whole circle gives out of those obtained what proportion is correct and this intersectional area divided by this green circle, measures what proportion of correct things have been obtained. So, I spent some time on precision .and recall and F score because this is a very frequently used measure everywhere. Now, we note an interesting thing and we find that the precision recall and F score they are different under certain condition and they are saying in other conditions. . So, if every word is given a tag and no word is left out, if every word is given a tag and no word is left out. Then we know that, the size of A is equal to size of O therefore, precision equal to recall is equal to F score. . .Why, so if you look at the slide again the reason is that the numerator A intersection O is same for both precision and recall, only the denominator is different. But, if we a place a tag for very word then this cardinality of O and cardinality of A become same, only when the part of speech tag are misses out some words because let say it is un known it is not there in the dictionary then we may have different values of precision and recall. And there precision recall and F score may be different from each other, but in general when we obtain a tag for every word, these quantities are same. . We proceed further on the slides and interesting thing is the relation between precision and recall, typically precision is inversely related to recall why is it, so. Let us see, the graph here recall is being plotted on the x axis, precision on the y axis, we see that as recall improves precision tense to come down. .. This can be understood by going back to the previous slide, where the precision and recall have been defined in terms of the intersection area. So, what happens is that to increase the precision we may do the following, one of the two one is that we can increase the numerator. That means, increase the overlap between the actual tag and the obtain tag or we may decrease the size of the denominator, the size of O. Now, when we decrease the size of O, the precision can go up, but actually we are obtaining less and less tags. We are possibly missing out on words not tagging them and that has an adverse effect on recall, if I want to improve recall then we again may increase the numerator and decrease the denominator. Now, decrease the denominator is not really possible because the actual set of tag towards are already given, we do not have much control on this, but when we increase this value, when we increase this try to increase this overlap, then we find that we are sacrificing on the precision. So, we can have more detail discussion on recall and precision later. .. So, in general the behavior is this that recall increase, typically entails precision fall. Now, this situation is quite typical and one can come out of this situation, only by injecting knowledge when this point is a deeper issue which we can understand later. . Now, we move on to the tags onwards and we remind our self that part of speech tagging is a layer, which sits between syntactic processing and morphological processing is a very useful diagram a classical diagram of natural language processing, where we say .that the processing of language happens in layers. Now, each of this layer makes is a rules and resource. . We move on to understanding words and their categories because we have been discussing part of speech tag, so long, but what is the linguistic foundation for this part of speech tags do they really exist does the language entail the existence of this tags. So, we discuss words and their categories. . .And the first discussion point is the categories themselves. We have this classical conflict in part of speech tagging, between lexical categories and functional categories. Lexical category means, the most frequent are most accepted category of a word which is a record in the dictionaries, so for example, if we have the word quick for example, quick we know is an adjective. And typically people’s perception about quick is an adjective, it qualifies a noun many times for example, a quick dog a quick finish and so on. But, quick and also have adverbial category sometimes not be frequently many times quite really it can act as adverb for example, in a colloquial setting you may say come here quick. So, come here quick, this quick is a qualifier for the action coming, so there it has adverbial function. So, quick has as lexical categories adjective this is what will be recorded in the dictionary, how ever in the sentence come here quick, quick has a functional role which is adverb. So, this is the functional categorization of quick. So, this is an important issue we have to understand in the sentence what is the tag of the word, and in the dictionary what is the tag of the word. So, now, we have this part of speech tags part of speech categories which are nouns, verbs this are very large categories. Now, there are constraints for this classes how do we know that a word is a noun, what kind of test exists for this. So, here there are some simple observation, nouns can be preceded by definite or indefinite articles, but not verbs. So, for example, verbs cannot be preceded by an article typically unless in poetry let us say. So, A or the cat is fine, but an applauded, applauded is a verb in past tense verb and before that would be ungrammatical, additionally nouns combine with other words to found phrases and they can be complements of verbs and verbs cannot do, so. So, what we are discussing is, what kind of constraints exist on the waivers of nouns and verbs, so that they can be distinguished. Now, steal is a verb, steal a car now a car is the object of steal, we also call it the compliment of the verb. Now, a verb cannot be the compliment of a verb without some changes in the morphology of the verb itself, so in general to let us keep things simple and say that nouns, typically form complements of other words. So, steal a car, but steal an applauded is wrong. .. Now, at this point it is useful to distinguish between subjects and complements, in a sentence there are subjects and complements of a verb, a verb can be looked up on I was having subject role and complement role, which have to be fill with nouns. So, these are also known as arguments, typically verbs are not arguments of verbs it is nouns which form the arguments. Here, in this sentence the boy found a watch, a watch, watch is a noun preceded by a article. So, this is a noun phrase the boy, boy is the noun preceded by determiner the boy is a noun phrase. So, found has this subject as lot which needs to be filled, the boy fills it found has a compliment slot which needs to be filled a watch fills it. . .Now, what did we are learn then nouns can combined with determiners, articles, etcetera to form a phrase. Nouns can be the arguments of verbs and that these distinguish nouns from the category called verbs, nouns and verbs both are large categories, verbs typically do not be arguments of other verbs, nouns are the arguments. And nouns are typically preceded by determiners, articles to form phrases. The next category is the set of modifiers, under that we have adjectives which qualify nouns a happy man is an adjective, happy is the adjective this is the example, adverbs they qualify verbs and adjectives. So, he carelessly drop the plate carelessly is the adverb, very blue sky very is adverb because it is qualifying blue, very is also called an intensifier. In English adverbs can be formed from adjectives by adding ly and exception to this rule is a very well yesterday, yesterday is a temporal adverb, adverb of time yesterday he came, well is an adverb of manner he plays well and very is an intensifier adverb, which can go before an adjective. . Then there are relaters which join entities in a sentence. So, we have prepositions like under before of about, so dust under the carpet, horse before the cart, capital of India a man above town, a story about Krishna. So, these are prepositions they do not undergo transformations in English, they do not take what is called inflexions. .. Now, we discuss the criteria for fixing the categories or classes, first important clue which comes for fixing the category is semantic, then morphological categories which realize on the word form and syntactic which realize on the behavior in phrases or structural behavior. So, this is an important point in all natural language processing, whenever we carry out a test for some phenomenon or some behavior, the test can be either semantic which requires deep meaning or syntactic which is a structural consideration or morphological which is based on the property of the word. So, this is almost like a running theme across natural language processing, whenever we design algorithms for natural language processing, we and we test something any algorithm for natural language processing, which tests something. Is either semantic in nature or syntactic or morphological depending on whether it is relaying on meaning or on the structure or on the property of the word. So, it is important to understand that semantic test is extremely reliable, this is extremely robust once you get at the meaning there is no doubt left, we have the decision very clearly fixed, but semantic test is also very hard to implement computationally, this is difficult to design semantic tests, syntactic tests are easier they relay on the structure the way the words relate to each other to form larger phrases. So, this requires parsing and this is less complex then a semantic test, lower than the syntactic test is the morphological test, which realize on the word it is form and its .properties and this is the simplest. So, algorithms typically attempt to remain at the level of morphological processing or word level processing because the moment it is tries to ascend to the level of syntax or semantics, then there are deep waters there are complex things to be handled. . So, we remark here semantic realize meaning, morphological realize on word forms, syntactic realize in where in many phrases for example. Let us take the word happiness and we ask, what is the categories of happiness, happiness we say is noun because it can be preceded by an article. So, this is a syntactic observations syntactic test, so a noun when it participate in a noun phrase, it can be typically preceded by an article, happiness is not an adjective because it does not take any comparative and superlative forms. So, for example, we cannot say happinesser or happinessest, like for quick we can say quicker and quickest, but not, so for happiness. There is not comparative and superlative form for happiness, nor can we make such forms by introducing more and most prefer them, more happiness, most happiness that will make it a noun phrase, it is not degree in the sense of an adjective. So, this shows why this is not an adjective, this is from purely morphological consideration and the fact it is a noun is given by the fact that it is preceded by an article it can preceded by an article. Why is happiness not a verb. So, this we leave as an exercise for the participant or the student, please think about why happiness cannot be a verb. So, see if you can make use .of simple morphological test or we have to go to the level of syntax and semantics to decide, why happiness is not a verb. One simple thing I can say is that, verbs typically have a different form depending on the tense, past, present and future here, happiness will not change it is form depending on whether it happen in the past or will happened in the future or will happening in the present, which is a morphological consideration. . Then there are this functional categories here is a long sentence, where which is full of functional category words. Bill thinks that tom and dick have been visiting Harriet to ask for help with one of the assignments which have to be finished for the next morphology class. This is a sentence from one of the celebrating linguistic text books and this is a long sentence, which has been obtained by gluing together, phrases and even sentence parts and this gluing has been achieve through, the functional categories. The functional categories are shown here, with underline that and to for with of the which to have be for the these are underline words and their functional categories words they full fill particular functions in the sentence. So, that is a subordinating conjunction when you have that, this that can be either a relative pronoun the boy that lives in Delhi it is a relative pronoun or that introduces as a new sentence. I say it that I will go I will go is a new sentence, this is the subordinate class and that introduce a that class, which is a relative pronoun, the city which was devastated in the verb, here which is a relative pronoun. So, we have different categories of words, functions words and content words .this is important for both language acquisition and language disorder, typically we find that when the brain is damaged. So, that the language faculty is also badly hampered, we typically find that the patient does not deal effectively with function words though content words are not affected, so easily. Content words carry the load of information, content words carry the load of information and they have to be really robust and very error free, the function words play the role of putting together sentence parts and phrases. And even if they are wrong fairly accurate amount of meaning can still be transferred, from the speaker to the listener or from the writer to the reader. . So, content words do play the most important role, the relationship between function words and content words is an important one, there are demonstratives these that an articles a, an, the. So, they precede nouns demonstratives precede the noun, these that denotes a particular noun, a, an, the they also denote noun the makes the noun a definite one, in a discourse scenario. Auxiliaries can precede verbs, we are talking about English language then we have pronouns these also looked up on a function words, function words and pronouns are function words because they are pretty close categories. That means, we do not add new pronouns everyday, it is only after centuries or 200 years, 300 years that pronouns get added to a language repository. So, in old English for example, there was this pronoun call thou which got deleted later in modern English. So, .closeness there’s fact that the set forms are close cultic class is possibly one of the reason for calling pronouns has functions words, they also function has reference for nouns, they do not carry the information themselves, but they refer to noun which carries information any way. So, we will discuss this, what categories in the next lecture.",
          "document_id": 1144865
        }
      ]
    }
  ]
}